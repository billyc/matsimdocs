{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Install Install MATSim on your computer. Gallery MATSim is used all over the world! Have a look at the gallery to see how others are using MATSim. Documentation Read up upon MATSim or have a look at the available tutorials to learn how to use MATSim. Get Help Ask your questions on our Q&A platform . Conferences & Meetings Upcoming announcements, and archives of previous conferences. RSS FEED SUBMIT NEWS Latest MATSim News {% for post in site.posts limit:7 %} {{ post.title }} Posted by {{post.author}} on {{ post.date | date: \"%e %b, %Y\" }} {{ post.summary }} \u00bb Read More\u2026 {% endfor %} Latest MATSim News \u00b6","title":"Home"},{"location":"#latest-matsim-news","text":"","title":"Latest MATSim News"},{"location":"benchmark/","text":"MATSim Benchmark \u00b6 The performance of MATSim depends on a lot of different factors: CPU-speed (although by far not always the limiting factor!) Memory-Bus / -Controller (we\u2019re moving huge amounts of memory, the faster the better) File system (local Hard drive vs. RAID vs. NFS vs \u2026) To get a better understanding, under which circumstances MATSim performs best, we created a simple benchmark (performance test) that runs 20 iterations of a sample scenario with different settings. If you run the benchmark on your machine, we would be happy if you could send us your results. Download and Installation \u00b6 Download the zip-file containing the benchmark: benchmark.zip (35MB). Unzip the downloaded file. Running the benchmark \u00b6 On the command line, run the following: java -Xmx500m -jar Benchmark.jar This will generate a directory output with some files in it from the run. The test will usually run between 25 and 40 minutes. The benchmark requires Java 1.5 or newer and 150MB free disk space. If you want to re-run the benchmark, rename or delete the ./output/ directory and run the test again. Submitting benchmark results \u00b6 Please send an email to benchmark AT matsim DOT org containing: the file output/stopwatch.txt the file output/logfile.log a description of your benchmark environment, including: vendor of machine (e.g. HP, Dell, Apple, etc.) processor-type (vendor (Intel, AMD, etc.), model-number, clock-speed, cache-size, number of processors and cores, \u2026) memory (bus-speed, memory-controller, etc.) storage system (rpm, cache size, \u2026, type: e.g. local hard drive, RAID, \u2026) operation system any other information you think might be of interest to us","title":"MATSim Benchmark"},{"location":"benchmark/#matsim-benchmark","text":"The performance of MATSim depends on a lot of different factors: CPU-speed (although by far not always the limiting factor!) Memory-Bus / -Controller (we\u2019re moving huge amounts of memory, the faster the better) File system (local Hard drive vs. RAID vs. NFS vs \u2026) To get a better understanding, under which circumstances MATSim performs best, we created a simple benchmark (performance test) that runs 20 iterations of a sample scenario with different settings. If you run the benchmark on your machine, we would be happy if you could send us your results.","title":"MATSim Benchmark"},{"location":"benchmark/#download-and-installation","text":"Download the zip-file containing the benchmark: benchmark.zip (35MB). Unzip the downloaded file.","title":"Download and Installation"},{"location":"benchmark/#running-the-benchmark","text":"On the command line, run the following: java -Xmx500m -jar Benchmark.jar This will generate a directory output with some files in it from the run. The test will usually run between 25 and 40 minutes. The benchmark requires Java 1.5 or newer and 150MB free disk space. If you want to re-run the benchmark, rename or delete the ./output/ directory and run the test again.","title":"Running the benchmark"},{"location":"benchmark/#submitting-benchmark-results","text":"Please send an email to benchmark AT matsim DOT org containing: the file output/stopwatch.txt the file output/logfile.log a description of your benchmark environment, including: vendor of machine (e.g. HP, Dell, Apple, etc.) processor-type (vendor (Intel, AMD, etc.), model-number, clock-speed, cache-size, number of processors and cores, \u2026) memory (bus-speed, memory-controller, etc.) storage system (rpm, cache size, \u2026, type: e.g. local hard drive, RAID, \u2026) operation system any other information you think might be of interest to us","title":"Submitting benchmark results"},{"location":"conferences/","text":"MATSim Conferences and Meetings \u00b6 Here you will find links to upcoming and past conferences and meetings related to MATSim research and application. {% comment %} with some liquid wizardry, one can probably detect those posts that are older than the current date and move them to \"past events\" automatically {% endcomment %} {% for post in site.conferences reversed %} {{ post.title }} {% if post.event_date.start %} {% if post.event_date.end %} {{ post.event_date.start | date: \"%e %B, %Y\" }} to {{ post.event_date.end | date: \"%e %B, %Y\" }} {% else %} on {{ post.event_date.start | date: \"%e %B, %Y\" }} {% endif %} {% endif %} {% if post.location.name %} in {% if post.location.url %} {% endif %} {{post.location.name}} {% if post.location.url %} {% endif %} {% endif %} {% assign contact_name=post.contact.name | default: post.contact.email %} {% if contact_name %} Contact: {% if post.contact.email %} {{contact_name}} {% else %} {{contact_name}} {% endif %} {% endif %} {{ post.summary }} \u00bb Read More\u2026 {% endfor %} Past Conferences \u00b6 Here you can find information and documentation from the annual MATSim user meeting and MATSim tutorials. The user meeting and a preceding overview tutorial take place annually, often alternating between Zurich and Berlin. Special tutorials are held upon request. 2021 User Meeting - Virtual 2020 User Meeting - Warsaw, Poland | Cancelled 2019 User Meeting - Leuven, Belgium 2018 User Meeting - Atlanta, USA - (Slides available) 2017 User Meeting - Haifa, Israel (some presentation slides also available) 2015 User Meeting - Singapore 2015 Tutorial - Singapore 2014 Tutorial - Berlin 2013 User Meeting - Zurich 2013 Tutorial - Berlin 2012 User Meeting and Tutorial - Berlin 2012 MATSim Tutorial in July 2012 - Madison, WI 2011 Special Tutorial - Shanghai 2011 Special Tutorial - Seoul 2011 Special Tutorial - Singapore 2011 Annual User Meeting and Tutorial - Berlin 2010 Annual User Meeting and Tutorial - Zurich 2010 Tutorial and User Meeting Announcement 2009 Annual User Meeting and Tutorial - Berlin 2009 User Meeting Announcement Old Website \u00b6 Some links on third-party sites may refer to content that no longer exists on this website. You might have a look at the archived, old website and see if the content is still available there. Look here for the archived conference page .","title":"Conferences and Meetings"},{"location":"conferences/#matsim-conferences-and-meetings","text":"Here you will find links to upcoming and past conferences and meetings related to MATSim research and application. {% comment %} with some liquid wizardry, one can probably detect those posts that are older than the current date and move them to \"past events\" automatically {% endcomment %} {% for post in site.conferences reversed %}","title":"&nbsp;MATSim Conferences and Meetings"},{"location":"conferences/#past-conferences","text":"Here you can find information and documentation from the annual MATSim user meeting and MATSim tutorials. The user meeting and a preceding overview tutorial take place annually, often alternating between Zurich and Berlin. Special tutorials are held upon request. 2021 User Meeting - Virtual 2020 User Meeting - Warsaw, Poland | Cancelled 2019 User Meeting - Leuven, Belgium 2018 User Meeting - Atlanta, USA - (Slides available) 2017 User Meeting - Haifa, Israel (some presentation slides also available) 2015 User Meeting - Singapore 2015 Tutorial - Singapore 2014 Tutorial - Berlin 2013 User Meeting - Zurich 2013 Tutorial - Berlin 2012 User Meeting and Tutorial - Berlin 2012 MATSim Tutorial in July 2012 - Madison, WI 2011 Special Tutorial - Shanghai 2011 Special Tutorial - Seoul 2011 Special Tutorial - Singapore 2011 Annual User Meeting and Tutorial - Berlin 2010 Annual User Meeting and Tutorial - Zurich 2010 Tutorial and User Meeting Announcement 2009 Annual User Meeting and Tutorial - Berlin 2009 User Meeting Announcement","title":"Past Conferences"},{"location":"conferences/#old-website","text":"Some links on third-party sites may refer to content that no longer exists on this website. You might have a look at the archived, old website and see if the content is still available there. Look here for the archived conference page .","title":"Old Website"},{"location":"documentation/","text":"MATSim Documentation \u00b6 For Users \u00b6 Tutorials Userguide Extensions MATSim Book Q&A MATSim Community pages (user guides, DIY instructions, etc.) For Developers \u00b6 API Documentation (Doxygen) Issue Tracker (GitHub) Build Server (Jenkins) MATSim Community pages (user guides, DIY instructions, etc.) Tutorials \u00b6 Quickstart: See Install General Tutorials MATSim book and user guide Simulation of public transport Information for developers \u00b6 These documents ... ... provide specification of key-aspects of MATSim (e.g. file formats, simulation events, ...) ... list some guidelines for developers (e.g. coding conventions) to keep MATSim maintainable. ... give information about certain packages, how to (programmatically) use them and what features they offer. offers additional pieces of information that may/should be of interest to developers (e.g. how to use Eclipse for development, or some Java-tips) Developer Resources Getting and Building the Code Contributing / Writing Code MATSim Benchmark Information for users \u00b6 The \"MATSim Book\" is now the authoritative reference. There is an extract of the first couple of chapters, which contains the most relevant topics for new users . This is also referred to as the ``MATSim user guide'' . Some Terminology (i.e. correspondences between MATSim terminology and more standard transport modelling terminology, and reasons why ours is different) can be found here . Publications \u00b6 Being an open-source project heavily driven by research organizations world-wide, a lot of publications were written about MATSim. If you are interested in scientific publications about MATSim, the publication lists of the following institutions serve as a good entry point: Publications by VSP TU-Berlin in particular the working paper series Publications at IVT ETH Zurich in particular the working paper series Google Scholar search, newest first Google Scholar search, most relevant first --> Newsletter \u00b6 Sign up to our newsletter to get news about MATSim about every other month. #mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; } /* Add your own MailChimp form style overrides in your site stylesheet or in this style block. We recommend moving this block and the preceding CSS link to the HEAD of your HTML file. */ #mc_embed_signup form { padding: 10px 0; } Email Address You can unsubscribe at any time by clicking the link in the footer of our emails. We use MailChimp as our marketing platform. By clicking below to subscribe, you acknowledge that your information will be transferred to MailChimp for processing. Learn more about MailChimp's privacy practices here . View previous newsletters. (function($) {window.fnames = new Array(); window.ftypes = new Array();fnames[0]='EMAIL';ftypes[0]='email';fnames[1]='FNAME';ftypes[1]='text';fnames[2]='LNAME';ftypes[2]='text';fnames[3]='ADDRESS';ftypes[3]='address';fnames[4]='PHONE';ftypes[4]='phone';fnames[5]='BIRTHDAY';ftypes[5]='birthday';}(jQuery));var $mcj = jQuery.noConflict(true);","title":"<i class=\"fa fa-book\">&nbsp;</i>MATSim Documentation"},{"location":"documentation/#matsim-documentation","text":"","title":"&nbsp;MATSim Documentation"},{"location":"documentation/#for-users","text":"Tutorials Userguide Extensions MATSim Book Q&A MATSim Community pages (user guides, DIY instructions, etc.)","title":"For Users"},{"location":"documentation/#for-developers","text":"API Documentation (Doxygen) Issue Tracker (GitHub) Build Server (Jenkins) MATSim Community pages (user guides, DIY instructions, etc.)","title":"For Developers"},{"location":"documentation/#tutorials","text":"Quickstart: See Install General Tutorials MATSim book and user guide Simulation of public transport","title":"Tutorials"},{"location":"documentation/#information-for-developers","text":"These documents ... ... provide specification of key-aspects of MATSim (e.g. file formats, simulation events, ...) ... list some guidelines for developers (e.g. coding conventions) to keep MATSim maintainable. ... give information about certain packages, how to (programmatically) use them and what features they offer. offers additional pieces of information that may/should be of interest to developers (e.g. how to use Eclipse for development, or some Java-tips) Developer Resources Getting and Building the Code Contributing / Writing Code MATSim Benchmark","title":"Information for developers"},{"location":"documentation/#information-for-users","text":"The \"MATSim Book\" is now the authoritative reference. There is an extract of the first couple of chapters, which contains the most relevant topics for new users . This is also referred to as the ``MATSim user guide'' . Some Terminology (i.e. correspondences between MATSim terminology and more standard transport modelling terminology, and reasons why ours is different) can be found here .","title":"Information for users"},{"location":"documentation/#publications","text":"Being an open-source project heavily driven by research organizations world-wide, a lot of publications were written about MATSim. If you are interested in scientific publications about MATSim, the publication lists of the following institutions serve as a good entry point: Publications by VSP TU-Berlin in particular the working paper series Publications at IVT ETH Zurich in particular the working paper series Google Scholar search, newest first Google Scholar search, most relevant first -->","title":"Publications"},{"location":"documentation/#newsletter","text":"Sign up to our newsletter to get news about MATSim about every other month. #mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; } /* Add your own MailChimp form style overrides in your site stylesheet or in this style block. We recommend moving this block and the preceding CSS link to the HEAD of your HTML file. */ #mc_embed_signup form { padding: 10px 0; } Email Address You can unsubscribe at any time by clicking the link in the footer of our emails. We use MailChimp as our marketing platform. By clicking below to subscribe, you acknowledge that your information will be transferred to MailChimp for processing. Learn more about MailChimp's privacy practices here . View previous newsletters. (function($) {window.fnames = new Array(); window.ftypes = new Array();fnames[0]='EMAIL';ftypes[0]='email';fnames[1]='FNAME';ftypes[1]='text';fnames[2]='LNAME';ftypes[2]='text';fnames[3]='ADDRESS';ftypes[3]='address';fnames[4]='PHONE';ftypes[4]='phone';fnames[5]='BIRTHDAY';ftypes[5]='birthday';}(jQuery));var $mcj = jQuery.noConflict(true);","title":"Newsletter"},{"location":"downloads/","text":"Contents \u00b6 Use MATSim as a programmer out of an IDE Use the MATSim GUI Use MATSim as a maven plugin Visualization About releases Benchmark \u00b6 Use MATSim as a programmer out of an IDE \u00b6 This approach targets programmers who are comfortable with Java and an IDE (e.g. Eclipse or IntelliJ). This will automatically download MATSim, allow you to browse the source code, and keep you up-to-date with releases or snapshots. Install: (optional but recommended) Fork matsim-example-project . Clone matsim-example-project into local directory. Import as maven project into IDE. Maven will sort out the dependencies. No need to download the MATSim main repository. Sources are available. IntelliJ: Import project --> browse to dir --> maven --> Next, Next, Next Eclipse: Import ... --> ... as maven project --> browse to dir --> accept, accept, accept Run MATSimGUI from the IDE. An example config file is in scenarios/equil . Press Run to run MATSim. (optional but recommended) Run RunMATSim from the IDE. (optional but recommended) Set up, for your forked repo, a continuous integration (CI) workflow. On the github website of your repo: Actions --> New Workflow --> More continuous integration workflows... --> Java with Maven --> Set up this workflow --> Start commit --> ... . This will result in a file .github/workflows/maven.yml which triggers the automatic build after each commit. Detailed configuration of the workflow via this file is possible at a later point in time. Notes: Code examples are in matsim-code-examples on github. Also see there for examples of how to use extensions (package extensions ). If you want/need to write your own extensions: Again, look at matsim-code-examples for examples. Look at ControlerDefaultsModule (in your IDE, source is retrieved by maven) to see how MATSim is plugged together. You will not be able to modify the existing MATSim source code. This is an advantage, since it improves scientific reproducibility. If you feel the need to modify the existing MATSim source code, please use https://matsim.org/faq and we will try to help or implement missing extension points. You can generate a \"clickable jar file\" of your own code with mvn package . This could, for example, be passed on to students or clients for specific studies. \u00b6 Use the MATSim GUI \u00b6 This \"standalone\" version is targeted to users who want to use MATSim by editing the input files, including config.xml directly. A basic GUI is provided. Download matsim-example-project and unzip it. There is an option ``download zipfile''; no need to use git. A clickable jar file is no longer provided, since they make the git repo too large. Instead, follow the instructions under ``Building and Running it locally'' at matsim-example-project . As stated there, you will be able to double click on the generated MATSim jar file. What opens is what we call the MATSim GUI. An example config file is in scenarios/equil . Pres Run to run MATSim. The logfile contains, between a lot of other information, also a dump of a the full matsim configuration. If there are interesting parameters, you could try to copy then into your own config file, modify them, and re-run. In my (kn's) view, one can actually get quite far in this way, i.e. by just editing the config file. The main problem is how to obtain the network and in particular the so-called initial demand for your own scenario. If you can't get that from somewhere else, it is probably better to go through the tutorial. #### Latest Stable Release Version 14.0 \"Spring 2022\", released April 2022 - [ Download ZIP](https://github.com/matsim-org/matsim-libs/releases/download/14.0/matsim-14.0-release.zip) ca. 60 MB - [Older versions](https://github.com/matsim-org/matsim-libs/releases) - [Even older versions (on sourceforge)](https://sourceforge.net/projects/matsim/files/MATSim/) #### Development Version This (= using a development version of MATSim via the GUI) is not recommended any longer. If you cannot work with a release, you should use the IDE and maven. \u00b6 Use MATSim as a maven plugin \u00b6 The \"Maven\" version is targeted to programmers who know about Maven, and want to include MATSim into an already existing Maven project. Similar to the \"MATSim example project\" above, the Maven approach will maven-download MATSim, allow you to browse the source code, and keep you up-to-date with releases or snapshots (depending on your pom.xml). It will not allow you to modify the existing MATSim code -- which, in most cases, also should not be necessary: it is preferred that you contact the developers in such situations and we will try to help or implement missing extension points. #### (Pre-)Release matsim MATSim Maven repository https://repo.matsim.org/repository/matsim/ org.matsim matsim 14.0 The [example project on GitHub](https://github.com/matsim-org/matsim-example-project) contains a valid `pom.xml`. [Extensions](/extensions) can be added in the same way; see the `pom.xml` in the [code examples on GitHub](https://github.com/matsim-org/matsim-code-examples) #### Automatic snapshot of development version matsim MATSim Maven repository https://repo.matsim.org/repository/matsim/ org.matsim matsim 15.0-SNAPSHOT These versions are typically less stable and don't come with up-to-date documenation, but may contain new features. \u00b6 Visualization \u00b6 When the simulation ran, many files were created in its output directory. Note that the GUI has a button to reach the output directory. One of the files is a so-called events file, typically generated for every 10th iteration. The events file for the zeroth iteration is located in .../ITERS/it.0/...0.events.xml.gz . This contains a lot of information that can be visualized. The easiest way to visualize MATSim output is to use VIA. A free version, with a limit on the number of agents, is available for download . If you start VIA, you should see a large, black area. This is where the traffic will be visualized. On the left side of this area, you see a smaller area with 4 icons on the top (\"Controls\"). Click the first icon (Data Sources). Now you can either drag and drop files into this section (e.g. a network.xml , or events.xml.gz ), or click the \"+\" at the bottom to select a file to be added. Use either option to add first network.xml to the list of available data and then events.xml.gz . Now the visualizer knows about our data, and we can tell it how to visualize it. Next, click on the second icon (\"Layers\") in the Controls section. Initially, you will see only the background layer listed. Click on the '+' to select the data you want to have displayed. It should already suggest to visualize the network with the loaded network.xml , so just click Add . After a short moment, the network should be shown in the visualization area. Click the '+' again, but this time choose Vehicles as layer type. The events.xml.gz file will be already pre-selected. Click on Add . As any layer depending on the events, a Load Data button will appear at the bottom of the layer tag. Click it to extract the vehicles' positions from the events. \u00b6 About releases \u00b6 We normally release together with our summer term class taught at TU Berlin: A pre-release in march/april. Possible bugfix versions while the class is running. In june/july, the last bugfix version becomes the stable release. In consequence, the \"latest (pre-)release\" may be more modern than the \"latest stable release\". \u00b6 Benchmark \u00b6 Download Benchmark ZIP, ca. 35MB More information about the MATSim Benchmark .","title":"Download/Install"},{"location":"downloads/#contents","text":"Use MATSim as a programmer out of an IDE Use the MATSim GUI Use MATSim as a maven plugin Visualization About releases Benchmark","title":"Contents"},{"location":"downloads/#programmers","text":"","title":"&nbsp;"},{"location":"downloads/#use-matsim-as-a-programmer-out-of-an-ide","text":"This approach targets programmers who are comfortable with Java and an IDE (e.g. Eclipse or IntelliJ). This will automatically download MATSim, allow you to browse the source code, and keep you up-to-date with releases or snapshots. Install: (optional but recommended) Fork matsim-example-project . Clone matsim-example-project into local directory. Import as maven project into IDE. Maven will sort out the dependencies. No need to download the MATSim main repository. Sources are available. IntelliJ: Import project --> browse to dir --> maven --> Next, Next, Next Eclipse: Import ... --> ... as maven project --> browse to dir --> accept, accept, accept Run MATSimGUI from the IDE. An example config file is in scenarios/equil . Press Run to run MATSim. (optional but recommended) Run RunMATSim from the IDE. (optional but recommended) Set up, for your forked repo, a continuous integration (CI) workflow. On the github website of your repo: Actions --> New Workflow --> More continuous integration workflows... --> Java with Maven --> Set up this workflow --> Start commit --> ... . This will result in a file .github/workflows/maven.yml which triggers the automatic build after each commit. Detailed configuration of the workflow via this file is possible at a later point in time. Notes: Code examples are in matsim-code-examples on github. Also see there for examples of how to use extensions (package extensions ). If you want/need to write your own extensions: Again, look at matsim-code-examples for examples. Look at ControlerDefaultsModule (in your IDE, source is retrieved by maven) to see how MATSim is plugged together. You will not be able to modify the existing MATSim source code. This is an advantage, since it improves scientific reproducibility. If you feel the need to modify the existing MATSim source code, please use https://matsim.org/faq and we will try to help or implement missing extension points. You can generate a \"clickable jar file\" of your own code with mvn package . This could, for example, be passed on to students or clients for specific studies.","title":"Use MATSim as a programmer out of an IDE"},{"location":"downloads/#gui","text":"","title":"&nbsp;"},{"location":"downloads/#use-the-matsim-gui","text":"This \"standalone\" version is targeted to users who want to use MATSim by editing the input files, including config.xml directly. A basic GUI is provided. Download matsim-example-project and unzip it. There is an option ``download zipfile''; no need to use git. A clickable jar file is no longer provided, since they make the git repo too large. Instead, follow the instructions under ``Building and Running it locally'' at matsim-example-project . As stated there, you will be able to double click on the generated MATSim jar file. What opens is what we call the MATSim GUI. An example config file is in scenarios/equil . Pres Run to run MATSim. The logfile contains, between a lot of other information, also a dump of a the full matsim configuration. If there are interesting parameters, you could try to copy then into your own config file, modify them, and re-run. In my (kn's) view, one can actually get quite far in this way, i.e. by just editing the config file. The main problem is how to obtain the network and in particular the so-called initial demand for your own scenario. If you can't get that from somewhere else, it is probably better to go through the tutorial. #### Latest Stable Release Version 14.0 \"Spring 2022\", released April 2022 - [ Download ZIP](https://github.com/matsim-org/matsim-libs/releases/download/14.0/matsim-14.0-release.zip) ca. 60 MB - [Older versions](https://github.com/matsim-org/matsim-libs/releases) - [Even older versions (on sourceforge)](https://sourceforge.net/projects/matsim/files/MATSim/) #### Development Version This (= using a development version of MATSim via the GUI) is not recommended any longer. If you cannot work with a release, you should use the IDE and maven.","title":"Use the MATSim GUI"},{"location":"downloads/#maven","text":"","title":"&nbsp;"},{"location":"downloads/#use-matsim-as-a-maven-plugin","text":"The \"Maven\" version is targeted to programmers who know about Maven, and want to include MATSim into an already existing Maven project. Similar to the \"MATSim example project\" above, the Maven approach will maven-download MATSim, allow you to browse the source code, and keep you up-to-date with releases or snapshots (depending on your pom.xml). It will not allow you to modify the existing MATSim code -- which, in most cases, also should not be necessary: it is preferred that you contact the developers in such situations and we will try to help or implement missing extension points. #### (Pre-)Release matsim MATSim Maven repository https://repo.matsim.org/repository/matsim/ org.matsim matsim 14.0 The [example project on GitHub](https://github.com/matsim-org/matsim-example-project) contains a valid `pom.xml`. [Extensions](/extensions) can be added in the same way; see the `pom.xml` in the [code examples on GitHub](https://github.com/matsim-org/matsim-code-examples) #### Automatic snapshot of development version matsim MATSim Maven repository https://repo.matsim.org/repository/matsim/ org.matsim matsim 15.0-SNAPSHOT These versions are typically less stable and don't come with up-to-date documenation, but may contain new features.","title":"Use MATSim as a maven plugin"},{"location":"downloads/#visualization","text":"","title":"&nbsp;"},{"location":"downloads/#visualization_1","text":"When the simulation ran, many files were created in its output directory. Note that the GUI has a button to reach the output directory. One of the files is a so-called events file, typically generated for every 10th iteration. The events file for the zeroth iteration is located in .../ITERS/it.0/...0.events.xml.gz . This contains a lot of information that can be visualized. The easiest way to visualize MATSim output is to use VIA. A free version, with a limit on the number of agents, is available for download . If you start VIA, you should see a large, black area. This is where the traffic will be visualized. On the left side of this area, you see a smaller area with 4 icons on the top (\"Controls\"). Click the first icon (Data Sources). Now you can either drag and drop files into this section (e.g. a network.xml , or events.xml.gz ), or click the \"+\" at the bottom to select a file to be added. Use either option to add first network.xml to the list of available data and then events.xml.gz . Now the visualizer knows about our data, and we can tell it how to visualize it. Next, click on the second icon (\"Layers\") in the Controls section. Initially, you will see only the background layer listed. Click on the '+' to select the data you want to have displayed. It should already suggest to visualize the network with the loaded network.xml , so just click Add . After a short moment, the network should be shown in the visualization area. Click the '+' again, but this time choose Vehicles as layer type. The events.xml.gz file will be already pre-selected. Click on Add . As any layer depending on the events, a Load Data button will appear at the bottom of the layer tag. Click it to extract the vehicles' positions from the events.","title":"Visualization"},{"location":"downloads/#releases","text":"","title":"&nbsp;"},{"location":"downloads/#about-releases","text":"We normally release together with our summer term class taught at TU Berlin: A pre-release in march/april. Possible bugfix versions while the class is running. In june/july, the last bugfix version becomes the stable release. In consequence, the \"latest (pre-)release\" may be more modern than the \"latest stable release\".","title":"About releases"},{"location":"downloads/#benchmark","text":"","title":"&nbsp;"},{"location":"downloads/#benchmark_1","text":"Download Benchmark ZIP, ca. 35MB More information about the MATSim Benchmark .","title":" &nbsp; Benchmark"},{"location":"javadoc/","text":"Javadoc documentation \u00b6 The documentation shown here is deprecated. The recommended way to obtain information about extensions now is to visit our extensions webpage . For contribs, see https://github.com/matsim-org/matsim-libs/tree/master/contribs and click into the respective contrib to view the respective README.md , which should give further information. If you really need the javadocs, you can download the corresponding javadocs-jar from our Maven repository . Component Development 12.0 (Summer 2020) 11.0 (Spring 2019) 0.10.1 (Spring 2018) 0.9.0 (Spring 2017) 0.8.1 (Spring 2016) 0.7.0 (Fall 2015) 0.6.0 (Fall 2014) 0.5.0 (Spring 2013) 0.4.0 (Spring 2012) 0.3.0 (Spring 2011) matsim main (core, pt, ...) HEAD in javadoc HEAD in doxygen 12.0 11.0 0.10.1 0.9.0 0.8.1 0.7.0 0.6.0 0.5.0 0.4.0 0.3.0 matsim code-examples (=\"tutorial\") repo repo repo repo repo included above included above included above included above included above included above Contribs accessibility HEAD 12.0 11.0 0.10.1 0.9.0 0.8.1 0.7.0 0.6.0 accidents HEAD 12.0 analysis HEAD 12.0 11.0 0.10.1 0.9.0 0.8.1 0.7.0 0.6.0 av (Autonomous Vehicles) HEAD 12.0 11.0 0.10.1 0.9.0 bicycle HEAD 12.0 11.0 0.10.1 0.9.0 cadytsIntegration HEAD 12.0 11.0 0.10.1 0.9.0 0.8.1 0.7.0 0.6.0 carsharing HEAD 12.0 11.0 0.10.1 0.9.0 0.8.1 0.7.0 commercialTrafficApplications HEAD 12.0 common HEAD 12.0 11.0 0.10.1 0.9.0 0.8.1 0.7.0 decongestion HEAD 12.0 discrete_mode_choice HEAD 12.0 drt HEAD 12.0 11.0 0.10.1 0.9.0 dvrp HEAD 12.0 11.0 0.10.1 0.9.0 0.8.1 0.7.0 0.6.0 emissions HEAD 12.0 11.0 0.10.1 0.9.0 0.8.1 0.7.0 0.6.0 ev (Electric Vehicles) HEAD 12.0 11.0 eventsBasedPTRouter HEAD 12.0 11.0 0.10.1 0.9.0 0.8.1 0.7.0 freight HEAD 12.0 11.0 0.10.1 0.9.0 0.8.1 0.7.0 0.6.0 0.4.0 evacuation (was: grips) repo 0.9.0 0.8.1 0.6.0 gtfs2matsimtransitschedule repo 0.9.0 0.8.1 0.7.0 0.6.0 0.4.0 hybridsim HEAD 12.0 11.0 0.10.1 locationchoice HEAD 12.0 11.0 0.10.1 0.9.0 0.8.1 0.7.0 0.6.0 0.5.0 matrixbasedptrouter HEAD 12.0 11.0 0.10.1 0.9.0 0.8.1 0.7.0 0.6.0 matsim4urbansim 0.10.1 0.9.0 0.8.1 0.7.0 0.6.0 0.4.0 minibus HEAD 12.0 11.0 0.10.1 0.9.0 0.8.1 0.7.0 multimodal HEAD 12.0 11.0 0.10.1 0.9.0 0.8.1 0.7.0 0.6.0 networkEditor 0.10.1 0.9.0 0.8.1 0.7.0 0.6.0 0.4.0 noise HEAD 12.0 11.0 0.10.1 0.9.0 0.8.1 osm HEAD 12.0 otfvis HEAD 12.0 11.0 0.10.1 0.9.0 0.8.1 0.7.0 0.6.0 parking HEAD 12.0 11.0 0.10.1 0.9.0 0.8.1 0.7.0 0.6.0 protobuf HEAD 12.0 11.0 0.10.1 0.9.0 pseudosimulation HEAD 12.0 11.0 0.10.1 0.9.0 0.8.1 0.7.0 roadpricing HEAD 12.0 11.0 0.10.1 0.9.0 0.8.1 0.7.0 0.6.0 signals HEAD 12.0 11.0 0.10.1 0.9.0 0.8.1 0.7.0 socnetgen 0.10.1 0.9.0 0.8.1 socnetsim HEAD 12.0 11.0 0.10.1 0.9.0 0.8.1 0.7.0 taxi HEAD 12.0 11.0 0.10.1 0.9.0 0.8.1 transEnergySim 0.10.1 0.9.0 0.8.1 0.7.0 0.6.0 travelsummary 0.10.1 0.9.0 0.8.1 vsp HEAD 12.0 wagonSim 0.10.1 0.9.0 0.8.1 0.7.0 0.6.0","title":"Javadoc"},{"location":"javadoc/#javadoc-documentation","text":"The documentation shown here is deprecated. The recommended way to obtain information about extensions now is to visit our extensions webpage . For contribs, see https://github.com/matsim-org/matsim-libs/tree/master/contribs and click into the respective contrib to view the respective README.md , which should give further information. If you really need the javadocs, you can download the corresponding javadocs-jar from our Maven repository . Component Development 12.0 (Summer 2020) 11.0 (Spring 2019) 0.10.1 (Spring 2018) 0.9.0 (Spring 2017) 0.8.1 (Spring 2016) 0.7.0 (Fall 2015) 0.6.0 (Fall 2014) 0.5.0 (Spring 2013) 0.4.0 (Spring 2012) 0.3.0 (Spring 2011) matsim main (core, pt, ...) HEAD in javadoc HEAD in doxygen 12.0 11.0 0.10.1 0.9.0 0.8.1 0.7.0 0.6.0 0.5.0 0.4.0 0.3.0 matsim code-examples (=\"tutorial\") repo repo repo repo repo included above included above included above included above included above included above Contribs accessibility HEAD 12.0 11.0 0.10.1 0.9.0 0.8.1 0.7.0 0.6.0 accidents HEAD 12.0 analysis HEAD 12.0 11.0 0.10.1 0.9.0 0.8.1 0.7.0 0.6.0 av (Autonomous Vehicles) HEAD 12.0 11.0 0.10.1 0.9.0 bicycle HEAD 12.0 11.0 0.10.1 0.9.0 cadytsIntegration HEAD 12.0 11.0 0.10.1 0.9.0 0.8.1 0.7.0 0.6.0 carsharing HEAD 12.0 11.0 0.10.1 0.9.0 0.8.1 0.7.0 commercialTrafficApplications HEAD 12.0 common HEAD 12.0 11.0 0.10.1 0.9.0 0.8.1 0.7.0 decongestion HEAD 12.0 discrete_mode_choice HEAD 12.0 drt HEAD 12.0 11.0 0.10.1 0.9.0 dvrp HEAD 12.0 11.0 0.10.1 0.9.0 0.8.1 0.7.0 0.6.0 emissions HEAD 12.0 11.0 0.10.1 0.9.0 0.8.1 0.7.0 0.6.0 ev (Electric Vehicles) HEAD 12.0 11.0 eventsBasedPTRouter HEAD 12.0 11.0 0.10.1 0.9.0 0.8.1 0.7.0 freight HEAD 12.0 11.0 0.10.1 0.9.0 0.8.1 0.7.0 0.6.0 0.4.0 evacuation (was: grips) repo 0.9.0 0.8.1 0.6.0 gtfs2matsimtransitschedule repo 0.9.0 0.8.1 0.7.0 0.6.0 0.4.0 hybridsim HEAD 12.0 11.0 0.10.1 locationchoice HEAD 12.0 11.0 0.10.1 0.9.0 0.8.1 0.7.0 0.6.0 0.5.0 matrixbasedptrouter HEAD 12.0 11.0 0.10.1 0.9.0 0.8.1 0.7.0 0.6.0 matsim4urbansim 0.10.1 0.9.0 0.8.1 0.7.0 0.6.0 0.4.0 minibus HEAD 12.0 11.0 0.10.1 0.9.0 0.8.1 0.7.0 multimodal HEAD 12.0 11.0 0.10.1 0.9.0 0.8.1 0.7.0 0.6.0 networkEditor 0.10.1 0.9.0 0.8.1 0.7.0 0.6.0 0.4.0 noise HEAD 12.0 11.0 0.10.1 0.9.0 0.8.1 osm HEAD 12.0 otfvis HEAD 12.0 11.0 0.10.1 0.9.0 0.8.1 0.7.0 0.6.0 parking HEAD 12.0 11.0 0.10.1 0.9.0 0.8.1 0.7.0 0.6.0 protobuf HEAD 12.0 11.0 0.10.1 0.9.0 pseudosimulation HEAD 12.0 11.0 0.10.1 0.9.0 0.8.1 0.7.0 roadpricing HEAD 12.0 11.0 0.10.1 0.9.0 0.8.1 0.7.0 0.6.0 signals HEAD 12.0 11.0 0.10.1 0.9.0 0.8.1 0.7.0 socnetgen 0.10.1 0.9.0 0.8.1 socnetsim HEAD 12.0 11.0 0.10.1 0.9.0 0.8.1 0.7.0 taxi HEAD 12.0 11.0 0.10.1 0.9.0 0.8.1 transEnergySim 0.10.1 0.9.0 0.8.1 0.7.0 0.6.0 travelsummary 0.10.1 0.9.0 0.8.1 vsp HEAD 12.0 wagonSim 0.10.1 0.9.0 0.8.1 0.7.0 0.6.0","title":"Javadoc documentation"},{"location":"open-scenario-data/","text":"Open Scenario Data \u00b6 The following is a list of known scenario data sets that are open and free to use with MATSim. Not all data sets contain all required files to run a MATSim model. Some may only provide a network for example. Please give credit when using these scenarios. matsim.org \u00b6 https://github.com/matsim-scenarios VSP, TU Berlin \u00b6 Most of our scenarios are now under https://github.com/matsim-scenarios . Some older open source scenarios are still in our svn directory as follows. The directories are hierarchically organized and should be self-explanatory. We try to provide readme files, but this does not always work: https://svn.vsp.tu-berlin.de/repos/public-svn/matsim/scenarios/ South Africa \u00b6 Prof. Johan Joubert from the University of Pretoria has open sourced some of the scenarios he built, each consisting of a network and a population: https://matsim.atlassian.net/wiki/display/MATPUB/South+Africa \u00cele-de-France \u00b6 An open and reproducible simulation scenario for \u00cele-de-France is available here . MATSim Test Examples \u00b6 Some smaller scenarios are directly contained in the MATSim source repository, often used for feature demonstration or tests: https://github.com/matsim-org/matsim/tree/master/examples Other links to open data \u00b6 (just a list of links we've come across) A registry of public transit data: http://transit.land . German rail: See http://data.deutschebahn.com/blog/2016/02/25/fahrplan for a German introduction and http://data.deutschebahn.com/apis/fahrplan for the API description; you'll need an API key that can be had by sending a simple E-Mail to DB's Open Data Team. Einen Monat spaeter hat jemand aus den API-Daten einen GTFS-Fahrplan extrahiert: https://github.com/fredlockheed/db-fv-gtfs Visualizations \u00b6 (this is not necessarily \"data\", but links to data and links to visualizations often come together and/or cannot be cleanly separated) Charging stations in Europe: https://ccs-map.eu . TRAVIC Transit Visualization Client http://travic.cs.uni-freiburg.de/ or https://tracker.geops.ch or https://github.com/geops .","title":"Open scenario data"},{"location":"open-scenario-data/#open-scenario-data","text":"The following is a list of known scenario data sets that are open and free to use with MATSim. Not all data sets contain all required files to run a MATSim model. Some may only provide a network for example. Please give credit when using these scenarios.","title":"Open Scenario Data"},{"location":"open-scenario-data/#matsimorg","text":"https://github.com/matsim-scenarios","title":"matsim.org"},{"location":"open-scenario-data/#vsp-tu-berlin","text":"Most of our scenarios are now under https://github.com/matsim-scenarios . Some older open source scenarios are still in our svn directory as follows. The directories are hierarchically organized and should be self-explanatory. We try to provide readme files, but this does not always work: https://svn.vsp.tu-berlin.de/repos/public-svn/matsim/scenarios/","title":"VSP, TU Berlin"},{"location":"open-scenario-data/#south-africa","text":"Prof. Johan Joubert from the University of Pretoria has open sourced some of the scenarios he built, each consisting of a network and a population: https://matsim.atlassian.net/wiki/display/MATPUB/South+Africa","title":"South Africa"},{"location":"open-scenario-data/#ile-de-france","text":"An open and reproducible simulation scenario for \u00cele-de-France is available here .","title":"\u00cele-de-France"},{"location":"open-scenario-data/#matsim-test-examples","text":"Some smaller scenarios are directly contained in the MATSim source repository, often used for feature demonstration or tests: https://github.com/matsim-org/matsim/tree/master/examples","title":"MATSim Test Examples"},{"location":"open-scenario-data/#other-links-to-open-data","text":"(just a list of links we've come across) A registry of public transit data: http://transit.land . German rail: See http://data.deutschebahn.com/blog/2016/02/25/fahrplan for a German introduction and http://data.deutschebahn.com/apis/fahrplan for the API description; you'll need an API key that can be had by sending a simple E-Mail to DB's Open Data Team. Einen Monat spaeter hat jemand aus den API-Daten einen GTFS-Fahrplan extrahiert: https://github.com/fredlockheed/db-fv-gtfs","title":"Other links to open data"},{"location":"open-scenario-data/#visualizations","text":"(this is not necessarily \"data\", but links to data and links to visualizations often come together and/or cannot be cleanly separated) Charging stations in Europe: https://ccs-map.eu . TRAVIC Transit Visualization Client http://travic.cs.uni-freiburg.de/ or https://tracker.geops.ch or https://github.com/geops .","title":"Visualizations"},{"location":"submit-news/","text":"Submit MATSim-related news \u00b6 {% capture today %}{{'now' | date: '%Y-%m-%d'}}{% endcapture %} CREATE ITEM \u00bb ON GITHUB \u00bb We welcome MATSim-related news items, job postings, and event announcements for our front page. To submit news, create a pull request on Github.com with the content of your news item in Markdown format. Here's how to do that: Instructions for posting news via GitHub \u00b6 You'll need a free account on Github to post items Click the Create item on Github button above, to draft a new item in the _posts directory of our site. Edit the file name , author , title , and summary lines. The summary will be shown on the front page as a \"teaser\" blurb. The file name becomes part of the URL, so please don't call it just \"news-item\", but give it a specific name. Add your remaining content in standard Markdown format Preview your post using the Preview pane, and when done... You're ready to create your pull request! Click Propose New File button, which will take you to the confirmation page: Click Create Pull Request You're done! We'll either add your content or get back to you soon! If this is too complicated \u00b6 If this is just too much, send us an email and we'll post your item for you.","title":"Submit MATSim News"},{"location":"submit-news/#submit-matsim-related-news","text":"{% capture today %}{{'now' | date: '%Y-%m-%d'}}{% endcapture %} CREATE ITEM \u00bb ON GITHUB \u00bb We welcome MATSim-related news items, job postings, and event announcements for our front page. To submit news, create a pull request on Github.com with the content of your news item in Markdown format. Here's how to do that:","title":"Submit MATSim-related news"},{"location":"submit-news/#instructions-for-posting-news-via-github","text":"You'll need a free account on Github to post items Click the Create item on Github button above, to draft a new item in the _posts directory of our site. Edit the file name , author , title , and summary lines. The summary will be shown on the front page as a \"teaser\" blurb. The file name becomes part of the URL, so please don't call it just \"news-item\", but give it a specific name. Add your remaining content in standard Markdown format Preview your post using the Preview pane, and when done... You're ready to create your pull request! Click Propose New File button, which will take you to the confirmation page: Click Create Pull Request You're done! We'll either add your content or get back to you soon!","title":"Instructions for posting news via GitHub"},{"location":"submit-news/#if-this-is-too-complicated","text":"If this is just too much, send us an email and we'll post your item for you.","title":"If this is too complicated"},{"location":"the-book/","text":"The MATSim Book is the official reference and user documentation for MATSim. Topics Covered \u00b6 The book is divided into four parts, covering a broad range of topics on more than 600 pages: Part I is an introduction on how to use MATSim, using only the functionality that MATSim brings out-of-the-box. Part II first explains the different data sets needed to run MATSim, and then introduces a number of extensions which add additional functionality to MATSim. Part III provides a lot of insight into the theoretical background of MATSim. Part IV finally presents over 40 use cases from around the world where MATSim was or still is used. Availability \u00b6 Current version \u00b6 Since the book keeps getting older, every year along with the MATSim class at TU Berlin we update the most important chapters, make them available here , and call it the User Guide. Edition 2016 \u00b6 The full book remains at the status of 2016. Download as PDF or eBook: available at Ubiquity Press Print on Demand: available at Ubiquity Press The book is published and available unter the CC-BY 4.0 license. Preferred Citation \u00b6 If you use MATSim and write a scientific paper about it, please cite the book as reference to MATSim. Horni, A., Nagel, K. and Axhausen, K.W. (eds.) 2016 The Multi-Agent Transport Simulation MATSim . London: Ubiquity Press. DOI: http://dx.doi.org/10.5334/baw . License: CC-BY 4.0","title":"The MATSim Book"},{"location":"the-book/#topics-covered","text":"The book is divided into four parts, covering a broad range of topics on more than 600 pages: Part I is an introduction on how to use MATSim, using only the functionality that MATSim brings out-of-the-box. Part II first explains the different data sets needed to run MATSim, and then introduces a number of extensions which add additional functionality to MATSim. Part III provides a lot of insight into the theoretical background of MATSim. Part IV finally presents over 40 use cases from around the world where MATSim was or still is used.","title":"Topics Covered"},{"location":"the-book/#availability","text":"","title":"Availability"},{"location":"the-book/#current-version","text":"Since the book keeps getting older, every year along with the MATSim class at TU Berlin we update the most important chapters, make them available here , and call it the User Guide.","title":"Current version"},{"location":"the-book/#edition-2016","text":"The full book remains at the status of 2016. Download as PDF or eBook: available at Ubiquity Press Print on Demand: available at Ubiquity Press The book is published and available unter the CC-BY 4.0 license.","title":"Edition 2016"},{"location":"the-book/#preferred-citation","text":"If you use MATSim and write a scientific paper about it, please cite the book as reference to MATSim. Horni, A., Nagel, K. and Axhausen, K.W. (eds.) 2016 The Multi-Agent Transport Simulation MATSim . London: Ubiquity Press. DOI: http://dx.doi.org/10.5334/baw . License: CC-BY 4.0","title":"Preferred Citation"},{"location":"about/about-matsim/","text":"Agent-Based Transport Simulations \u00b6 MATSim provides a framework to implement large-scale agent-based transport simulations. The framework consists of several modules which can be combined or used stand-alone. Modules can be replaced by custom implementations to test single aspects of your own work. Currently, MATSim offers a framework for demand-modeling, agent-based mobility-simulation (traffic flow simulation), re-planning, a controler to iteratively run simulations as well as methods to analyze the output generated by the modules. Key Features of MATSim Fast Dynamic and Agent-Based Traffic Simulation Simulate whole days within minutes Private and Public Traffic Both private cars and transit traffic can be simulated Supports Large Scenarios MATSim can simulate millions of agents or huge, detailed networks Versatile Analyses and Simulation Output E.g. compare simulated data to real-world counting stations Modular Approach Easily extended with your own algorithms Open Source You get the Java Source Code, which runs on all major operating systems Active Development The international MATSim community constantly adds new features and improves current ones Start using MATSim! \u00b6 To learn more, look at the documentation or at the scenario gallery to see how others use MATSim.","title":"About MATSim"},{"location":"about/about-matsim/#agent-based-transport-simulations","text":"MATSim provides a framework to implement large-scale agent-based transport simulations. The framework consists of several modules which can be combined or used stand-alone. Modules can be replaced by custom implementations to test single aspects of your own work. Currently, MATSim offers a framework for demand-modeling, agent-based mobility-simulation (traffic flow simulation), re-planning, a controler to iteratively run simulations as well as methods to analyze the output generated by the modules.","title":"Agent-Based Transport Simulations"},{"location":"about/about-matsim/#start-using-matsim","text":"To learn more, look at the documentation or at the scenario gallery to see how others use MATSim.","title":"Start using MATSim!"},{"location":"about/about-us/","text":"MATSim Community \u00b6 MATSim is currently a joint effort by various groups and persons. The two main drivers for the development of MATSim are: Transport Systems Planning and Transport Telematics at the Institute for Land and Sea Transport Systems, Technische Universit\u00e4t Berlin, led by Prof. Dr. Kai Nagel Transport Planning at the Institute for Transport Planning and Systems (IVT), Swiss Federal Institute of Technology Zurich, led by Prof. Dr. Kay W. Axhausen In addition, the following groups and companies contribute regularly, or have so in the past, to the development of MATSim: Senozon , a company in Switzerland with subsidiaries in Germany and Austria, founded by former PhD and research students. Simunto , another company in Switzerland, founded by a former PhD and research student. Center for Transport Development at the University of Pretoria, especially the group led by Prof. Dr. Johan Joubert. Future Cities Laboratory , part of the Singapore-ETH Centre. Department of Transport Systems at Poznan University of Technology (Poland), especially Micha\u0142 Maciejewski. In addition, we stay in close contact to other research groups using and extending MATSim, for example in Toronto (Canada), KIT Karlsruhe and DLR Berlin (both Germany). After all, MATSim is an open source project, feel free to join us on user meetings, conferences or submit patches and pull requests to gain some glory within the MATSim community! While the development is mostly advanced by current research projects, there is a MATSim Committee that acts as a steering group for organizational and strategic issues. Attendants of the conceptual meeting in 2012: Some members of the MATSim Core Development Group in Fall 2011 during the yearly core developer meeting: Attendants of the first MATSim User Meeting 2009 in Berlin:","title":"MATSim Community"},{"location":"about/about-us/#matsim-community","text":"MATSim is currently a joint effort by various groups and persons. The two main drivers for the development of MATSim are: Transport Systems Planning and Transport Telematics at the Institute for Land and Sea Transport Systems, Technische Universit\u00e4t Berlin, led by Prof. Dr. Kai Nagel Transport Planning at the Institute for Transport Planning and Systems (IVT), Swiss Federal Institute of Technology Zurich, led by Prof. Dr. Kay W. Axhausen In addition, the following groups and companies contribute regularly, or have so in the past, to the development of MATSim: Senozon , a company in Switzerland with subsidiaries in Germany and Austria, founded by former PhD and research students. Simunto , another company in Switzerland, founded by a former PhD and research student. Center for Transport Development at the University of Pretoria, especially the group led by Prof. Dr. Johan Joubert. Future Cities Laboratory , part of the Singapore-ETH Centre. Department of Transport Systems at Poznan University of Technology (Poland), especially Micha\u0142 Maciejewski. In addition, we stay in close contact to other research groups using and extending MATSim, for example in Toronto (Canada), KIT Karlsruhe and DLR Berlin (both Germany). After all, MATSim is an open source project, feel free to join us on user meetings, conferences or submit patches and pull requests to gain some glory within the MATSim community! While the development is mostly advanced by current research projects, there is a MATSim Committee that acts as a steering group for organizational and strategic issues. Attendants of the conceptual meeting in 2012: Some members of the MATSim Core Development Group in Fall 2011 during the yearly core developer meeting: Attendants of the first MATSim User Meeting 2009 in Berlin:","title":"MATSim Community"},{"location":"content/2016-matsim-class-tu-berlin-matsim-version-08x/","text":"2016: MATSim class at TU Berlin (matsim version 0.8.x) \u00b6 This is a summary of tutorials of the MATSim class at TU Berlin which is held each year during the summer term. The tutorials provide a step-by-step installation and usage guide for creating your own scenario and policy cases. It does not always go too much into detail (as it is usually taught in a very responsive way in a classroom), so if you need more details about a certain topic, please also consult the MATSim book . All code snippets in this tutorial are direct links to the GitHub repository of MATSim release 0.8.0 (June 2016). It is not recommended to use any other MATSim version with this tutorial. Access: The tutorial lies within TU Berlin's e-learning system ISIS but is open for guests. > Click here to get to the course < To access as a guest, click \"Als Gast\" and accept the Terms & Conditions, just as in the following two pictures:","title":"2016 MATSim class at TU Berlin (matsim version 0.8.x)"},{"location":"content/2016-matsim-class-tu-berlin-matsim-version-08x/#2016-matsim-class-at-tu-berlin-matsim-version-08x","text":"This is a summary of tutorials of the MATSim class at TU Berlin which is held each year during the summer term. The tutorials provide a step-by-step installation and usage guide for creating your own scenario and policy cases. It does not always go too much into detail (as it is usually taught in a very responsive way in a classroom), so if you need more details about a certain topic, please also consult the MATSim book . All code snippets in this tutorial are direct links to the GitHub repository of MATSim release 0.8.0 (June 2016). It is not recommended to use any other MATSim version with this tutorial. Access: The tutorial lies within TU Berlin's e-learning system ISIS but is open for guests. > Click here to get to the course < To access as a guest, click \"Als Gast\" and accept the Terms & Conditions, just as in the following two pictures:","title":"2016: MATSim class at TU Berlin (matsim version 0.8.x)"},{"location":"content/2017-matsim-class-tu-berlin-matsim-version-09x/","text":"2017: MATSim class at TU Berlin (matsim version 0.9.x) \u00b6 This is a summary of tutorials of the MATSim class at TU Berlin which is held each year during the summer term. The tutorials provide a step-by-step installation and usage guide for creating your own scenario and policy cases. It does not always go too much into detail (as it is usually taught in a very responsive way in a classroom), so if you need more details about a certain topic, please also consult the MATSim book . All code snippets in this tutorial are direct links to the GitHub repository of MATSim release 0.9.0 (Summer 2017). It is not recommended to use any other MATSim version with this tutorial. Access: The tutorial lies within TU Berlin's e-learning system ISIS but is open for guests. To access as a guest, click \"Log in as guest\". Unfortunately, from then on it continues in German, no matter what you do. You will have accept the Site Policy Agreement, called \"Nutzungsbedingungen\" in German. The pictures below give some idea, but the layout of the site keeps changing. > Click here to get to the course <","title":"2017 MATSim class at TU Berlin (matsim version 0.9.x)"},{"location":"content/2017-matsim-class-tu-berlin-matsim-version-09x/#2017-matsim-class-at-tu-berlin-matsim-version-09x","text":"This is a summary of tutorials of the MATSim class at TU Berlin which is held each year during the summer term. The tutorials provide a step-by-step installation and usage guide for creating your own scenario and policy cases. It does not always go too much into detail (as it is usually taught in a very responsive way in a classroom), so if you need more details about a certain topic, please also consult the MATSim book . All code snippets in this tutorial are direct links to the GitHub repository of MATSim release 0.9.0 (Summer 2017). It is not recommended to use any other MATSim version with this tutorial. Access: The tutorial lies within TU Berlin's e-learning system ISIS but is open for guests. To access as a guest, click \"Log in as guest\". Unfortunately, from then on it continues in German, no matter what you do. You will have accept the Site Policy Agreement, called \"Nutzungsbedingungen\" in German. The pictures below give some idea, but the layout of the site keeps changing. > Click here to get to the course <","title":"2017: MATSim class at TU Berlin (matsim version 0.9.x)"},{"location":"content/2018-matsim-class-tu-berlin-matsim-version-010x/","text":"2018: MATSim class at TU Berlin (matsim version 0.10.x) \u00b6 This is a summary of tutorials of the MATSim class at TU Berlin which is held each year during the summer term. The tutorials provide a step-by-step installation and usage guide for creating your own scenario and policy cases. It does not always go too much into detail (as it is usually taught in a very responsive way in a classroom), so if you need more details about a certain topic, please also consult the MATSim book . All code snippets in this tutorial are direct links to the GitHub repository of MATSim release 0.10.0 (Summer 2018). It is not recommended to use any other MATSim version with this tutorial. Access: The tutorial lies within TU Berlin's e-learning system ISIS but is open for guests. To access as a guest, click \"Log in as guest\". > Click here to get to the course <","title":"2018 MATSim class at TU Berlin (matsim version 0.10.x)"},{"location":"content/2018-matsim-class-tu-berlin-matsim-version-010x/#2018-matsim-class-at-tu-berlin-matsim-version-010x","text":"This is a summary of tutorials of the MATSim class at TU Berlin which is held each year during the summer term. The tutorials provide a step-by-step installation and usage guide for creating your own scenario and policy cases. It does not always go too much into detail (as it is usually taught in a very responsive way in a classroom), so if you need more details about a certain topic, please also consult the MATSim book . All code snippets in this tutorial are direct links to the GitHub repository of MATSim release 0.10.0 (Summer 2018). It is not recommended to use any other MATSim version with this tutorial. Access: The tutorial lies within TU Berlin's e-learning system ISIS but is open for guests. To access as a guest, click \"Log in as guest\". > Click here to get to the course <","title":"2018: MATSim class at TU Berlin (matsim version 0.10.x)"},{"location":"content/2019-matsim-class-tu-berlin-matsim-version-11x/","text":"2019: MATSim class at TU Berlin (matsim version 11.x) \u00b6 This is a summary of tutorials of the MATSim class at TU Berlin which is held each year during the summer term. The tutorials provide a step-by-step installation and usage guide for creating your own scenario and policy cases. It does not always go too much into detail (as it is usually taught in a very responsive way in a classroom), so if you need more details about a certain topic, please also consult the MATSim book . All code snippets in this tutorial are direct links to the GitHub repository of MATSim release 11.0 (Summer 2019). It is not recommended to use any other MATSim version with this tutorial. Access: The tutorial lies within TU Berlin's e-learning system ISIS but is open for guests. To access as a guest, click \"Log in as guest\". > Click here to get to the course <","title":"2019 MATSim class at TU Berlin (matsim version 11.x)"},{"location":"content/2019-matsim-class-tu-berlin-matsim-version-11x/#2019-matsim-class-at-tu-berlin-matsim-version-11x","text":"This is a summary of tutorials of the MATSim class at TU Berlin which is held each year during the summer term. The tutorials provide a step-by-step installation and usage guide for creating your own scenario and policy cases. It does not always go too much into detail (as it is usually taught in a very responsive way in a classroom), so if you need more details about a certain topic, please also consult the MATSim book . All code snippets in this tutorial are direct links to the GitHub repository of MATSim release 11.0 (Summer 2019). It is not recommended to use any other MATSim version with this tutorial. Access: The tutorial lies within TU Berlin's e-learning system ISIS but is open for guests. To access as a guest, click \"Log in as guest\". > Click here to get to the course <","title":"2019: MATSim class at TU Berlin (matsim version 11.x)"},{"location":"content/2020-matsim-class-tu-berlin-matsim-version-12x/","text":"2020: MATSim class at TU Berlin (matsim version 12.x) \u00b6 This is a summary of tutorials of the MATSim class at TU Berlin which is held each year during the summer term. The tutorials provide a step-by-step installation and usage guide for creating your own scenario and policy cases. It does not always go too much into detail (as it is usually taught in a very responsive way in a classroom), so if you need more details about a certain topic, please also consult the MATSim book . All code snippets in this tutorial are direct links to the GitHub repository of MATSim release 12.0 (Summer 2020). It is not recommended to use any other MATSim version with this tutorial. Access: The tutorial lies within TU Berlin's e-learning system ISIS but is open for guests. To access as a guest, click \"Log in as guest\". ==> Click here to get to the course ==<","title":"2020 MATSim class at TU Berlin (matsim version 12.x)"},{"location":"content/2020-matsim-class-tu-berlin-matsim-version-12x/#2020-matsim-class-at-tu-berlin-matsim-version-12x","text":"This is a summary of tutorials of the MATSim class at TU Berlin which is held each year during the summer term. The tutorials provide a step-by-step installation and usage guide for creating your own scenario and policy cases. It does not always go too much into detail (as it is usually taught in a very responsive way in a classroom), so if you need more details about a certain topic, please also consult the MATSim book . All code snippets in this tutorial are direct links to the GitHub repository of MATSim release 12.0 (Summer 2020). It is not recommended to use any other MATSim version with this tutorial. Access: The tutorial lies within TU Berlin's e-learning system ISIS but is open for guests. To access as a guest, click \"Log in as guest\". ==> Click here to get to the course ==<","title":"2020: MATSim class at TU Berlin (matsim version 12.x)"},{"location":"content/developer-resources/","text":"Developer Resources \u00b6 Below is a list of several links that contain information about the development process of MATSim. Some of the linked pages may be useful, while others are just \"for fun\". Most of the pages are updated once a day during the night. Build Server \u00b6 The MATSim Build Server (sometimes also called \"Continuous Integration Server\") regularly checks out the source code of MATSim, compiles the code and runs the tests. The build server has detailed statistics about the code and tests. Issue Tracker \u00b6 Found a bug? Then file a bug-report! Have a feature request? Enter it here! Nothing to do anymore? Fix a bug or implement a feature request! Javadoc \u00b6 Doxygen \u00b6 Test results archive \u00b6 We regularly archive some test results, such as plots of fundamental diagrams.","title":"Developer Resources"},{"location":"content/developer-resources/#developer-resources","text":"Below is a list of several links that contain information about the development process of MATSim. Some of the linked pages may be useful, while others are just \"for fun\". Most of the pages are updated once a day during the night.","title":"Developer Resources"},{"location":"content/developer-resources/#build-server","text":"The MATSim Build Server (sometimes also called \"Continuous Integration Server\") regularly checks out the source code of MATSim, compiles the code and runs the tests. The build server has detailed statistics about the code and tests.","title":"Build Server"},{"location":"content/developer-resources/#issue-tracker","text":"Found a bug? Then file a bug-report! Have a feature request? Enter it here! Nothing to do anymore? Fix a bug or implement a feature request!","title":"Issue Tracker"},{"location":"content/developer-resources/#javadoc","text":"","title":"Javadoc"},{"location":"content/developer-resources/#doxygen","text":"","title":"Doxygen"},{"location":"content/developer-resources/#test-results-archive","text":"We regularly archive some test results, such as plots of fundamental diagrams.","title":"Test results archive"},{"location":"content/matsim-book-and-users-guide/","text":"MATSim Book and User's Guide \u00b6 The MATSim book is a comprehensive introduction into MATSim. Since books are a bit static, and software is dynamic, we provide an extract of some chapters as a user's guide . In contrast to the book, these chapters are regularly updated in conjunction with our annual MATSim class at TU Berlin, running from March until July every year.","title":"MATSim Book and User's Guide"},{"location":"content/matsim-book-and-users-guide/#matsim-book-and-users-guide","text":"The MATSim book is a comprehensive introduction into MATSim. Since books are a bit static, and software is dynamic, we provide an extract of some chapters as a user's guide . In contrast to the book, these chapters are regularly updated in conjunction with our annual MATSim class at TU Berlin, running from March until July every year.","title":"MATSim Book and User's Guide"},{"location":"content/zz_archive/matsim-example-project/","text":"MATSim Example Project \u00b6 There is a MATSim example project on GitHub . It allows to use all of the matsim main distribution as well as the contribs as maven-includes. The setup allows both release versions and nightly snapshot version. It is almost certainly the best way to go if you are somewhat familiar with maven and want to program against MATSim (i.e. use matsim as a library).","title":"MATSim Example Project"},{"location":"content/zz_archive/matsim-example-project/#matsim-example-project","text":"There is a MATSim example project on GitHub . It allows to use all of the matsim main distribution as well as the contribs as maven-includes. The setup allows both release versions and nightly snapshot version. It is almost certainly the best way to go if you are somewhat familiar with maven and want to program against MATSim (i.e. use matsim as a library).","title":"MATSim Example Project"},{"location":"content/zz_archive/quickstart/","text":"Quickstart \u00b6 (0) Download the release and unzip it. (1) Go the the directory where you find matsim-*.jar . (2) Double click on the MATSim jar file. What opens is what we call the MATSim GUI. Then type (if you opened the directory on explorer you need to open the command line and type the following command in there) java -Xmx2000m -cp matsim-0.7.0.jar org.matsim.run.Controler examples/tutorial/config/example5-config.xml This should produce a new output directory. Meaning of the parameters: -Xmx2000m : Increases the Java heap space to 2000MB of memory. If you have less memory, try smaller values, but the Java default is too small. -cp matsim-0.7.0.jar : The jar file (Java library) which contains MATSim. The release number of the jar file you downloaded might be different from the one in this example (0.7.0), so make sure you type in a release number that corresponds to the version you downloaded. org.matsim.run.Controler : The class where the main method for running \"iterations\" resides. ~~ ~~examples/tutorial/config/example5-config.xml : The xml file that contains all of the configuration of the run. The file can be edited. Note: if you run the above \"org.matsim.run.Controler\" line again, you first need to erase the contents of the output directory. (3) Now it is time to have a look at the output. When the simulation ran, many files were created in its output directory. Note that the GUI has a button to reach the output directory. One of the files is a so-called events file, typically generated for every 10th iteration. The events file for the first iteration is located in output/ITERS/it.0/run0.0.events.xml.gz . This contains a lot of information that can be visualized. Now, when you start the visualizer (called Via, a free version is available for download , you should see a large, black area. This is where the traffic will be visualized. On the left side of this area, you see a smaller area with 4 icons on the top (\"Controls\"). Click the first icon (Data Sources). Now you can either drag and drop files into this section (e.g. a network.xml , or events.xml.gz ), or click the \"+\" at the bottom to select a file to be added. Use either option to add first network.xml to the list of available data and then events.xml.gz . Now the visualizer knows about our data, and we can tell it how to visualize it. Next, click on the second icon (\"Layers\") in the Controls section. Initially, you will see only the background layer listed. Click on the '+' to select the data you want to have displayed. It should already suggest to visualize the network with the loaded network.xml , so just click \"Add\". After a short moment, the network should be shown in the visualization area. Click the '+' again, but this time choose Vehicles as layer type. The events.xml.gz file will be already pre-selected. Click on \"Add\". As any layer depending on the events, a \"Load Data\" button will appear at the bottom of the layer tag. Click it to extract the vehicles' positions from the events. (4) The logfile, with the above example in output/example5/logfile.log contains, between a lot of other information, also a dump of a the full matsim configuration. If there are interesting parameters, you could try to copy then into your own config file, modify them, and re-run. In my (kn's) view, one can actually get quite far in this way, i.e. by just editing the config file. The main problem is how to obtain the network and in particular the so-called initial demand for your own scenario. If you can't get that from somewhere else, it is probably better to go through the tutorial.","title":"Quickstart"},{"location":"content/zz_archive/quickstart/#quickstart","text":"(0) Download the release and unzip it. (1) Go the the directory where you find matsim-*.jar . (2) Double click on the MATSim jar file. What opens is what we call the MATSim GUI. Then type (if you opened the directory on explorer you need to open the command line and type the following command in there) java -Xmx2000m -cp matsim-0.7.0.jar org.matsim.run.Controler examples/tutorial/config/example5-config.xml This should produce a new output directory. Meaning of the parameters: -Xmx2000m : Increases the Java heap space to 2000MB of memory. If you have less memory, try smaller values, but the Java default is too small. -cp matsim-0.7.0.jar : The jar file (Java library) which contains MATSim. The release number of the jar file you downloaded might be different from the one in this example (0.7.0), so make sure you type in a release number that corresponds to the version you downloaded. org.matsim.run.Controler : The class where the main method for running \"iterations\" resides. ~~ ~~examples/tutorial/config/example5-config.xml : The xml file that contains all of the configuration of the run. The file can be edited. Note: if you run the above \"org.matsim.run.Controler\" line again, you first need to erase the contents of the output directory. (3) Now it is time to have a look at the output. When the simulation ran, many files were created in its output directory. Note that the GUI has a button to reach the output directory. One of the files is a so-called events file, typically generated for every 10th iteration. The events file for the first iteration is located in output/ITERS/it.0/run0.0.events.xml.gz . This contains a lot of information that can be visualized. Now, when you start the visualizer (called Via, a free version is available for download , you should see a large, black area. This is where the traffic will be visualized. On the left side of this area, you see a smaller area with 4 icons on the top (\"Controls\"). Click the first icon (Data Sources). Now you can either drag and drop files into this section (e.g. a network.xml , or events.xml.gz ), or click the \"+\" at the bottom to select a file to be added. Use either option to add first network.xml to the list of available data and then events.xml.gz . Now the visualizer knows about our data, and we can tell it how to visualize it. Next, click on the second icon (\"Layers\") in the Controls section. Initially, you will see only the background layer listed. Click on the '+' to select the data you want to have displayed. It should already suggest to visualize the network with the loaded network.xml , so just click \"Add\". After a short moment, the network should be shown in the visualization area. Click the '+' again, but this time choose Vehicles as layer type. The events.xml.gz file will be already pre-selected. Click on \"Add\". As any layer depending on the events, a \"Load Data\" button will appear at the bottom of the layer tag. Click it to extract the vehicles' positions from the events. (4) The logfile, with the above example in output/example5/logfile.log contains, between a lot of other information, also a dump of a the full matsim configuration. If there are interesting parameters, you could try to copy then into your own config file, modify them, and re-run. In my (kn's) view, one can actually get quite far in this way, i.e. by just editing the config file. The main problem is how to obtain the network and in particular the so-called initial demand for your own scenario. If you can't get that from somewhere else, it is probably better to go through the tutorial.","title":"Quickstart"},{"location":"contributing/","text":"Contributing / Writing Code \u00b6 The most important rules: Committed Code must compile with Java 8 (current system requirements by MATSim) Only commit to your personal playground, unless you are a contrib maintainer or you have been given the rights to commit in other locations. The following sections contain more information for writing code for MATSim: Coding Conventions Naming Conventions Committing to the Repository Data in the source repository Configuration conventions Documenting your code IDE Configuration Java-related Information MATSim Extensions Prefer composition / delegation over inheritance Using Generics","title":"Contributing / Writing Code"},{"location":"contributing/#contributing-writing-code","text":"The most important rules: Committed Code must compile with Java 8 (current system requirements by MATSim) Only commit to your personal playground, unless you are a contrib maintainer or you have been given the rights to commit in other locations. The following sections contain more information for writing code for MATSim: Coding Conventions Naming Conventions Committing to the Repository Data in the source repository Configuration conventions Documenting your code IDE Configuration Java-related Information MATSim Extensions Prefer composition / delegation over inheritance Using Generics","title":"Contributing / Writing Code"},{"location":"contributing/extensions/","text":"Important Note \u00b6 The following text is no longer up to date and needs to be revised. We now say that \"extensions\" is everything that extends MATSim, but there are three categories of extensions: \"extensions which are part of the MATSim main distribution \"contribs\", which are outside the MATSim main distribution, but inside the MATSim main repository \"other extensions\", which are maintained outside the MATSim main repository. This category again splits into two subcategories extensions hosted at github.com/matsim-org but not in the MATSim main repository other extensions. VIA is the most prominent example here. So please read the following text with care; quite often it says \"extension\" but means \"contrib\". Introduction \u00b6 As a lot of functionality in MATSim is created by PhD students, there is often a problem maintaining this functionality after the respective students finished their work and leave university. In order to better communicate which features are \"standard MATSim\" which will (and have to) be maintained by the MATSim core developers, and which features are just \"single-developer functionality\", MATSim introduces the concept of \" MATSim core \" and \" MATSim extensions \". The core will be maintained by the core developers, and should contain central functionality which is likely to stay in MATSim forever. Extensions can provide new, but stable, functionality developed to solve specific problems which can be of interest to others in the MATSim community. Extensions will\u2014as long as they compile and pass all tests\u2014also be packaged for releases and be thus optional parts of MATSim releases. This requires that extensions follow certain guidelines, also in order to keep code maintenance and user support in reasonable bounds. Requirements \u00b6 You feel responsible for your extension Document the functionality of your extension Document the usage of your extension. This documentation should cover topics like (a) How to use it, (b) How to configure it, (c) if it has any special system requirements, (d) optionally have a small tutorial with sample data to demonstrate the functionality. If your code offers one or more main classes, make sure to provide useful error message to the user in the case the user submits no or wrong arguments If your code offers functionality to other code (e.g. special algorithms and data structures), such classes/interfaces should be well-documented using Javadoc comments. You will maintain the code in the case that some updates in MATSim-Core break some functionality in your extension You are wiling to assist interested users in the case something is not working as described by your documentation. Creating your own extension \u00b6 Create the code in your playground or private repository Make sure you meet the code requirements outline above Talk to a member of the MATSim committee to request a new contrib-project for your code. If the committee agrees to your request, they will create a contrib-project for you, where you can move your code to. Write documentation about your extension to comply with the above-mentioned documentation requirements. Once all the code and documentation requirements are met, your extension will be included in future releases and nightly builds will be created for it. Documenting extensions in the contrib section \u00b6 Extensions in the contrib section are stand-alone documentations. The entry points are under matsim.org/javadoc . Always please do the following: Provide an example \"script in java\" with a name RunXxx somewhere inside that extension package, and add documentation to enable others to use it. Also see How to provide coding examples ? Additional options depend on personal style. Some options are Populate src/main/javadoc/overview.html with html text. Look at at the minibus contrib for an example. The content will show up at the entry point of the documentation. Javadoc can link into the listing by something like <a href=\"{@docRoot}/src-html/org/matsim/contrib/emissions/example/RunEmissionToolOnlineExample.html\">here</a> into the java source listing.","title":"MATSim Extensions"},{"location":"contributing/extensions/#important-note","text":"The following text is no longer up to date and needs to be revised. We now say that \"extensions\" is everything that extends MATSim, but there are three categories of extensions: \"extensions which are part of the MATSim main distribution \"contribs\", which are outside the MATSim main distribution, but inside the MATSim main repository \"other extensions\", which are maintained outside the MATSim main repository. This category again splits into two subcategories extensions hosted at github.com/matsim-org but not in the MATSim main repository other extensions. VIA is the most prominent example here. So please read the following text with care; quite often it says \"extension\" but means \"contrib\".","title":"Important Note"},{"location":"contributing/extensions/#introduction","text":"As a lot of functionality in MATSim is created by PhD students, there is often a problem maintaining this functionality after the respective students finished their work and leave university. In order to better communicate which features are \"standard MATSim\" which will (and have to) be maintained by the MATSim core developers, and which features are just \"single-developer functionality\", MATSim introduces the concept of \" MATSim core \" and \" MATSim extensions \". The core will be maintained by the core developers, and should contain central functionality which is likely to stay in MATSim forever. Extensions can provide new, but stable, functionality developed to solve specific problems which can be of interest to others in the MATSim community. Extensions will\u2014as long as they compile and pass all tests\u2014also be packaged for releases and be thus optional parts of MATSim releases. This requires that extensions follow certain guidelines, also in order to keep code maintenance and user support in reasonable bounds.","title":"Introduction"},{"location":"contributing/extensions/#requirements","text":"You feel responsible for your extension Document the functionality of your extension Document the usage of your extension. This documentation should cover topics like (a) How to use it, (b) How to configure it, (c) if it has any special system requirements, (d) optionally have a small tutorial with sample data to demonstrate the functionality. If your code offers one or more main classes, make sure to provide useful error message to the user in the case the user submits no or wrong arguments If your code offers functionality to other code (e.g. special algorithms and data structures), such classes/interfaces should be well-documented using Javadoc comments. You will maintain the code in the case that some updates in MATSim-Core break some functionality in your extension You are wiling to assist interested users in the case something is not working as described by your documentation.","title":"Requirements"},{"location":"contributing/extensions/#creating-your-own-extension","text":"Create the code in your playground or private repository Make sure you meet the code requirements outline above Talk to a member of the MATSim committee to request a new contrib-project for your code. If the committee agrees to your request, they will create a contrib-project for you, where you can move your code to. Write documentation about your extension to comply with the above-mentioned documentation requirements. Once all the code and documentation requirements are met, your extension will be included in future releases and nightly builds will be created for it.","title":"Creating your own extension"},{"location":"contributing/extensions/#documenting-extensions-in-the-contrib-section","text":"Extensions in the contrib section are stand-alone documentations. The entry points are under matsim.org/javadoc . Always please do the following: Provide an example \"script in java\" with a name RunXxx somewhere inside that extension package, and add documentation to enable others to use it. Also see How to provide coding examples ? Additional options depend on personal style. Some options are Populate src/main/javadoc/overview.html with html text. Look at at the minibus contrib for an example. The content will show up at the entry point of the documentation. Javadoc can link into the listing by something like <a href=\"{@docRoot}/src-html/org/matsim/contrib/emissions/example/RunEmissionToolOnlineExample.html\">here</a> into the java source listing.","title":"Documenting extensions in the contrib section"},{"location":"devguide/build-release/","text":"Building a (personal / nightly) release \u00b6 Note: We are currently deprecating the concept of playgrounds. If you are a new MATSim user, please use MATSim as a regular Java library, and package your package as you would package any other package. The following information gives instructions how to package a playground with its dependencies, often used to upload it to another machine to execute a compute job. Playgrounds are subfolders in a shared repository, where people host their custom projects. Creating a release of a playground \u00b6 Prerequisite: Make sure you have the file assembly-release.xml in your playground at src/main/assembly . If you are missing this file, you can copy it from playgrounds/_template/src/main/assembly . # install matsim, contribs and playgrounds to local maven repository # (from matsim repository root directory) mvn clean mvn install -DskipTests=true # from your playground mvn clean mvn -Prelease -DskipTests=true This will create a file myPlayground-0.x.0-SNAPSHOT-r#####.zip in your contrib's or playground's target directory containing the release. Unzip it to use it. Verification for Contrib and Playgrounds \u00b6 calling java -cp myplayground.jar org.matsim.run.ReleaseInfo should show some useful build information (revision number and timestamp). Running your code from the release \u00b6 If you unzip the created release-zip-file, you'll find a jar-file of your contrib/playground, and a \"libs\" directory. To run your code, simple call java -cp myplayground.jar playground.myPlayground.my.MainClass arg1 arg2 arg3 (naturally, replacing the filename, classname and actual arguments with correct values). Notes \u00b6 The Manifest for the release-jars may be special and must be configured in the plugin-configuration in the pom, thus the release profile ( -Prelease ) is used for the generation of the final zip. This is also the reason why it is important to clean before building the release, as Maven might not recompile the jar when just the profile changes, leading to missing entries in the Manifest of the packaged jar-file. To see the content of the generated zip file, use the following command to unzip it: unzip target/matsim-0.x.0-SNAPSHOT-release.zip -d target/release Adding revision information and timestamp is possible with the buildnumber-plugin, but it needs quite some customization. Using the buildnumber-properties in filtered files seems only to work if the buildnumber-plugin is NOT configured in a profile, but in the main part of the pom.","title":"Build a release"},{"location":"devguide/build-release/#building-a-personal-nightly-release","text":"Note: We are currently deprecating the concept of playgrounds. If you are a new MATSim user, please use MATSim as a regular Java library, and package your package as you would package any other package. The following information gives instructions how to package a playground with its dependencies, often used to upload it to another machine to execute a compute job. Playgrounds are subfolders in a shared repository, where people host their custom projects.","title":"Building a (personal / nightly) release"},{"location":"devguide/build-release/#creating-a-release-of-a-playground","text":"Prerequisite: Make sure you have the file assembly-release.xml in your playground at src/main/assembly . If you are missing this file, you can copy it from playgrounds/_template/src/main/assembly . # install matsim, contribs and playgrounds to local maven repository # (from matsim repository root directory) mvn clean mvn install -DskipTests=true # from your playground mvn clean mvn -Prelease -DskipTests=true This will create a file myPlayground-0.x.0-SNAPSHOT-r#####.zip in your contrib's or playground's target directory containing the release. Unzip it to use it.","title":"Creating a release of a playground"},{"location":"devguide/build-release/#verification-for-contrib-and-playgrounds","text":"calling java -cp myplayground.jar org.matsim.run.ReleaseInfo should show some useful build information (revision number and timestamp).","title":"Verification for Contrib and Playgrounds"},{"location":"devguide/build-release/#running-your-code-from-the-release","text":"If you unzip the created release-zip-file, you'll find a jar-file of your contrib/playground, and a \"libs\" directory. To run your code, simple call java -cp myplayground.jar playground.myPlayground.my.MainClass arg1 arg2 arg3 (naturally, replacing the filename, classname and actual arguments with correct values).","title":"Running your code from the release"},{"location":"devguide/build-release/#notes","text":"The Manifest for the release-jars may be special and must be configured in the plugin-configuration in the pom, thus the release profile ( -Prelease ) is used for the generation of the final zip. This is also the reason why it is important to clean before building the release, as Maven might not recompile the jar when just the profile changes, leading to missing entries in the Manifest of the packaged jar-file. To see the content of the generated zip file, use the following command to unzip it: unzip target/matsim-0.x.0-SNAPSHOT-release.zip -d target/release Adding revision information and timestamp is possible with the buildnumber-plugin, but it needs quite some customization. Using the buildnumber-properties in filtered files seems only to work if the buildnumber-plugin is NOT configured in a profile, but in the main part of the pom.","title":"Notes"},{"location":"devguide/commit-rules/","text":"Commit Rules \u00b6 Code to be committed must compile. Use UTF-8 as file encoding. Otherwise it may not compile on all machines. By default, only commit to your personal contrib . Do not commit to org.matsim.* unless you are the maintainer of a package/module in org.matsim.* . Create Pull-Requests for changes in org.matsim.* . Do not directly commit to org.matsim.* , but create a pull request with the changes you want to apply. Write your commit messages in English. Write useful commit messages. A short header line, followed by a blank line, followed by text explaining the change is standard Git practice. Do not commit personal data (=non-code) files to the repository. Exception is data for test cases, which must be committed to test/input/* . See the detailed discussion of this topic.","title":"Commit rules"},{"location":"devguide/commit-rules/#commit-rules","text":"Code to be committed must compile. Use UTF-8 as file encoding. Otherwise it may not compile on all machines. By default, only commit to your personal contrib . Do not commit to org.matsim.* unless you are the maintainer of a package/module in org.matsim.* . Create Pull-Requests for changes in org.matsim.* . Do not directly commit to org.matsim.* , but create a pull request with the changes you want to apply. Write your commit messages in English. Write useful commit messages. A short header line, followed by a blank line, followed by text explaining the change is standard Git practice. Do not commit personal data (=non-code) files to the repository. Exception is data for test cases, which must be committed to test/input/* . See the detailed discussion of this topic.","title":"Commit Rules"},{"location":"devguide/configuration-conventions/","text":"Configuration Conventions \u00b6 For non-programmers, MATSim is configured via the config file. (For extensions, we have not yet found a good solution.) If you make your code configurable, please observe the following hints. Avoid automagic \u00b6 Examples for automagic are: If the code finds a file of a certain type, then do something special. If the code finds a config module of a certain type, then do something special. If some values are overwritten then some other values are cleared. The problem with such automagic is that it is nearly impossible to write code that is robust against typoes. As a result, one gets warnings such as \"File of certain type not found, thus assuming ...\" (This may either be a deliberate user decision, or a typo on the filename.) \"Config module of a certain type not found, thus assuming ...\" (This may either be a deliberate user decision, or a type in the module name.) \"Config module of a certain type found, thus assuming ...\" (This may be a leftover module from some other experiments.) \"When you are overwriting value X please remember that this also affects values Y and Z.\" (Which may be what the user wants, or not.) If a user is not able to switch off warnings, she or he will eventually start to ignore them. Which is not good. In that sense: Avoid warnings that cannot be switched off \u00b6 If a user is not able to switch off warnings, she or he will eventually start to ignore them. Two aspects: Automagic should be avoided (see above). If the user is doing something non-standard/not-recommended, this may lead to a warning. It would make sense to provide a switch to disable such warnings. (Makes the configuration file a lot longer, though.)","title":"Configuration conventions"},{"location":"devguide/configuration-conventions/#configuration-conventions","text":"For non-programmers, MATSim is configured via the config file. (For extensions, we have not yet found a good solution.) If you make your code configurable, please observe the following hints.","title":"Configuration Conventions"},{"location":"devguide/configuration-conventions/#avoid-automagic","text":"Examples for automagic are: If the code finds a file of a certain type, then do something special. If the code finds a config module of a certain type, then do something special. If some values are overwritten then some other values are cleared. The problem with such automagic is that it is nearly impossible to write code that is robust against typoes. As a result, one gets warnings such as \"File of certain type not found, thus assuming ...\" (This may either be a deliberate user decision, or a typo on the filename.) \"Config module of a certain type not found, thus assuming ...\" (This may either be a deliberate user decision, or a type in the module name.) \"Config module of a certain type found, thus assuming ...\" (This may be a leftover module from some other experiments.) \"When you are overwriting value X please remember that this also affects values Y and Z.\" (Which may be what the user wants, or not.) If a user is not able to switch off warnings, she or he will eventually start to ignore them. Which is not good. In that sense:","title":"Avoid automagic"},{"location":"devguide/configuration-conventions/#avoid-warnings-that-cannot-be-switched-off","text":"If a user is not able to switch off warnings, she or he will eventually start to ignore them. Two aspects: Automagic should be avoided (see above). If the user is doing something non-standard/not-recommended, this may lead to a warning. It would make sense to provide a switch to disable such warnings. (Makes the configuration file a lot longer, though.)","title":"Avoid warnings that cannot be switched off"},{"location":"devguide/conventions/","text":"Coding Conventions \u00b6 For a project the size of MATSim, we need a minimal set of guidelines to insure the stability of MATSim and enable its further development. We try to keep this list as short as possible. We try to follow the Java Code Conventions This includes the Naming Conventions (Classes start with capital letters, variables with lowercase letters, ...), the usage of braces in if statements and other stuff. A notable exception are line lengths (we have no problem with lines up to 132 characters). Also, source code should only contain ASCII characters in code. Non-ascii in comments are ok; non-ascii in Strings should be avoided but sometimes cannot (e.g. file readers). More detailed Naming Conventions for MATSim are also available. Indentation MATSim Source code is indented with tabs, not spaces. Code is consistent and compiles! Code committed to the repository has to compile - always. If you want to try out some stuff, do it somewhere else or do not commit it. Classes in org.matsim.* do not reference other classes outside of the org.matsim.* -package except for classes provided by third-party libraries. Especially, org.matsim.* -classes must not reference tutorial and contrib -classes. All our code files have the MATSim-specific GPL-Header In Eclipse, you could add the header to the code template, so every new Java file has this header set by default. To do this, go to the global Preferences in Eclipse (Menu: Window > Preferences), navigate to Java > Code Style > Code Templates. Choose \"Code > New Java files\" and click on \"Edit...\". Paste there the following text: /* *********************************************************************** * * project: org.matsim.* * *********************************************************************** * * * * copyright : (C) ${ year } by the members listed in the COPYING, * * LICENSE and WARRANTY file. * * email : info at matsim dot org * * * * *********************************************************************** * * * * This program is free software; you can redistribute it and/or modify * * it under the terms of the GNU General Public License as published by * * the Free Software Foundation; either version 2 of the License, or * * (at your option) any later version. * * See also COPYING, LICENSE and WARRANTY file * * * * *********************************************************************** */ ${ filecomment } ${ package_declaration } ${ typecomment } ${ type_declaration } We use meaningful commit-messages Commit messages help to rule out quickly some revision of a file when looking for specific changes that, for example, may have introduced a bug in the code. Useless or empty commit messages make it more cumbersome, as the file itself must be looked at in each revision. Additionally, we write commit-messages (as well as comments in the code) in English, as development takes place in many different areas, and not only in german-speaking Countries. Do not commit personal test-data Use another repository if you want to version your personal test-data. We often work with data we are not allowed to share, and our code repository is open to anyone. It is a bad idea to store test-data in this repository, because sooner or later somebody will commit confidental data to the repository which cannot be removed! Some simple test-data is available in the directory examples , which is maintained by the core developers \u2013 please contact them if you want to add your own examples to this directory.","title":"Conventions"},{"location":"devguide/conventions/#coding-conventions","text":"For a project the size of MATSim, we need a minimal set of guidelines to insure the stability of MATSim and enable its further development. We try to keep this list as short as possible. We try to follow the Java Code Conventions This includes the Naming Conventions (Classes start with capital letters, variables with lowercase letters, ...), the usage of braces in if statements and other stuff. A notable exception are line lengths (we have no problem with lines up to 132 characters). Also, source code should only contain ASCII characters in code. Non-ascii in comments are ok; non-ascii in Strings should be avoided but sometimes cannot (e.g. file readers). More detailed Naming Conventions for MATSim are also available. Indentation MATSim Source code is indented with tabs, not spaces. Code is consistent and compiles! Code committed to the repository has to compile - always. If you want to try out some stuff, do it somewhere else or do not commit it. Classes in org.matsim.* do not reference other classes outside of the org.matsim.* -package except for classes provided by third-party libraries. Especially, org.matsim.* -classes must not reference tutorial and contrib -classes. All our code files have the MATSim-specific GPL-Header In Eclipse, you could add the header to the code template, so every new Java file has this header set by default. To do this, go to the global Preferences in Eclipse (Menu: Window > Preferences), navigate to Java > Code Style > Code Templates. Choose \"Code > New Java files\" and click on \"Edit...\". Paste there the following text: /* *********************************************************************** * * project: org.matsim.* * *********************************************************************** * * * * copyright : (C) ${ year } by the members listed in the COPYING, * * LICENSE and WARRANTY file. * * email : info at matsim dot org * * * * *********************************************************************** * * * * This program is free software; you can redistribute it and/or modify * * it under the terms of the GNU General Public License as published by * * the Free Software Foundation; either version 2 of the License, or * * (at your option) any later version. * * See also COPYING, LICENSE and WARRANTY file * * * * *********************************************************************** */ ${ filecomment } ${ package_declaration } ${ typecomment } ${ type_declaration } We use meaningful commit-messages Commit messages help to rule out quickly some revision of a file when looking for specific changes that, for example, may have introduced a bug in the code. Useless or empty commit messages make it more cumbersome, as the file itself must be looked at in each revision. Additionally, we write commit-messages (as well as comments in the code) in English, as development takes place in many different areas, and not only in german-speaking Countries. Do not commit personal test-data Use another repository if you want to version your personal test-data. We often work with data we are not allowed to share, and our code repository is open to anyone. It is a bad idea to store test-data in this repository, because sooner or later somebody will commit confidental data to the repository which cannot be removed! Some simple test-data is available in the directory examples , which is maintained by the core developers \u2013 please contact them if you want to add your own examples to this directory.","title":"Coding Conventions"},{"location":"devguide/custom-gui/","text":"Build a custom GUI runner \u00b6 Since version 0.8.0, MATSim comes with a simple GUI that starts upon double-clicking the matsim.jar file. The GUI requests a config file, and then lets users run a simulation by starting org.matsim.run.Controler with the specified config file as argument. Contribs are able to re-use the GUI infrastructure to provide a version of the GUI that starts their own, specialized Controler. How to create a GUI that runs a special class \u00b6 Prepare your main class that should be started to run your simulation: public class MySuperSimulation { public static void main ( String [] args ) { String configFilename = args [ 0 ] ; Controler controler = new Controler () ; // setup controler or do other custom stuff controler . run ( configFilename ) ; } } Create a new class, acting as the main class when double-clicking the jar-file. This class essentially only runs one command to start the GUI and specifies which main class should be started by the GUI: import org.matsim.run.gui.Gui ; public class MySuperSimulationGUI { public static void main ( String [] args ) { Gui . show ( \"MATSim: My Super Simulation\" , MySuperSimulation . class ); } } Modify the pom.xml in your contrib to include the following settings. Make sure to specify the correct class name for your GUI class. <build> <plugins> <plugin> <groupId> org.apache.maven.plugins </groupId> <artifactId> maven-jar-plugin </artifactId> <configuration> <archive> <manifest> <mainClass> org.matsim.contribs.mySuperContrib.MySuperSimulationGUI </mainClass> </manifest> </archive> </configuration> </plugin> </plugins> </build> And then, build a release. First, make sure that all required dependencies (including MATSim-core) are maven-installed, e.g. do mvn install -DskipTests=true for all required dependencies. Then change to the directory of your project, e.g. cd /path/to/matsim/contribs/mySuperContrib/ . Perform a Maven clean ( mvn clean ) first, followed by mvn -Prelease -DskipTests=true . This will result in a zip file in the target-directory which includes the clickable jar-file.","title":"Custom GUI"},{"location":"devguide/custom-gui/#build-a-custom-gui-runner","text":"Since version 0.8.0, MATSim comes with a simple GUI that starts upon double-clicking the matsim.jar file. The GUI requests a config file, and then lets users run a simulation by starting org.matsim.run.Controler with the specified config file as argument. Contribs are able to re-use the GUI infrastructure to provide a version of the GUI that starts their own, specialized Controler.","title":"Build a custom GUI runner"},{"location":"devguide/custom-gui/#how-to-create-a-gui-that-runs-a-special-class","text":"Prepare your main class that should be started to run your simulation: public class MySuperSimulation { public static void main ( String [] args ) { String configFilename = args [ 0 ] ; Controler controler = new Controler () ; // setup controler or do other custom stuff controler . run ( configFilename ) ; } } Create a new class, acting as the main class when double-clicking the jar-file. This class essentially only runs one command to start the GUI and specifies which main class should be started by the GUI: import org.matsim.run.gui.Gui ; public class MySuperSimulationGUI { public static void main ( String [] args ) { Gui . show ( \"MATSim: My Super Simulation\" , MySuperSimulation . class ); } } Modify the pom.xml in your contrib to include the following settings. Make sure to specify the correct class name for your GUI class. <build> <plugins> <plugin> <groupId> org.apache.maven.plugins </groupId> <artifactId> maven-jar-plugin </artifactId> <configuration> <archive> <manifest> <mainClass> org.matsim.contribs.mySuperContrib.MySuperSimulationGUI </mainClass> </manifest> </archive> </configuration> </plugin> </plugins> </build> And then, build a release. First, make sure that all required dependencies (including MATSim-core) are maven-installed, e.g. do mvn install -DskipTests=true for all required dependencies. Then change to the directory of your project, e.g. cd /path/to/matsim/contribs/mySuperContrib/ . Perform a Maven clean ( mvn clean ) first, followed by mvn -Prelease -DskipTests=true . This will result in a zip file in the target-directory which includes the clickable jar-file.","title":"How to create a GUI that runs a special class"},{"location":"devguide/data-in-source-repository/","text":"Data in the Source Reporsitory \u00b6 Some questions occurred about committing data to the MATSim project. To clarify what kind of data is allowed to commit and where to put it, here a short guideline: Only commit source files in src and its subdirectories. Do not commit any data files under src ! If you need to use data during the development and you want to keep that data on a save place, please use internal storages of you institution (e.g. internal SVN/Git repositories, internal shared folders, etc.) When you write JUnit test cases under test/src , you are allowed to add required data to test/input or test/scenario . Then please follow the following constraints: Use\u2014if possible\u2014already existing scenario data sets in test/scenario . Add only small data sets (some KBytes to max. 2 MBytes) to test/input or test/scenario . Note that bigger files may be compressed with gzip since MATSim supports reading and writing gzipped files with org.matsim.utils.io.IOUtils.getBufferedReader() and IOUtils.getBufferedWriter() respectively. Use artificial or falsified data in test cases and put them under test/input or test/scenario .","title":"Data in source repository"},{"location":"devguide/data-in-source-repository/#data-in-the-source-reporsitory","text":"Some questions occurred about committing data to the MATSim project. To clarify what kind of data is allowed to commit and where to put it, here a short guideline: Only commit source files in src and its subdirectories. Do not commit any data files under src ! If you need to use data during the development and you want to keep that data on a save place, please use internal storages of you institution (e.g. internal SVN/Git repositories, internal shared folders, etc.) When you write JUnit test cases under test/src , you are allowed to add required data to test/input or test/scenario . Then please follow the following constraints: Use\u2014if possible\u2014already existing scenario data sets in test/scenario . Add only small data sets (some KBytes to max. 2 MBytes) to test/input or test/scenario . Note that bigger files may be compressed with gzip since MATSim supports reading and writing gzipped files with org.matsim.utils.io.IOUtils.getBufferedReader() and IOUtils.getBufferedWriter() respectively. Use artificial or falsified data in test cases and put them under test/input or test/scenario .","title":"Data in the Source Reporsitory"},{"location":"devguide/development-environment/","text":"Getting and Building the Code \u00b6 In addition to the resources listed below, the Downloads page contains additional information about getting the source code of MATSim. Most people will only need the information in \"Using Eclipse\". Using Eclipse Build a custom GUI runner Run Eclipse with a JDK Working behind a Proxy","title":"Development environment"},{"location":"devguide/development-environment/#getting-and-building-the-code","text":"In addition to the resources listed below, the Downloads page contains additional information about getting the source code of MATSim. Most people will only need the information in \"Using Eclipse\". Using Eclipse Build a custom GUI runner Run Eclipse with a JDK Working behind a Proxy","title":"Getting and Building the Code"},{"location":"devguide/documenting-your-code/","text":"Documenting your Code \u00b6 Every public class should have the following items: For every class, a statement what it is meant for. For every class, a very rough description of what it does. For every class, the author should be specified with the @author-tag All these items should be written in a Javadoc block atop of the class.","title":"Documenting your code"},{"location":"devguide/documenting-your-code/#documenting-your-code","text":"Every public class should have the following items: For every class, a statement what it is meant for. For every class, a very rough description of what it does. For every class, the author should be specified with the @author-tag All these items should be written in a Javadoc block atop of the class.","title":"Documenting your Code"},{"location":"devguide/ide-configuration/","text":"IDE Configuration \u00b6 MATSim is developed by several persons on different platforms. So we need a basic set of settings to work successfully together. Namely, source code files should use UTF-8 as encoding and Unix-style line endings. Eclipse \u00b6 Text File Encoding \u00b6 In the Eclipse Preferences, please set the Text File Encoding to \"UTF-8\", and the New Text File Line Delimiter to \"Unix\" (in General > Workspace).","title":"IDE configuration"},{"location":"devguide/ide-configuration/#ide-configuration","text":"MATSim is developed by several persons on different platforms. So we need a basic set of settings to work successfully together. Namely, source code files should use UTF-8 as encoding and Unix-style line endings.","title":"IDE Configuration"},{"location":"devguide/ide-configuration/#eclipse","text":"","title":"Eclipse"},{"location":"devguide/ide-configuration/#text-file-encoding","text":"In the Eclipse Preferences, please set the Text File Encoding to \"UTF-8\", and the New Text File Line Delimiter to \"Unix\" (in General > Workspace).","title":"Text File Encoding"},{"location":"devguide/java/","text":"Java-related information \u00b6 MATSim is written in Java. While Java is widely known, from time to time we stumble over certain features or specialities we'd like to highlight. This is the place to collect interesting and informative stuff about Java which might (or might not) have some relation to our code. Problems with HashMap, HashSet and Iterator \u00b6 HashSet and HashMap do not specify in which order elements are iterated, possibly resulting in different results if the same code is run multiple times. This can lead to tests that randomly fail, further making debugging very hard. Use LinkedHashSet/LinkedHashMap instead. Those can be iterated over insertion order, leading to deterministic behavior. Random Numbers \u00b6 Introduction to random numbers \u00b6 Our simulations depend heavily on random numbers. But despite using random numbers, we still want the simulations to be deterministic, so that results can be reproduced by running the same scenario a second time. Usually, random numbers in Java are generated by calling Math.random() : double d = Math . random () ; While this method returns a random number, the number is indeed random such as that in a second run of the same scenario, other random numbers would result and the simulation would no longer be deterministic. To overcome this problem, an instance of java.util.Random can be generated and initialized with a custom random seed: Random random = new Random () ; random . setSeed ( 1234 ) ; ... double d = random . nextDouble () ; In this case, everytime the code is run, we get the same random numbers. As drawing random numbers is widely used in the code, MATSim offers a global instance of Random , which is automatically initialized with the seed specified in the configuration file: import org.matsim.core.gbl.MatsimRandom ; ... double d = MatsimRandom . random . nextDouble (); Choosing a random seed \u00b6 What value should be used as random seed? Is a value of 1 better than the value 86294 ? As both numbers have the same probability to be chosen in the range from 0 to Integer.MAX_VALUE , any value is equally good for a random seed. But this is only half of the story. We all know, that these random numbers are only pseudo-random\u2014and they depend on the chosen seed! Using Random numbers in PlanAlgorithms \u00b6 PlanAlgorithm s could be executed in parallel in multiple threads, e.g. during replanning. As the exact order of execution with multiple threads is not deterministic, the usage of MatsimRandom.random would lead to non-deterministic results. Instead, every instance of a PlanAlgorithm should have its own random number generator. The best way to realize that is that PlanAlgorithm s that use random numbers have a constructor where an object of type java.util.Random can be passed. When instantiating PlanAlgorithm s, one can use MatsimRandom.getLocalInstance() to obtain a Random -object that can be passed to the PlanAlgorithm . A Random object received by getLocalInstance() is already correctly initialized to return useful random numbers (see below). Problems when setting the random seed \u00b6 In our code, we set the random seed at the start of every iteration, so that we can restart a simulation at any iteration. The code was similar to the example code below: int baseSeed ; // the random seed specified in the configuration file ... for ( int iteration = 0 ; iteration < 1000; iteration++) { MatsimRandom . random . setSeed ( baseSeed + iteration ) ; ... } After running several iterations we realized that the first agent was never chosen for re-planning (remember, they get \"randomly\" chosen for re-planning). A little bit of research revealed that the first random number drawn after setting the random seed depends heavily on the random seed! Only a slight change in the random seed (in our case always +1 for each iteration) resulted in only a slight change in the value of the random number. The following figure shows the distribution of the first and second drawn random number after setting different random seeds. As can be clearly seen, the first drawn number only moves in a very small range. The second drawn numbers have a better distribution when the seed is only changed a little. distribution of random numbers with differrent random seed To overcome this problem, we decided that after setting a random seed, we draw one random number and immediately throw it away, as it seems not enough random.","title":"Java"},{"location":"devguide/java/#java-related-information","text":"MATSim is written in Java. While Java is widely known, from time to time we stumble over certain features or specialities we'd like to highlight. This is the place to collect interesting and informative stuff about Java which might (or might not) have some relation to our code.","title":"Java-related information"},{"location":"devguide/java/#problems-with-hashmap-hashset-and-iterator","text":"HashSet and HashMap do not specify in which order elements are iterated, possibly resulting in different results if the same code is run multiple times. This can lead to tests that randomly fail, further making debugging very hard. Use LinkedHashSet/LinkedHashMap instead. Those can be iterated over insertion order, leading to deterministic behavior.","title":"Problems with HashMap, HashSet and Iterator"},{"location":"devguide/java/#random-numbers","text":"","title":"Random Numbers"},{"location":"devguide/java/#introduction-to-random-numbers","text":"Our simulations depend heavily on random numbers. But despite using random numbers, we still want the simulations to be deterministic, so that results can be reproduced by running the same scenario a second time. Usually, random numbers in Java are generated by calling Math.random() : double d = Math . random () ; While this method returns a random number, the number is indeed random such as that in a second run of the same scenario, other random numbers would result and the simulation would no longer be deterministic. To overcome this problem, an instance of java.util.Random can be generated and initialized with a custom random seed: Random random = new Random () ; random . setSeed ( 1234 ) ; ... double d = random . nextDouble () ; In this case, everytime the code is run, we get the same random numbers. As drawing random numbers is widely used in the code, MATSim offers a global instance of Random , which is automatically initialized with the seed specified in the configuration file: import org.matsim.core.gbl.MatsimRandom ; ... double d = MatsimRandom . random . nextDouble ();","title":"Introduction to random numbers"},{"location":"devguide/java/#choosing-a-random-seed","text":"What value should be used as random seed? Is a value of 1 better than the value 86294 ? As both numbers have the same probability to be chosen in the range from 0 to Integer.MAX_VALUE , any value is equally good for a random seed. But this is only half of the story. We all know, that these random numbers are only pseudo-random\u2014and they depend on the chosen seed!","title":"Choosing a random seed"},{"location":"devguide/java/#using-random-numbers-in-planalgorithms","text":"PlanAlgorithm s could be executed in parallel in multiple threads, e.g. during replanning. As the exact order of execution with multiple threads is not deterministic, the usage of MatsimRandom.random would lead to non-deterministic results. Instead, every instance of a PlanAlgorithm should have its own random number generator. The best way to realize that is that PlanAlgorithm s that use random numbers have a constructor where an object of type java.util.Random can be passed. When instantiating PlanAlgorithm s, one can use MatsimRandom.getLocalInstance() to obtain a Random -object that can be passed to the PlanAlgorithm . A Random object received by getLocalInstance() is already correctly initialized to return useful random numbers (see below).","title":"Using Random numbers in PlanAlgorithms"},{"location":"devguide/java/#problems-when-setting-the-random-seed","text":"In our code, we set the random seed at the start of every iteration, so that we can restart a simulation at any iteration. The code was similar to the example code below: int baseSeed ; // the random seed specified in the configuration file ... for ( int iteration = 0 ; iteration < 1000; iteration++) { MatsimRandom . random . setSeed ( baseSeed + iteration ) ; ... } After running several iterations we realized that the first agent was never chosen for re-planning (remember, they get \"randomly\" chosen for re-planning). A little bit of research revealed that the first random number drawn after setting the random seed depends heavily on the random seed! Only a slight change in the random seed (in our case always +1 for each iteration) resulted in only a slight change in the value of the random number. The following figure shows the distribution of the first and second drawn random number after setting different random seeds. As can be clearly seen, the first drawn number only moves in a very small range. The second drawn numbers have a better distribution when the seed is only changed a little. distribution of random numbers with differrent random seed To overcome this problem, we decided that after setting a random seed, we draw one random number and immediately throw it away, as it seems not enough random.","title":"Problems when setting the random seed"},{"location":"devguide/naming-conventions/","text":"Naming Conventions \u00b6 We follow the Naming Conventions from Oracle's Java Code Conventions . Short version: Use CamelCase in general, with: Classes and Interfaces starting with uppercase letters Methods, packages and variables/members starting with lowercase letters Constants use all-uppercase letters together with underscores (\"_\"). Abbreviations should be avoided: getTravTime() >> getTravelTime() getDist() >> getDistance() Id is an abbreviation for Identifier, the 'd' is thus usually a lowercase letter. Factory methods are named create*() , e.g. createLink() . newLink() or other names should be avoided. Abstract classes should start with Abstract , e.g. AbstractPersonAlgorithm . Interfaces are not specially marked in their name, e.g. there is no pre- or suffix I like SomeInterfaceI . Default Implementations of interfaces end on Impl , if no more specific class-name is suitable, e.g. PlanImpl implements Plan .","title":"Naming conventions"},{"location":"devguide/naming-conventions/#naming-conventions","text":"We follow the Naming Conventions from Oracle's Java Code Conventions . Short version: Use CamelCase in general, with: Classes and Interfaces starting with uppercase letters Methods, packages and variables/members starting with lowercase letters Constants use all-uppercase letters together with underscores (\"_\"). Abbreviations should be avoided: getTravTime() >> getTravelTime() getDist() >> getDistance() Id is an abbreviation for Identifier, the 'd' is thus usually a lowercase letter. Factory methods are named create*() , e.g. createLink() . newLink() or other names should be avoided. Abstract classes should start with Abstract , e.g. AbstractPersonAlgorithm . Interfaces are not specially marked in their name, e.g. there is no pre- or suffix I like SomeInterfaceI . Default Implementations of interfaces end on Impl , if no more specific class-name is suitable, e.g. PlanImpl implements Plan .","title":"Naming Conventions"},{"location":"devguide/prefer-composition-and-delegation-over-inheritance/","text":"Prefer composition / delegation over inheritance \u00b6 Inheritance is not very robust \u00b6 There are numerous hints that inheritance is not very stable under refactoring; see, for example, Bloch, \"Effective Java\". The short version \u00b6 If you think you need to use inheritance, restrict it to a package. This can be achieved by making classes and methods only package-visible (no public/protected). Having it within a package makes the situation very local, and thus much better to manage. If you think you need to use inheritance beyond package limits, observe the following rule of thumb: Public or protected methods should be final or empty. (Which implies: If you are extending a class from elsewhere, you should make all of your public or protected methods final.) The long version \u00b6 The problem \u00b6 The problem has something to do with the sequence of program execution. Assume class Base { run () { partA (); partB (); } partA () { do1 (); do2 (); } partB () { do3 (); do4 (); } ... and some derived code class Derived extends Base { partA () { do1 (); doMyOwnStuff (); do2 (); } ... Now assume that the maintainer of the base class decides that do3() should be done before do2() . Thus (for example): class Base { ... partA () { do1 (); do3 (); do2 (); } partB () { do4 (); } ... Now the derived code will not execute do3() at all. One may argue that this is a consequence of bad design of the base class, e.g. that run() should call the doX() methods directly, or the designer should know beforehand in which sequence something needs to be done. In practice, these arguments do not work: Levels of abstraction are difficult to get right from the start; and there may be situations where sequences of execution originally do not matter, and when it later turns out that they matter, they may be in the wrong sequence. One may also argue that this is a consequence of bad design of the derived class, i.e. the programmer who overrides methods that have content should always call the super-method. That is class Derived extends Base { partA () { super . partA (); doMyOwnStuff (); } ... (Note that this is not the same thing as above.) However, the base class maintainers cannot enforce that class users (those who extend the base class) do this. One may argue that this is the problem of the class users, but in our setup test failures resulting from such issues are, as a tendency, the responsibility of the base class maintainer (since her or his code change broke the tests). Use delegation in Eclipse \u00b6 We therefore suggest to prefer composition (=delegation) over inheritance where this is possible. It is only possible when the class that one wants to inherit from implements an interface. In that case, the following is possible (with Eclipse): Write a class skeleton as follows: class MyClass implements XXXInterface { private XXXInterface delegate = new XXXImplementation (...); } In Eclipse, go to menu \"Source\"/\"Generate delegate methods\" and follow the instructions. [[Somebody please add a screenshot here. thanks. kai]] This will delegate all method calls to MyClass to the delegate. Now you can modify some of the delegate methods as you like. (This sometimes seems to provide less access than inheritance, but I don't think this is true as long as you assume that internal variables/fields are always private.) The typical example \u00b6 It is called \"composition\" since you can do this with more than one interface/delegate. The classical example is something like class MyCar implements HasSteering , HasBrakes , HasGears { private HasSteering steeringDelegate = new PowerSteering (...) ; private HasBrakes brakesDelegate = new SimpleBrakes (...) ; private HasGears gearsDelegate = new ElectronicGears (...) ; } where Eclipse's \"Generate delegate methods\" will produce methods such as public void steerToRight(double value) { steeringDelegate.steerToRight(value); } ... public void brake(double value) { brakesDelegate.brake(value); } As one can see, this now allows operations such as MyCar car ... ... car.brake(3.); car.steerToRight(0.3); that is, the car is now composed of its internals. Exposing the delegates \u00b6 In MATSim, we often expose the delegation, that is, the syntax is car.getBrakes().brake(3.); car.getSteering().steerToRight(0.3); This has the advantage that, if you extend the interfaces, you do not need to adapt every implementation. It is, clearly, not an option if you want to write a class (such as a PlanStrategy ) that is later inserted into the code \u2013 that has to fulfill the contract defined by the interface.","title":"Composition vs inheritance"},{"location":"devguide/prefer-composition-and-delegation-over-inheritance/#prefer-composition-delegation-over-inheritance","text":"","title":"Prefer composition / delegation over inheritance"},{"location":"devguide/prefer-composition-and-delegation-over-inheritance/#inheritance-is-not-very-robust","text":"There are numerous hints that inheritance is not very stable under refactoring; see, for example, Bloch, \"Effective Java\".","title":"Inheritance is not very robust"},{"location":"devguide/prefer-composition-and-delegation-over-inheritance/#the-short-version","text":"If you think you need to use inheritance, restrict it to a package. This can be achieved by making classes and methods only package-visible (no public/protected). Having it within a package makes the situation very local, and thus much better to manage. If you think you need to use inheritance beyond package limits, observe the following rule of thumb: Public or protected methods should be final or empty. (Which implies: If you are extending a class from elsewhere, you should make all of your public or protected methods final.)","title":"The short version"},{"location":"devguide/prefer-composition-and-delegation-over-inheritance/#the-long-version","text":"","title":"The long version"},{"location":"devguide/prefer-composition-and-delegation-over-inheritance/#the-problem","text":"The problem has something to do with the sequence of program execution. Assume class Base { run () { partA (); partB (); } partA () { do1 (); do2 (); } partB () { do3 (); do4 (); } ... and some derived code class Derived extends Base { partA () { do1 (); doMyOwnStuff (); do2 (); } ... Now assume that the maintainer of the base class decides that do3() should be done before do2() . Thus (for example): class Base { ... partA () { do1 (); do3 (); do2 (); } partB () { do4 (); } ... Now the derived code will not execute do3() at all. One may argue that this is a consequence of bad design of the base class, e.g. that run() should call the doX() methods directly, or the designer should know beforehand in which sequence something needs to be done. In practice, these arguments do not work: Levels of abstraction are difficult to get right from the start; and there may be situations where sequences of execution originally do not matter, and when it later turns out that they matter, they may be in the wrong sequence. One may also argue that this is a consequence of bad design of the derived class, i.e. the programmer who overrides methods that have content should always call the super-method. That is class Derived extends Base { partA () { super . partA (); doMyOwnStuff (); } ... (Note that this is not the same thing as above.) However, the base class maintainers cannot enforce that class users (those who extend the base class) do this. One may argue that this is the problem of the class users, but in our setup test failures resulting from such issues are, as a tendency, the responsibility of the base class maintainer (since her or his code change broke the tests).","title":"The problem"},{"location":"devguide/prefer-composition-and-delegation-over-inheritance/#use-delegation-in-eclipse","text":"We therefore suggest to prefer composition (=delegation) over inheritance where this is possible. It is only possible when the class that one wants to inherit from implements an interface. In that case, the following is possible (with Eclipse): Write a class skeleton as follows: class MyClass implements XXXInterface { private XXXInterface delegate = new XXXImplementation (...); } In Eclipse, go to menu \"Source\"/\"Generate delegate methods\" and follow the instructions. [[Somebody please add a screenshot here. thanks. kai]] This will delegate all method calls to MyClass to the delegate. Now you can modify some of the delegate methods as you like. (This sometimes seems to provide less access than inheritance, but I don't think this is true as long as you assume that internal variables/fields are always private.)","title":"Use delegation in Eclipse"},{"location":"devguide/prefer-composition-and-delegation-over-inheritance/#the-typical-example","text":"It is called \"composition\" since you can do this with more than one interface/delegate. The classical example is something like class MyCar implements HasSteering , HasBrakes , HasGears { private HasSteering steeringDelegate = new PowerSteering (...) ; private HasBrakes brakesDelegate = new SimpleBrakes (...) ; private HasGears gearsDelegate = new ElectronicGears (...) ; } where Eclipse's \"Generate delegate methods\" will produce methods such as public void steerToRight(double value) { steeringDelegate.steerToRight(value); } ... public void brake(double value) { brakesDelegate.brake(value); } As one can see, this now allows operations such as MyCar car ... ... car.brake(3.); car.steerToRight(0.3); that is, the car is now composed of its internals.","title":"The typical example"},{"location":"devguide/prefer-composition-and-delegation-over-inheritance/#exposing-the-delegates","text":"In MATSim, we often expose the delegation, that is, the syntax is car.getBrakes().brake(3.); car.getSteering().steerToRight(0.3); This has the advantage that, if you extend the interfaces, you do not need to adapt every implementation. It is, clearly, not an option if you want to write a class (such as a PlanStrategy ) that is later inserted into the code \u2013 that has to fulfill the contract defined by the interface.","title":"Exposing the delegates"},{"location":"devguide/proxy-configuration/","text":"Working behind a Proxy \u00b6 Things are getting a bit cumbersome if you are behind a proxy server. Apparently, Java ignores your system wide proxy settings (checked on Linux Mint 16, Windows Server 2008, Mac OS 10.9), that is, you need to configure each piece of software that is involved in your build process separately. Usually, this includes Eclipse and Maven. Eclipse \u00b6 Go to Preferences > General > Network Connections and enter your proxy settings. Set Active Provider to Manual . The Native option did never work for me (JI apr'14). Users report that one should leave the SOCKS field empty. You may need to restart Eclipse. Maven \u00b6 Edit your maven settings file (or create if not existing) ~/.m2/settings.xml to look like that: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <settings xmlns= \"http://maven.apache.org/SETTINGS/1.1.0\" xmlns:xsi= \"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation= \"http://maven.apache.org/SETTINGS/1.1.0 http://maven.apache.org/xsd/settings-1.1.0.xsd\" > <proxies> <proxy> <active> true </active> <protocol> http </protocol> <host> localhost </host> <port> 3128 </port> <nonProxyHosts> 127.0.0.1 </nonProxyHosts> </proxy> </proxies> </settings> If neccessary, add <username> and <password> fields (see also here ). Double check that Eclipse is using the correct settings file ( Preferences > Maven > User Settings ). NTLM Authentification \u00b6 Things are getting even worse, if you are behind a proxy that uses NTLM authentification (usually Windows based networks). As far as my experience goes (JI apr'14) none of the above java tools can talk to a NTLM based proxy. The only work around is to run a local NTLM-capable proxy on your machine that handles the authentification. There is cntlm which works flawlessly for me (JI apr'14), or Java NTLM Proxy and NTLMaps (both I have not tested).","title":"Proxy configuration"},{"location":"devguide/proxy-configuration/#working-behind-a-proxy","text":"Things are getting a bit cumbersome if you are behind a proxy server. Apparently, Java ignores your system wide proxy settings (checked on Linux Mint 16, Windows Server 2008, Mac OS 10.9), that is, you need to configure each piece of software that is involved in your build process separately. Usually, this includes Eclipse and Maven.","title":"Working behind a Proxy"},{"location":"devguide/proxy-configuration/#eclipse","text":"Go to Preferences > General > Network Connections and enter your proxy settings. Set Active Provider to Manual . The Native option did never work for me (JI apr'14). Users report that one should leave the SOCKS field empty. You may need to restart Eclipse.","title":"Eclipse"},{"location":"devguide/proxy-configuration/#maven","text":"Edit your maven settings file (or create if not existing) ~/.m2/settings.xml to look like that: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <settings xmlns= \"http://maven.apache.org/SETTINGS/1.1.0\" xmlns:xsi= \"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation= \"http://maven.apache.org/SETTINGS/1.1.0 http://maven.apache.org/xsd/settings-1.1.0.xsd\" > <proxies> <proxy> <active> true </active> <protocol> http </protocol> <host> localhost </host> <port> 3128 </port> <nonProxyHosts> 127.0.0.1 </nonProxyHosts> </proxy> </proxies> </settings> If neccessary, add <username> and <password> fields (see also here ). Double check that Eclipse is using the correct settings file ( Preferences > Maven > User Settings ).","title":"Maven"},{"location":"devguide/proxy-configuration/#ntlm-authentification","text":"Things are getting even worse, if you are behind a proxy that uses NTLM authentification (usually Windows based networks). As far as my experience goes (JI apr'14) none of the above java tools can talk to a NTLM based proxy. The only work around is to run a local NTLM-capable proxy on your machine that handles the authentification. There is cntlm which works flawlessly for me (JI apr'14), or Java NTLM Proxy and NTLMaps (both I have not tested).","title":"NTLM Authentification"},{"location":"devguide/using-generics/","text":"Using Generics \u00b6 Generics can be quite powerful, but also very cumbersome if used wrongly. Thus, respect the following rules: Using Generics: that's okay, e.g. when using the Java collection classes Providing Generics (i.e. introducing Generics in our own classes): only sparingly if you know exactly what you do. If you are not sure, do not use Generics!","title":"Using Generics"},{"location":"devguide/using-generics/#using-generics","text":"Generics can be quite powerful, but also very cumbersome if used wrongly. Thus, respect the following rules: Using Generics: that's okay, e.g. when using the Java collection classes Providing Generics (i.e. introducing Generics in our own classes): only sparingly if you know exactly what you do. If you are not sure, do not use Generics!","title":"Using Generics"},{"location":"devguide/eclipse/","text":"Using Eclipse \u00b6 The following sections explain how to install and setup Eclipse Mars (4.5, released June 2015) or newer to work with MATSim. Prerequisites \u00b6 You must have the following software installed and ready to use: Java 11 or newer To use MATSim, you need to have a Java SDK (JDK) installed and not only a Java Runtime Environment (JRE). Best is to download and install JDK 11 from adoptopenjdk.net . Eclipse Download Eclipse from eclipse.org , the package \"Eclipse IDE for Java Developers\" is enough for MATSim. Unzip the downloaded file and place it on some suitable location on your harddisk. Eclipse does not require any special installation. Experience shows that on Windows it's best to install Eclipse at a location that does not require administrative rights. Configure Eclipse Use UTF8 as File-Encoding . Make sure Eclipse is running from a JDK Configure Eclipse to use a JDK Cloning the MATSim project to Eclipse \u00b6 \"Cloning\" refers to the task of getting a copy of the MATSim source code from the server that keeps the most current and official source code version. The copy will be placed on your computer and allows you to work with the source code. To clone the MATSim source code to your computer, start Eclipse, then: choose menu File > Import\u2026 , and there Git > Projects from Git . Click Next . select Clone URI and click Next . Enter the following URI: https://github.com/matsim-org/matsim.git . Choose the master branch and click Next . Specify a location on your computer, where the source code should be saved. Eclipse makes a suggestion on where to put the data. It's okay to use that, but make sure you'll remember the location as we will need it later again! When you click on Next , Eclipse will start downloading the source code. Depending on your internet connection, this may take some minutes. After all the source code has been downloaded, Eclipse will ask you how to import the source code. Choose Import as general project and click Next . Name the project matsim-all . Important: Name it matsim-all , and not just \"matsim\" as proposed! You should now end up with a project matsim-all in Eclipse. Choose menu File > Import , then Maven > Existing Maven Projects . Click Next . Navigate to the directory, where you stored the MATSim source code (see some steps above). Once you've selected the right directory, it should list the matsim project, and all the contribs. Select the matsim project and those contribs that you need. If you are unsure, just start with the matsim project. These last two steps can be repeated any time when you need additional contrib. Click on Finish . Eclipse will now add the selected parts as projects to Eclipse. Depending on the number of contribs you selected, this might take a moment.","title":"Eclipse"},{"location":"devguide/eclipse/#using-eclipse","text":"The following sections explain how to install and setup Eclipse Mars (4.5, released June 2015) or newer to work with MATSim.","title":"Using Eclipse"},{"location":"devguide/eclipse/#prerequisites","text":"You must have the following software installed and ready to use: Java 11 or newer To use MATSim, you need to have a Java SDK (JDK) installed and not only a Java Runtime Environment (JRE). Best is to download and install JDK 11 from adoptopenjdk.net . Eclipse Download Eclipse from eclipse.org , the package \"Eclipse IDE for Java Developers\" is enough for MATSim. Unzip the downloaded file and place it on some suitable location on your harddisk. Eclipse does not require any special installation. Experience shows that on Windows it's best to install Eclipse at a location that does not require administrative rights. Configure Eclipse Use UTF8 as File-Encoding . Make sure Eclipse is running from a JDK Configure Eclipse to use a JDK","title":"Prerequisites"},{"location":"devguide/eclipse/#cloning-the-matsim-project-to-eclipse","text":"\"Cloning\" refers to the task of getting a copy of the MATSim source code from the server that keeps the most current and official source code version. The copy will be placed on your computer and allows you to work with the source code. To clone the MATSim source code to your computer, start Eclipse, then: choose menu File > Import\u2026 , and there Git > Projects from Git . Click Next . select Clone URI and click Next . Enter the following URI: https://github.com/matsim-org/matsim.git . Choose the master branch and click Next . Specify a location on your computer, where the source code should be saved. Eclipse makes a suggestion on where to put the data. It's okay to use that, but make sure you'll remember the location as we will need it later again! When you click on Next , Eclipse will start downloading the source code. Depending on your internet connection, this may take some minutes. After all the source code has been downloaded, Eclipse will ask you how to import the source code. Choose Import as general project and click Next . Name the project matsim-all . Important: Name it matsim-all , and not just \"matsim\" as proposed! You should now end up with a project matsim-all in Eclipse. Choose menu File > Import , then Maven > Existing Maven Projects . Click Next . Navigate to the directory, where you stored the MATSim source code (see some steps above). Once you've selected the right directory, it should list the matsim project, and all the contribs. Select the matsim project and those contribs that you need. If you are unsure, just start with the matsim project. These last two steps can be repeated any time when you need additional contrib. Click on Finish . Eclipse will now add the selected parts as projects to Eclipse. Depending on the number of contribs you selected, this might take a moment.","title":"Cloning the MATSim project to Eclipse"},{"location":"devguide/eclipse/jdk/","text":"Run Eclipse with a JDK \u00b6 Maven requires Eclipse using a JDK, i.e. Java Development Kit, instead of a Java Runtime Environment (JRE). The main difference is that a JDK also contains a Java Compiler and other tools to develop Java Code, while the JRE is only able to run compiled Java applications. To check with what Java version (JRE or JDK) Eclipse is running, do the following: Open the menu item Help > About Eclipse . (On the Mac, it's in the Eclipse-menu, not the Help-menu) Click on Installation Details . Switch to the tab Configuration Search for a line that starts with -vm . The line following it shows which Java binary is used. Depending on the name and location of the used Java binary one can figure out if a JRE or a JDK is used: If the path contains \"jre\" (e.g. as in C:\\Program Files\\Java\\jre6\\bin\\client\\jvm.dll ) it is a JRE If the path contains \"jdk\" (e.g. as in C:\\Program Files\\Java\\jdk1.6.0_31\\bin\\javaw.exe ) it is a JDK. If no JDK is used for Eclipse, change it: Quit Eclipse if it is running Go to the Eclipse installation directory and open the file eclipse.ini in a text editor. Search for the line -vmargs Before the line -vmargs , add two lines: On the first line, write -vm On the second line, write the path to your JDK installation (usually something like: C:\\Program Files\\Java\\jdk1.6.0_31\\bin\\javaw.exe on Windows)","title":"Eclipse JDK"},{"location":"devguide/eclipse/jdk/#run-eclipse-with-a-jdk","text":"Maven requires Eclipse using a JDK, i.e. Java Development Kit, instead of a Java Runtime Environment (JRE). The main difference is that a JDK also contains a Java Compiler and other tools to develop Java Code, while the JRE is only able to run compiled Java applications. To check with what Java version (JRE or JDK) Eclipse is running, do the following: Open the menu item Help > About Eclipse . (On the Mac, it's in the Eclipse-menu, not the Help-menu) Click on Installation Details . Switch to the tab Configuration Search for a line that starts with -vm . The line following it shows which Java binary is used. Depending on the name and location of the used Java binary one can figure out if a JRE or a JDK is used: If the path contains \"jre\" (e.g. as in C:\\Program Files\\Java\\jre6\\bin\\client\\jvm.dll ) it is a JRE If the path contains \"jdk\" (e.g. as in C:\\Program Files\\Java\\jdk1.6.0_31\\bin\\javaw.exe ) it is a JDK. If no JDK is used for Eclipse, change it: Quit Eclipse if it is running Go to the Eclipse installation directory and open the file eclipse.ini in a text editor. Search for the line -vmargs Before the line -vmargs , add two lines: On the first line, write -vm On the second line, write the path to your JDK installation (usually something like: C:\\Program Files\\Java\\jdk1.6.0_31\\bin\\javaw.exe on Windows)","title":"Run Eclipse with a JDK"},{"location":"extensions/","text":"MATSim Extensions \u00b6 Introduction \u00b6 The default MATSim releases contain all the functionality typically used to model agent behavior and simulate traffic. But sometimes, this just is not enough. The MATSim Extensions provide additional functionality for specific tasks, and can be used along MATSim. MATSim Extensions gives an overview of the currently available extensions. Please note that these extensions are usually provided and maintained by single persons from the community, and thus long-term support may vary from the default MATSim release. Using Extensions via Maven \u00b6 This is the recommended way for using extensions. See here under \"Maven\" about how to use MATSim via Maven. Note, in particular, the \"MATSim example project\". MATSim contribs (those extensions that are part of the contrib directory) can then just be used by adding them as additional dependencies in the pom.xml. Using Extensions \"manually\" \u00b6 This is not the recommended way for using extensions (see \"Using Extensions via Maven\" above). Downloading Extensions \u00b6 All extensions come as a compressed zip-file. You can either download the last stable release of an extension to be used together with the stable release of MATSim, or you can download a so-called \"nightly build\"\u2014an automatically created, but untested and probably unstable version of the extension. You can download the stable releases of extensions from the MATSim download page . Likely unstable nightly builds can be found from the same page. Make sure to also download MATSim itself. The extensions cannot be used without MATSim. Using Extensions on the Command Line \u00b6 Once you've downloaded an extension and MATSim, unzip the extension and place the extension's directory inside the MATSim directory, next to the libs directory. The file/directory structure should look similar to the following example: matsim/ + MATSim.jar + libs/ | + <lots of .jar files> + extension1/ | + extension1.jar +extension2/ | + extension2.jar | + libs/ <-- not all extensions contain additional libs | | + <one or more .jar files> Then, start your simulation with the extension.jar-file on the classpath along the MATSim jar-file, e.g: java -Xmx2000m -cp MATSim.jar:extension1/extension1.jar:extension2/extension2.jar org.matsim.contrib.RunXxxExample myConfig.xml On Windows, use ; instead of : to separate the different jar-files. Contributing Extensions \u00b6 See here for instructions.","title":"MATSim Extensions"},{"location":"extensions/#matsim-extensions","text":"","title":"MATSim Extensions"},{"location":"extensions/#introduction","text":"The default MATSim releases contain all the functionality typically used to model agent behavior and simulate traffic. But sometimes, this just is not enough. The MATSim Extensions provide additional functionality for specific tasks, and can be used along MATSim. MATSim Extensions gives an overview of the currently available extensions. Please note that these extensions are usually provided and maintained by single persons from the community, and thus long-term support may vary from the default MATSim release.","title":"Introduction"},{"location":"extensions/#using-extensions-via-maven","text":"This is the recommended way for using extensions. See here under \"Maven\" about how to use MATSim via Maven. Note, in particular, the \"MATSim example project\". MATSim contribs (those extensions that are part of the contrib directory) can then just be used by adding them as additional dependencies in the pom.xml.","title":"Using Extensions via Maven"},{"location":"extensions/#using-extensions-manually","text":"This is not the recommended way for using extensions (see \"Using Extensions via Maven\" above).","title":"Using Extensions \"manually\""},{"location":"extensions/#downloading-extensions","text":"All extensions come as a compressed zip-file. You can either download the last stable release of an extension to be used together with the stable release of MATSim, or you can download a so-called \"nightly build\"\u2014an automatically created, but untested and probably unstable version of the extension. You can download the stable releases of extensions from the MATSim download page . Likely unstable nightly builds can be found from the same page. Make sure to also download MATSim itself. The extensions cannot be used without MATSim.","title":"Downloading Extensions"},{"location":"extensions/#using-extensions-on-the-command-line","text":"Once you've downloaded an extension and MATSim, unzip the extension and place the extension's directory inside the MATSim directory, next to the libs directory. The file/directory structure should look similar to the following example: matsim/ + MATSim.jar + libs/ | + <lots of .jar files> + extension1/ | + extension1.jar +extension2/ | + extension2.jar | + libs/ <-- not all extensions contain additional libs | | + <one or more .jar files> Then, start your simulation with the extension.jar-file on the classpath along the MATSim jar-file, e.g: java -Xmx2000m -cp MATSim.jar:extension1/extension1.jar:extension2/extension2.jar org.matsim.contrib.RunXxxExample myConfig.xml On Windows, use ; instead of : to separate the different jar-files.","title":"Using Extensions on the Command Line"},{"location":"extensions/#contributing-extensions","text":"See here for instructions.","title":"Contributing Extensions"},{"location":"gallery/","text":"Scenario Gallery \u00b6 MATSim is used all over the world! Have a look how others use MATSim and in what regions they apply it. Learn what data they used and how they prepared their data and processed the output. Some scenario data is freely available. Have a look!","title":"Gallery"},{"location":"gallery/#scenario-gallery","text":"MATSim is used all over the world! Have a look how others use MATSim and in what regions they apply it. Learn what data they used and how they prepared their data and processed the output. Some scenario data is freely available. Have a look!","title":"Scenario Gallery"},{"location":"gallery/air-traffic/","text":"In this scenario, air traffic over Europe is simulated using MATSim. The model was created by VSP, TU Berlin based on data provided by OAG Aviation. It can be nicely seen how air traffic increases around 5:00 A.M. (GMT), which corresponds to 6 A.M. in most central European countries: the time the ban on night flights is lifted at many airports. The model is currently being improved to take capacity constraints at airports, like runway capacities, into account.","title":"Air Traffic over Europe"},{"location":"gallery/aliaga/","text":"{% include image.html image=page.image1 %} In this study, evacuation simulations are carried out for Aliaga, the industrial zone of Izmir, Turkey, where petro-chemical companies such as Petkim and Tupras are active. The scenario is based on an explosion in the acrylonitrile (ACN) factory in Petkim. The risk zone is determined considering the features of ACN, the wind speed and the direction of the wind. Simulations are executed via MATSim and a mesoscopic simulation software called Cube Avenue. The aim of using two simulation softwares is to be able to compare evacuation time estimates and to obtain reliable results from evacuation simulations which are crucial and critical in creating emergency plans. {% include image.html image=page.image2 %} Network is converted from OpenStreetMap and modified manually for both softwares. Three different scenarios have been identified for the evacuation simulation with an assumption that all evacuees are at home. The selection of these three scenarios is mainly based on the location of the destination zones and traffic demand. Free spaces which are close to the risk zone are designated as gathering-areas. The aim is to provide the arrival of evacuees to health care centers and gathering areas according to distance to explosion area, within a minimum time. The simulations based on these scenarios allow to choose the most useful scenario to be implemented in real case. Research Paper \u00b6 Evacuation plan of an industrial zone: Case study of a chemical accident in Aliaga, Turkey and the comparison of two different simulation softwares Safety Science, Volume 60, December 2013, Pages 123-130 Pelin Onelcin*, Mehmet Metin Mutlu, Yalcin Alver Department of Civil Engineering, Ege University, 35100 Bornova, Izmir, Turkey Paper Link","title":"Aliaga, Turkey"},{"location":"gallery/aliaga/#research-paper","text":"Evacuation plan of an industrial zone: Case study of a chemical accident in Aliaga, Turkey and the comparison of two different simulation softwares Safety Science, Volume 60, December 2013, Pages 123-130 Pelin Onelcin*, Mehmet Metin Mutlu, Yalcin Alver Department of Civil Engineering, Ege University, 35100 Bornova, Izmir, Turkey Paper Link","title":"Research Paper"},{"location":"gallery/berlin/","text":"Berlin, the capital of Germany, has more than 3 million inhabitants. Together with the people living in the surrounding Brandenburg area, a total population of nearly 6 million people is accounted for in this scenario, which covers an area of 150 x 250 kilometers. {% include image.html image=page.image1 %} A first approach for a model of Berlin was started in 2006. The road network used was originally developed by the planning department of the city of Berlin. It consists of more than 10,000 nodes and almost 30,000 links. As the scenario has its focus on the urban area of Berlin, this part of the region is represented with a much higher level of detail and accuracy than Brandenburg. The travel demand was based on intermediary output generated by the so called \"Kutter-Model\" for Berlin (also known as \"Berliner Personenverkehrs-Modell\"), an agent-based demand generation model. To speed up computational performance, only a 10% sample of car drivers was simulated, resulting in over 160,000 simulated agents. Due to problems with the input data, the scenario was only in use for a short time. In 2010, a new scenario for Berlin and its surroundings was created on behalf of the Berlin transit company BVG, together with PTV. This new model is based on extensive survey data for creating a good replication of the travel behaviour in the Berlin area. It also includes the complete public transit services (hundreds of bus lines, dozends of tram lines, trains, subways and even a few ferries). Based on that model, a forecasting model for 2015 was created.","title":"Berlin, Germany"},{"location":"gallery/caracas/","text":"{% include image.html image=page.image1 %} The commercial and industrial zone \"Los Ruices y Los Cortijos de Lourdes\" in Caracas is one of the most transited zones on the east side of the city. The network was created by using data from OpenStreetMap, but then manually modified (e.g. setting correct speed, capacity attributes) based on information delievered by a company doing a prior study in the same area. Demand was given in a O/D matrix by the same company, but only for the morning period. As the area researched is mainly a consuming zone in the morning, and a producing zone in the afternoon, the values from the O/D matrix were used to create dayplans for the agents. An initial departure around 7:30 time was assigned to the plans. Several scenarios with different replanning rates were run to test how much agents have to change their departure time in the morning such that the network can accomodate all of the travel demand. The screenshots above show how the traffic jam builds up in the scenario in which the simulated demand matches the values of real-world traffic counts best. The model and research was done by Daniel Ampuero Anca and Jes\u00fas Francisco G\u00f3mez Ort\u00edz during their Bachelor's study at Universidad Central de Venezuela. The work was tutored by Prof. H\u00e9ctor Navarro. Special thanks to URBISA SA and its founder \u00d3scar Anzola.","title":"Caracas, Venezuela"},{"location":"gallery/dakar/","text":"The modal of Dakar, Senegal, was created during the D4D challenge (Data for Development). The travel demand is created using mobile phone data, and simulated on a network extracted from OpenStreetMap (OSM). The process is implemented in a prototype software called SPOT (Spatial Planning simulation and Optimization Technologies), which uses MATSim for the traffic simulation. Additional information is available in: Serigne Gueye, Babacar M. Ndiaye, Didier Josselin, Michael Poss, Roger M. Faye, Philippe Michelon, Cyrille Genre-Grandpierre, and Francesco Ciari. Using mobile phone data for Spatial Planning simulation and Optimization Technologies (SPOT) Download PDF version of paper","title":"Dakar, Senegal"},{"location":"gallery/gauteng/","text":"Gauteng is the smallest province in South Africa, accounting for around 2% of the land surface, but contributes more than a third of the country's Gross Domestic Product (GDP). Due to high urbanization (the three metropolitan cities of Johannesburg, Tshwane (Pretoria) and Ekurhuleni form part of Gauteng) the province has around 11 million inhabitants. The scenario is currently built by researchers led by Prof. Johan W. Joubert at the Department of Industrial and Systems Engineering at the University of Pretoria in South Africa. The groundwork for the scenario was laid during a two-month stay of a Master student (Pieter J. Fourie) from South Africa in Berlin during 2008, where the essential steps of preparing the network, travel demand, and traffic counts for validation, were done. Network data and zonal information was imported from GIS Shapefiles. Travel demand is based on census information. In an initial step, only travelers commuting via private car were simulated, leading to the well-recognizable morning and evening rush hours. The model has since been extended ( Joubert et al., 2010 ) to include freight agent activity chains, allowing for traffic throughout the day. Recently the model was used to evaluate the impact of the Gauteng Freeway Improvement Project (GFIP) . Specifically, the South African National Roads Agency Limited (SANRAL) was interested in the MATSim capability to model detailed diversion patterns given different road pricing strategies. The video shown starts with the GFIP network shaded as gray. The road pricing scheme modelled here includes various discount structures, for example time-of-day, whether the vehicle is equipped with an eTag, public transport vehicles, and the vehicle class. The population for the toll diversion study included private cars (only home-work-home trips); commercial vehicles (complete activity chains as in Joubert et al., 2010 ); public transport vehicles and external traffic from the original Saturn model used by SANRAL. From the video one can see the peak spreading as a result of the toll. Specifically, there is an increase in the overall traffic across the province between 05:15 and 06:00 when the pre-peak discount for all vehicle classes ends. The major diversion from the GFIP network is expected from commercial vehicles, and specifically during off-peak periods (see 09:00 - 15:00). One of the reasons is that the secondary road network is less congested during the off-peak period, and is hence available to commercial vehicles as an alternative. Files Poster presented at Winter Simulation Conference (WSC) 2008 (PDF) Paper presented at Southern African Transport Conference 2010 (PDF)","title":"Gauteng, South Africa"},{"location":"gallery/germany/","text":"The video \u2014 make sure to watch it in HD on Vimeo \u2014 shows a sub-sample of 500K agents from the MATSim Germany national scenario for private car travel. The full scenario counts 4 million agents generated from a random realization of the national German travel survey (Mobilit\u00e4t in Deutschland 2008), calibrated against 2500 count stations and OD-flows of navigation devices. The network of major roads (360 K links) as well as more than 4 million activity locations are extracted from openstreetmap.org. The scenario consists of full-day travel plans with activities of type home, work, edu, shop, leisure and miscellaneous. Created by Johannes Illenberger, DB Mobility Logistics AG, Frankfurt am Main, Germany.","title":"Germany"},{"location":"gallery/ile_de_france/","text":"The MATSim model of \u00cele-de-France is open and reproducible. It is based entirely on open data and open software and can therefore be used by any researcher to start analyses on the synthetic population itself or on downstream MATSim simulations. The methodology is documented in detail in the following publication: H\u00f6rl, S. and M. Balac (2021) Synthetic population and travel demand for Paris and \u00cele-de-France based on open and publicly available data , Transportation Research Part C , 130 , 103291. Instructions on how to reproduce and run the simulations are available online on Github: An open synthetic population of \u00cele-de-France . While the scenario covers the \u00cele-de-France region around Paris, it can easily be adapted to other regions and cities of France. First attempts have been made for Toulouse and Lille.","title":"Open \u00cele-de-France, France"},{"location":"gallery/izmir/","text":"{% include image.html image=page.image1 %} A simulation for existing urban transportation, and three simulations for gulf crossing scenarios, for Izmir, Turkey are made using MATSim. Simulation results for existing urban transportation are compared to count station results to determine verification ratios. Simulation results for gulf crossing scenarios are used to determine the effects of different scenarios to existing traffic. {% include image.html image=page.image2 %} Road network is converted from OpenStreetMap and modified manually. Analyzed TAZs, land use and urban automobile traffic data is obtained from Izmir Metropolitan Municipality transportation master plan. Izmir urban traffic is distributed to 47 internal zones according to land use information. Best gulf crossing scenario is determined using simulation results, choosing the crossing which has minimum negative effects (increasing volume) to links which it is connected to and maximum positive effects (decreasing volume) to links which are at upper limits of their capacities, taking infrastructural investment requirements into consideration. Research paper \u00b6 MATSim-T Urban Traffic Simulation for Izmir, TURKEY. MUTLU, M. Metin, Graduation Thesis in Civil Engineering. Supervisor: ALVER, Yal\u00e7\u0131n, Assistant Prof. Dr., February 2010","title":"Izmir, Turkey"},{"location":"gallery/izmir/#research-paper","text":"MATSim-T Urban Traffic Simulation for Izmir, TURKEY. MUTLU, M. Metin, Graduation Thesis in Civil Engineering. Supervisor: ALVER, Yal\u00e7\u0131n, Assistant Prof. Dr., February 2010","title":"Research paper"},{"location":"gallery/joinville/","text":"Joinville is a mid-sized industrial city in the south of Brazil with around 550.000 inhabitants. It has a large workforce, including from its neighbouring cities. As it has an intense industrial activity profile, companies work often in three shifts, which cause peculiar traffic patterns. Besides this, it is common to have people with 12-hour routines considering work and higher education. The Joinville traffic model was built as an initial step of a project that intends to simulate the entire northeast region of Santa Catarina State, including air traffic, shipping, state highways and neighbouring cities. The aim of the project is a wide comprehension of people and freight movement on the region. The urban Joinville model is on its first version now and was produced as a graduation thesis at the Federal University of Santa Catarina (UFSC) , course of Transportation and Logistics Engineering . The scenario population was generated with data from the 2010 Brazilian census combined with demographic information from the city's travel survey. Travel demand was generated from the same travel survey. Both were designed to fit into MATSim using Tutorial classes (with some adaptations). The network was produced with vector data provided by the local Urban Sustainable Planning Institute of Joinville (IPPUJ). The data came as a shapefile with many connectivity problems. We were able to fix them using scripts in Python with the NetworkX module . Transforming was performed from the vector data into a graph, fixing the issues with the help of QGIS and finally writing as the MATSim XML network format. The facilities were produced from land-use data provided from the city government. For now the model runs only with cars. The model used a full sample of the population. From the available data we inferred 135.652 agents that did their routines by car, the rest were removed of the simulation. Figure 1 shows a screenshot of the Events using Via . {% include image.html image=page.image1 %} Figure 2 shows the comparison between simulated and count data for 20 links in the morning peak from 7 to 8 AM. The count data available for comparison is still sparse which could not provide us with a good measure of success. We know that calibration is needed for the next versions of the model. The good news is that the local authorities are installing over a hundred counting stations throughout the city within the next couple months and a new travel survey will be held this year. {% include image.html image=page.image2 %}","title":"Joinville, Brazil"},{"location":"gallery/munich/","text":"The MATSim scenarion for the Munich metropolitan area was set up during the year 2010. The goal is, among others, a simulation of local and global air pollutant and greenhouse gas emissions and how these levels change with respect to different policy measures. Network information from VISUM was linked to travel demand from different sources: an activity-based demand for inner-urban traffic came from the survey \"Mobility in Germany\" (MiD, 2002). Commuters and reverse commuters are modeled based on data provided by the German Federal Employment Office. Freight traffic is also introduced in the model by using data from the German Ministry for Transport. Emissions are calculated every time a vehicle leaves a street, and is dependent on the engine type, age, cubic capacity as well as the traffic state (free flow or stop & go). This video shows, for the city of Munich, a spatial distribution of NO2 exhaust emissions over time of day. Emission levels are calculated for every street and aggregated for 30 minutes time bins. Using a Gaussian smoothing function allows to identify areas with the highest emission levels. For publications related to the Munich scenario see here .","title":"Munich, Germany"},{"location":"gallery/padang/","text":"With MATSim it is possible to simulate large-scale evacuation scenarios. In a running project Last-Mile Evacuation we are developing an evacuation simulation for the Indonesian city of Padang, which faces a high risk of being hit by a tsunami. The estimated advance warning time before an earthquake-triggered tsunami reaches the shore line is about 30 minutes. That means the evacuation needs to be very fast. A realistic simulation of the evacuation process would help to give an estimate of the evacuation time, to detect bottlenecks in advance and to identify highly endangered areas, where a vertical evacuation seems the only way. The movie shows preliminary results of the evacuation simulation. The simulation starts 28 min before the tsunami reaches the shore line. It is assumed that all people are at home (\u201cevacuation at 3 a.m.\u201d).","title":"Padang, Indonesia"},{"location":"gallery/paris/","text":"The MATSim model of Paris was built by GeoTwin for the CityMakers challenge . Most of the data sources used for the model are available as OpenData, including network (from OpenStreetMap), population census, commuter matrix and travel diary. The model covers the city of Paris as well as parts of the surrounding region of \u00cele-de-France. About 10 mio. people live in the modelled area, of which a 10% sample was simulated. The model includes private cars, public transport, walk and bike (both teleportation-only), and also includes a fixed taxi-demand as well as freefloating car-sharing as technical proof-of-concepts for the aforementioned challenge. The model will be improved and expanded in the future to allow the planning of sophisticated new mobility patterns.","title":"Paris, France"},{"location":"gallery/poznan/","text":"Poznan, with its population of over 550,000, is the 5th largest city in Poland. Together with the neighbouring districts, it makes up an agglomeration of nearly 1 million people. The development of the MATSim scenario for the Poznan region began in 2012, with the primary goal of creating a 24-hour multi-agent simulation of the city and the surrounding districts. The road network was generated based on OpenStreetMap data and consists of over 13,600 nodes and over 32,000 links. The travel demand was derived from a static (1-hour morning peak) model created in PTV VISUM by the Poznan city planning department. The current version of the simulation covers the whole morning peak, 5 A.M. to 12 Noon. In parallel with the work on the Poznan model, there is ongoing research on dynamic taxi fleet routing. The process of dispatching taxis is carried out on-line. New requests may be submitted at any time and often no assumptions can be made about future demand. Moreover, since only historic approximations of travel times are known, trips may last longer or shorter than expected due to the day-to-day changes in traffic flow and the limited precision of the estimates themselves. The optimization algorithm dynamically reacts to changes in the current state concerning both supply and demand. Currently, in the first version of the simulation, there are 1,000 taxis (represented as light red rectangles in the video) moving around and serving 5000 taxi trips. Taxi trips are 2% of all 250,000 PrT trips during the morning peak.","title":"Poznan, Poland"},{"location":"gallery/quito/","text":"The Metropolitan District of Quito (DMQ) is Ecuador's capital where currently more than two million people are living. It has grown quickly in recent years, causing traffic congestion and pollution. Our research integrates evolutionary computation, public and private mobility and emission simulation and data mining tools to gain a better understanding of complex mobility problems in the city. The geographical area of study is the business district which covers approximately 5\u00d78 km2. A first scenario dealt with the optimization of 70 traffic signals with 20.000 agents moving in two main trips. The plans are designed so that all the agents move first from each home location to different points along the zone. The network comes from OpenStreetMap and includes the primary and secondary pathways, represented in total by 8192 links. The evolutionary algorithm (EA) together with MATSim found the optimal signal setting of the DMQ Scenario, minimizing average travel time. We implemented several genetic operators and designed and tested several experiments to find a proper configuration that allows fluid traffic flow through proper coordination between signals. Using data mining techniques, we group the optimal solutions in clusters. Finally, we analyze the effects of traffic signal settings in respect to the environmental impact using the output data from the MATSim emission module. {% include image.html image=page.image1 %} A second approach examines traffic density levels in urban transportation. The EA searches the combinations of a number of private/public transport users, capacity and headways of Bus Rapid Transit (BRT) of five main corridors on DMQ Scenario. The traffic density is influenced by the proportions of the population that use public (NPt) and private transportation and implies a bi-level optimization problem. Different proportions and configurations impact the traffic density, travel time and fuel consumption. Those criteria are in conflict with each other; we developed a framework to minimize simultaneously the three objectives, coupling a multi-objective EA with MATSim. {% include image.html image=page.image2 %} We acknowledge the support of Shinshu University (Japan) and Senescyt (Ecuador). Thanks to Senozon for the visualising software . Quito, Ecuador from MATSim page on Vimeo . More information about the scenario and the work can be found in the following publications: R. Armas, H. Aguirre and K. Tanaka, \u201cMulti-Objective Optimization of Level of Service in Urban Transportation\u201d, The Genetic and Evolutionary Computation Conference (GECCO) , Berlin, 2017, to appear. R. Armas, H. Aguirre, F. Daolio and K. Tanaka, \"An effective EA for short term evolution with small population for traffic signal optimization\", 2016 IEEE Symposium Series on Computational Intelligence (SSCI) , Athens, 2016, pp. 1-8. doi: 10.1109/SSCI.2016.7850099 R. Armas, H. Aguirre, F. Daolio and K. Tanaka, \"Traffic signal optimization and coordination using neighborhood mutation\", 2016 IEEE Congress on Evolutionary Computation (CEC) , Vancouver, BC, 2016, pp. 395-402. doi: 10.1109/CEC.2016.7743821 R. Armas, and H. Aguirre, 2016. Quito Metropolitan District. In: Horni, A, Nagel, K and Axhausen, K W. (eds.) The Multi-Agent Transport Simulation MATSim, pp. 473-476. London: Ubiquity Press. DOI: http://dx.doi.org/10.5334/baw.80 License: CC-BY 4.0 R. Armas, H. Aguirre, S. Zapotecas-Mart\u00ednez and K. Tanaka (2016) Traffic Signal Optimization: Minimizing Travel Time and Fuel Consumption. In: Bonnevay S., Legrand P., Monmarch\u00e9 N., Lutton E., Schoenauer M. (eds) Artificial Evolution. EA 2015. Lecture Notes in Computer Science, vol 9554. Springer, Cham R. Armas, H. Aguirre and K. Tanaka (2014) Effects of Mutation and Crossover Operators in the Optimization of Traffic Signal Parameters. In: Dick G. et al. (eds) Simulated Evolution and Learning. SEAL 2014. Lecture Notes in Computer Science, vol 8886. Springer, Cham","title":"Quito, Ecuador"},{"location":"gallery/santiago/","text":"Santiago, the capital city of Chile, has a total population of 6 million people in an area of 641 square kilometers, which makes it by far the most populated city of Chile. The city suffers from air pollution due to emissions from fixed and mobile sources, which particularly in the winter season concentrate in the Santiago Valley. The MATSim Santiago scenario was built upon three open data sources: Car network information from OpenStreetMap, Public transport supply data in Google Transit Feed Specification (GTFS), and Travel diaries from Santiago's 2012 Origin-Destination Survey. In its first part, the simulation video shows the activities of the 1% population being carried out in each time, where red dots represents \u201chome\u201d activities while blue dots represents \u201cwork\u201d, two of the most important ones. Secondly, the video shows the movement of the car and public transport vehicles along the network of the scenario. Different runnable versions of the scenario are available under https://svn.vsp.tu-berlin.de/repos/public-svn/matsim/scenarios/countries/cl/santiago/ . It is planned that the latest version will be continuously improved by MATSim community researchers. Recent improvements include: Usage of population expansion factors from the 2012 Origin-Destination Survey to generate a 1% and a 10% sample population. Randomizing activity locations of the expanded agents, using official land registry data. Generating more variability in the agents\u2019 trip start times, using smartcard transit data (known as Bip!). Integrating tolls on the tolled highways. Integrating shared taxis (colectivos) into the simulation. The scenario is typically calibrated with respect to modal split and traffic volumes using manual and automatic calibration methods. The sole use of open data sources and the continuous stepwise scenario improvement process makes MATSim Santiago one of the most complete scenarios that are freely available for researchers worldwide. It might become a role model for administrations all around the world to realize the power of open data initiatives when it comes to transparent decisionmaking and the stimulation of innovation activity in the private sector.","title":"Santiago, Chile"},{"location":"gallery/seoul/","text":"The MATSim model of Seoul Metropolitan was developed in 2012 as a result of long-term research collaboration between the University of Seoul (Prof. Seungjae Lee) & ETH Z\u00fcrich (Prof. Kay W. Axhausen), with additional support from Senozon. The model is updated on a yearly basis and the demand is generated based on 2012 Household Travel Survey Data (HHTSD). The study area covers the Seoul Metropolitan Area. A population synthesizer was developed to generate the MATSim input demand, based on HHTS 2012. Total population of SMA is 21.5 million; therefore, a 10% sample was generated and simulated (2.15 million agents). A detailed network of nodes and links was generated capturing all the details (16 384 nodes and 32 768 links) for railways, highways, arterials, pedestrians, expressways and bus-only lanes. A more detailed description of the scenario can be found in the MATSim book.","title":"Seoul, South Korea"},{"location":"gallery/singapore/","text":"The future cities laboratory (FCL) was established by ETH Zurich and Singapore's National Research Foundation (NRF). The FCL is a transdisciplinary research centre focused on urban sustainability, located in Singapore. As part of the research, a MATSim complete model for Singapore is being built. The following video shows the simulation output of the second MATSim model for Singapore. The initial demand modeling is based on diverse sources such as the Household Interview Travel Survey shared by Land Transport Authority (LTA), land use information from Urban Redevelopment Authority (URA), NAVTEQ and diverse web resources. The simulation covers both public and private transport and their interactions. This video is purely a product of research and has no immediate relevance to policy and planning. Pieter Fourie is responsible for the demand modeling, Sergio Ord\u00f3\u00f1ez took care of the network modeling, Michael van Eggermond collected the facilities data, Artem Chakirov tested the public transport simulation, Mohit Shah prepared the ERP, traffic count and special trip information and Lijun Sun investigated boarding and alighting process times, all coordinated by Alex Erath. We acknowledge LTA and URA for providing the underlying data and Senozon (senozon.com) for the visualising software. Additional videos of the MATSim model for Singapore can be found on FCL's Vimeo channel .","title":"Singapore"},{"location":"gallery/sioux-falls/","text":"{% include image.html image=page.image1 %} Advances in transport demand modeling require the use of well-known test scenarios --- demand and supply descriptions that allow rapid testing, demonstration and comparison of new algorithms, methods, and policies. A simplified road network based on the city of Sioux Falls, South Dakota, became very popular within the transport research community, as it was readily available. The conventional Sioux Falls scenario presents static origin-destination matrices, as presented in LeBlanc et al. (1975), and is unsuitable for agent-based simulation. Consequently, Chakirov and Fourie (2014) transformed the original scenario into an enriched, agent-based scenario with dynamic demand and an integrated public transport system. The new scenario therefore makes it possible to rapidly test the full feature set of the MATSim framework in an integrated fashion. The scenario aims to provide a realistic, fully dynamic demand with heterogeneous socio-demographic users and a high degree of spatial resolution. Real world survey and land-use data is used to generate a diverse synthetic population and accurate activity locations. The socio-demographic characteristics include age and sex on individual and income on household levels. Car ownership was assigned using the ordered probit model of Giuliano and Dargay (2006) . The assignment of home and work locations employs land-use and building information, census data from the City of Sioux Falls, South Dakota as well as commonly used static OD-matrices from LeBlanc et al. (1975) . It is important to note that the scenario does not aim to replicate the real City of Sioux Falls, SD, and remains a fictitious test-case scenario. The developers acknowledge the City of Sioux Falls GIS division for kindly proving data on the current land-use and Ihab Kaddoura and Benjamin Kickhoefer from TU Berlin, who provided feedback on potential bugs during the scenario generation and testing process. They also thank Prof. Kay Axhausen and Dr. Alexander Erath (IVT, ETH Zurich) for valuable input to the generation of this scenario. Where to find the scenario data \u00b6 The scenario data ships in MATSim XML format, ready to use, with every checkout of MATSim. See the Download section for details. After checking out, check matsim/examples/siouxfalls2014/config.xml to see where all the individual scenario components reside. The original tables used to generate the MATSim XML demand description, as well as the MATSim input data and the simulation results analyzed in Chakirov and Fourie (2014), can be found on the Transportation Test Problems page of the Ben-Gurion University of the Negev, maintained by Hillel Bar-gera.","title":"Sioux Falls, SD, USA"},{"location":"gallery/sioux-falls/#where-to-find-the-scenario-data","text":"The scenario data ships in MATSim XML format, ready to use, with every checkout of MATSim. See the Download section for details. After checking out, check matsim/examples/siouxfalls2014/config.xml to see where all the individual scenario components reside. The original tables used to generate the MATSim XML demand description, as well as the MATSim input data and the simulation results analyzed in Chakirov and Fourie (2014), can be found on the Transportation Test Problems page of the Ben-Gurion University of the Negev, maintained by Hillel Bar-gera.","title":"Where to find the scenario data"},{"location":"gallery/south-africa/","text":"In this example, we generated a synthetic population of commercial vehicles (mainly freight) on a national scale in South Africa. The activity chains were generated using a path-dependent complex network of connectivity (paper pending). The concept of using complex networks to describe commercial vehicle movement was originally addressed in Joubert & Axhausen (2013) .","title":"Freight in South Africa"},{"location":"gallery/sweden/","text":"The MATSim model for Sweden focuses on depicting long distance road transport in the country. It depicts both passenger and freight transport. The model has been set up by converting results of the two existing static models (SAMGODS for freight and SAMPERS for passengers) into MATSim demand. The network is OSM based and the public transport supply origins from GTFS. The primary goal of the model is to research the effects of a mass electrification of transport, including Electric Road Systems. But the model may also be used for different purposes. Currently, a ten percent version of the model is publicly available. It can be accessed via Github .","title":"Sweden"},{"location":"gallery/telaviv/","text":"The MATSim model for Tel Aviv, Israel, was built for a study exploring the possibility of integrating an operational activity-based model and a dynamic traffic assignment framework. It generates the travel demand directly from an activity-based model generated for the Tel Aviv area, without falling back to OD matrices. The Tel Aviv activity-based model system comprises a hierarchy of logit and nested logit models for the main stop of a tour, while intermediate stops are modeled conditionally on the basis of the main stop. The primary data source is the Israel National Travel Habits Survey from 1996. The network used was converted from a static EMME/2 model which exists for the modeled region. In the future, the model will be updated with improved secondary activity locations (shown last in the video) and location choice will be enabled in the simulation in order to try to achieve better travel time and travel distance distributions for secondary activities.","title":"Tel Aviv, Israel"},{"location":"gallery/toronto/","text":"MATSim in Greater Toronto Work on the GTA MATSim scenario started in fall 2008. Due to the availability of an agent-based demand generation model for the Greater Toronto area, the first scenario run in MATSim could be completed within one week of joint work of two Master students from Toronto with the MATSim groups in Berlin and Zurich. The road network was converted from an EMME/2 network, while the travel demand is based on the output of TASHA (Travel Activity Scheduler for Household Agents), an agent-based demand generation already available for the Greater Toronto area. The scenario is currently further improved by extending the information exchange between TASHA and MATSim. There are plans that TASHA may be used as a replanning module for MATSim in the future, allowing for sophisticated activity replanning. In 2011, work started to integrate the public transport services into the model.","title":"Toronto, Canada"},{"location":"gallery/usa-nationwide/","text":"This research is aimed at simulating road travel for the entire continental United States using agent-level activity profiles derived from smartphone-based geospatial big data. The expansive spatial scope of this work allows for the estimation of travel demand for an entire nation in one go. This work may be of value to transportation and planning agencies who are interested in estimating and predicting the system-wide travel demand. The above figure shows the nationwide road congestion at 9 AM EST. Most of the east coast in the United States is busy with activity and the same holds for the Central time zone. However, activity levels are only higher in the big population centers on the West Coast as it is 6 AM for them. Research paper \u00b6 Additional information can be found in the research paper : Sashikanth Gurram, Vijayaraghavan Sivaraman, Jonathan T. Apple, Abdul R. Pinjari. Agent-based modeling to simulate road travel using Big Data from smartphone GPS: An application to the continental United States . 2019. Abstract \u00b6 Growing concerns about urban sustainability, economic and public health vitality, and climate change are common features across the world. Transportation is often inextricably linked to these concerns and this necessitates the development of robust and scalable tools that can assist in timely understanding of the agent-system interactions. Such expedient but accurate analyses are critical for policymaking, especially in the current environment where urban mobility is witnessing a rapid transformation. To support such analyses, we demonstrate a novel methodology that implements a top-down large-scale agent-based simulation of urban travel using Global Positioning System (GPS) derived raw sightings. Specifically, we constructed the daily activity and travel patterns of devices (i.e. agents) using GPS data for a single day (Wednesday, March 6, 2019) for the entire continental United States. Data filtering techniques were applied to identify approximately 2.7 million smart devices (out of a daily total of 30.5 million) that were highly visible and mobile. We sourced roadway network data for the entire North America from Open Street Maps (OSM). We then fed the daily activity and travel records of agents along with the roadway network data into MATSim, an agent-based travel simulator, to produce highly spatiotemporally resolved agent activities along with their estimated travel trajectories. We processed these travel trajectories (1.5 billion records) to estimate vehicle miles traveled (VMT) for each U.S. state and modeled vehicle volumes per roadway link in the continental U.S. Overall, we found strong rank correlations between our results and Federal Highway Administration\u2019s VMT estimates, although absolute measures displayed a higher variability. We observed similar trends (i.e. low rank correlation errors but higher absolute errors) at the disaggregate roadway link level when comparing our extrapolated traffic volumes against roadway count station data from a select state (Florida). Finally, root mean squared error of our roadway volume estimates are comparatively similar to those for Florida\u2019s regionwide travel demand models indicating a satisfactory model performance. The proposed methodology in our study demonstrates that such big data-powered large-scale agent-based simulations may provide value in estimating and predicting travel demand.","title":"USA"},{"location":"gallery/usa-nationwide/#research-paper","text":"Additional information can be found in the research paper : Sashikanth Gurram, Vijayaraghavan Sivaraman, Jonathan T. Apple, Abdul R. Pinjari. Agent-based modeling to simulate road travel using Big Data from smartphone GPS: An application to the continental United States . 2019.","title":"Research paper"},{"location":"gallery/usa-nationwide/#abstract","text":"Growing concerns about urban sustainability, economic and public health vitality, and climate change are common features across the world. Transportation is often inextricably linked to these concerns and this necessitates the development of robust and scalable tools that can assist in timely understanding of the agent-system interactions. Such expedient but accurate analyses are critical for policymaking, especially in the current environment where urban mobility is witnessing a rapid transformation. To support such analyses, we demonstrate a novel methodology that implements a top-down large-scale agent-based simulation of urban travel using Global Positioning System (GPS) derived raw sightings. Specifically, we constructed the daily activity and travel patterns of devices (i.e. agents) using GPS data for a single day (Wednesday, March 6, 2019) for the entire continental United States. Data filtering techniques were applied to identify approximately 2.7 million smart devices (out of a daily total of 30.5 million) that were highly visible and mobile. We sourced roadway network data for the entire North America from Open Street Maps (OSM). We then fed the daily activity and travel records of agents along with the roadway network data into MATSim, an agent-based travel simulator, to produce highly spatiotemporally resolved agent activities along with their estimated travel trajectories. We processed these travel trajectories (1.5 billion records) to estimate vehicle miles traveled (VMT) for each U.S. state and modeled vehicle volumes per roadway link in the continental U.S. Overall, we found strong rank correlations between our results and Federal Highway Administration\u2019s VMT estimates, although absolute measures displayed a higher variability. We observed similar trends (i.e. low rank correlation errors but higher absolute errors) at the disaggregate roadway link level when comparing our extrapolated traffic volumes against roadway count station data from a select state (Florida). Finally, root mean squared error of our roadway volume estimates are comparatively similar to those for Florida\u2019s regionwide travel demand models indicating a satisfactory model performance. The proposed methodology in our study demonstrates that such big data-powered large-scale agent-based simulations may provide value in estimating and predicting travel demand.","title":"Abstract"},{"location":"gallery/vorarlberg/","text":"The Austrian Institute of Technology's (AIT) business unit Dynamic Transportation Systems (Mobility Department) has developed a new MATSim model for Vorarlberg, the westernmost state of Austria with a size of 2,600 km\u00b2 and about 380,000 inhabitants in 2015. The model area covers the whole state of Vorarlberg and takes into account the trips of all inhabitants. Freight transport and holiday traffic are excluded in the current model. The work has been developed within the project SmartCityRheintal , a research project funded by the Climate and Energy Fund Austria . The network graph has been derived from OpenStreetMap and enhanced using specialized methods to (1) make it routable and (2) provide each link with its specific parameters like capacity and free-flow speed. The population was generated based on the traffic survey \u201cMobilit\u00e4t in Vorarlberg 2013\u201d, the land use plan, and the places of interest (\"POI\") database of Vorarlberg, as well as sociodemographic data. To supply the agents\u2019 plans with a transport mode, an external mode choice model using a maximum likelihood approach was developed. The MATSim simulation of the existing situation was run twice, first with 10% and finally with 100% of the population. Based on this model, three scenarios were simulated with a 10% sample: (1) improvements in the public transport schedule, (2) traffic impacts of urban development projects, and (3) location and distribution of charging stations for e-mobility. The simulation video above includes 100% of the population of Vorarlberg and shows the motorized individual traffic of the basic model - without holiday traffic and commuters travelling to Vorarlberg from other regions. Each colored dot represents a single, simulated vehicle where the color green represents high velocity / free speed and red represents low velocity. Scenario description and video provided by Gernot Lenz, AIT, Mobility DTS Files SmartCityRheintal Endbericht Verkehrsmodell (german only)","title":"Vorarlberg, Austria"},{"location":"gallery/zurich/","text":"Zurich is the largest city of Switzerland with around 380,000 inhabitants (June 2008). More than 1 million people live in the metropolitan area of Zurich, which is much larger than the city itself, while Switzerland has a total population of about 7.5 million people. Zurich was one of the first real-world scenarios that was created for MATSim, as the development of MATSim itself started in Zurich. The scenario was later extended to cover all of Switzerland. Over the years, more and more data could be collected for Switzerland or Zurich, leading to improved scenarios for all of Switzerland as well as for Zurich. The newest Zurich scenario currently uses a Swiss regional planning network consisting of over 24,000 nodes and more than 60,000 unidirectional links, covering all of Switzerland as well as major European transit corridors. The travel demand is based on a synthetic population for Switzerland, generated out of different data (e.g. Swiss national census, micro census, enterprise census). All travellers have complete daily activity patterns, individual activity durations, and an initial mode choice. Simulation results can be compared to nearly 160 traffic counting stations in the region of Zurich, or over 500 such counting stations in whole Switzerland. In the simulation shown in the movie above, all travelers from the synthetic population of whole Switzerland were included that, when driving a car, would be at least once inside an imaginary boundary around Zurich during their day as part of their routing. The boundary is defined as a circle with radius 30 kilometres (around 18.6 miles) and with its center at \"Bellevue\", a central place in Zurich. In order to obtain a higher computational speed, a random 10% sample was chosen for simulation, resulting in 181,484 agents. Those agents could decide during the simulation if they travel with a car or make use of a non-car transportation mode. The movie starts with a general view of a large part of Switzerland, then zooming in to the Zurich metropolitan area, zooming further in to the city in the afternoon hours, and finally returning back to an overview of Switzerland in the evening hours. Each colored dot represents a single, simulated vehicle (green = high velocity, red = low velocity)","title":"Zurich, Switzerland"},{"location":"news/","text":"Latest MATSim News \u00b6 For older entries, see the News Archive to the left!","title":"Latest MATSim News"},{"location":"news/#latest-matsim-news","text":"For older entries, see the News Archive to the left!","title":"Latest MATSim News"},{"location":"news/2019-10-04-matsim-user-meeting/","text":"Dear MATSim community, this year the annual MATSim user meeting will be in Warsaw, Poland. The meeting occurs on April 6th, just a day before the ANT conference, which begins on Tuesday, April 7th. http://cs-conferences.acadiau.ca/ant-20/ We are now accepting submissions for the User Meeting from both Science and Industry. Submissions for the User Meeting should take the form of an abstract (< 1000 words), and are to be submitted before 29th February 2020, through EasyChair. MATSim-related submissions to the main conference will as well be considered for inclusion in the User Meeting program. Please feel free to forward this information to any of your contacts, by sharing the link to the EasyChair call for papers: https://easychair.org/cfp/matsim2020 Registration for the User Meeting will be announced in the close future. We are looking forward to seeing you in Warsaw! Thibaut Dubernet Stefano Penazzi","title":"Announcing MATSim User Meeting 2020: April 6th at ANT in Warsaw, Poland"},{"location":"news/2019-10-28-vrije-univ-brussels/","text":"The Vrije Universiteit Brussels has currently an open position for pursuing a PhD in the domain of freight transport with a strong focus on transport externalities. For details please see https://jobs.vub.be/job/Elsene-PhD-Scholarship-MOBI/563948201/ . For any possible questions you may contact me at Koen.Mommens@vub.be .","title":"Ph.D. at MOBI (Vrije Universiteit Brussel Belgium)"},{"location":"news/2019-11-25-tel-aviv-univ/","text":"The Geosimulation and Spatial Analysis Laboratory , Porter School of the Environment and Earth Sciences, Faculty of Exact Sciences, Tel Aviv University, Israel have an immediate open position for a postdoc expert in MATSim and Transportation Modeling. The position is for a period of 1.5-2 years with an annual scholarship of 16,500-20,500 euros, depending on the qualification. We are looking for a suitable candidate which holds a PhD on agent-based traffic modeling with the MATSim. The accepted candidate will join our team for building, calibration and validating A MATSim scenario for the Jerusalem metropolitan area based on cellular phone data and assessing the transportation future of Jerusalem. You will work at Tel Aviv, University, hand in hand with the transportation authority of Jerusalem. You should have: Technical experience and proficiency in Computer Science/Data Science/Statistics/Mathematics. Excellent JAVA/Object-oriented programming skills. Big data analysis. Experience with statistical analysis with R/ Stata/other . Experience with Geographic Information Systems and Agent-Based Modelling . MATSim experience (mandatory) . Bonuses: Fleet assignment, dispatching, pooling and optimizations (a bonus). Experience of mobile phone data analysis (a bonus) The Geosimulation lab is looking for a strongly motivated candidate who can work both independently and in a team. The applicant will actively participate in the different phases of the research process, from its conception to writing for publication. Excellent command of English is necessary. For any other inquires please contact Prof. Itzhak Benenson, bennya@tauex.tau.ac.il","title":"MATSim-related Post-Doc Position in Tel-Aviv University, Israel"},{"location":"news/2019-12-02-routing-mode/","text":"We (Kai Nagel, Gregor Leich) just merged the branch routingMode5 into the development head master branch ( https://github.com/matsim-org/matsim/pull/738 ). Summary: \u00b6 all legs now have an attribute \u201croutingMode\u201d the MainModeIdentifier is only used to retrofit old plans without routingMode (automatic in PrepareForSimImpl), it won\u2019t be used in ModeStatsControlerListener (overwrite AnalysisMainModeIdentifier instead) several helper walk modes such as \u201ctransit_walk\u201d, \u201cnon_network_walk\u201d, \u201caccess_walk\u201d, \u201cdrt_walk\u201d, \u201cdrt_fallback\u201d were replaced by normal TransportMode.walk (automatic retrofit in PrepareForSimImpl), more precisely by calls to the RoutingModule for TransportMode.walk. This replaced many custom *walk routers and will allow routing \u201cwalk\u201d over the network in the future. This is a pretty old topic ( https://matsim.atlassian.net/browse/MATSIM-26 ), partly solves several Jira issues, e.g. ( https://matsim.atlassian.net/browse/MATSIM-943 , https://matsim.atlassian.net/browse/MATSIM-856 , https://matsim.atlassian.net/browse/MATSIM-473 ) and makes life easier for intermodal trips. The content is our long-discussed \"routing mode\", i.e. that trips memorize the router from which they were generated. The prime example is a trip which currently may have mode transit_walk ; in the future, it would have mode walk and routing mode pt . This also means that \"MainModeIdentifier\" will no longer be necessary. (We will keep it to retrofit older plans files.) In general, we are not using non_network_walk or transit_walk or drt_walk . The reasoning is that teleported bicycle is bike , not non_network_bike , and we have always done it like that. In consequence, if the walk router called from, say, the pt router is a teleportation router, it will still return plain walk . The only exception is a network-based walk router: In that case, we indeed have non_network_walk access to the walk network, then a walk leg along the network, and a non_network_walk to the final destination. The implementation currently is via Attributable . Since there is no trip, we attach it to every leg. Trips that have inconsistent routing modes in their legs will lead to an error. We should probably consider to elevate the routing mode to a typed argument with a future population file. \u201cnon_network_walk\u201c will now only be used by the walk router if walk is routed over the network and only for access/egress to the walk network. It is some kind of fallback layer to access the network. All other modes can use the walk router to access the network. Per default the walk router is still a pure teleportation router NOT routing over the network. So in the end what was a non_network_walk \u2192 pt interaction \u2192 pt \u2192 pt interaction \u2192 non_network_walk trip will now per default be a walk \u2192 pt interaction \u2192 pt \u2192 pt interaction \u2192 walk trip with the plansCalcRoute and scoring parameters of walk !. Keep in mind that what was previously a direct walk \u201ctransit_walk\u201d is now a walk leg with routingMode pt and has the same scoring and plansCalcRoute parameters as walk with routingMode walk, so mode shift from one to the other does not necessarily mean a real change (that problem already existed before as the default for transit_walk was to copy parameters from walk). Similar issues apply to the other fallback modes ( drt_walk , drt_fallback ). Previously we had only the MainModeIdentifier which was used for two rather incompatible purposes (see https://matsim.atlassian.net/browse/MATSIM-26 for details): to identify the correct routing module to identify the main mode according to transportation planning. One example where this becomes clear are the somewhat weird \"main mode\" definition in the German travel survey ... which just has an arbitrary hierarchy for multi-modal trips. So this varies from country to country, and maybe even from survey to survey. We now split them up: is now explictly saved in the attribute routingMode ( and uses MainModeIdentifier for retrofitting old plans) AnalysisMainModeIdentifier binding, defaults to routingMode for backwards compatibility, but can be overwritten separately from MainModeIdentifier with something more useful for mode share analysis. This is only an analysis problem, you can now plug in an AnalysisMainModeIdentifier to fix this in analysis, e.g. overwrite the default with an hierachical MainModeIdentifier such as TransportPlanningMainModeIdentifier .","title":"Routing mode + (helper) walk modes"},{"location":"news/2019-12-02-routing-mode/#summary","text":"all legs now have an attribute \u201croutingMode\u201d the MainModeIdentifier is only used to retrofit old plans without routingMode (automatic in PrepareForSimImpl), it won\u2019t be used in ModeStatsControlerListener (overwrite AnalysisMainModeIdentifier instead) several helper walk modes such as \u201ctransit_walk\u201d, \u201cnon_network_walk\u201d, \u201caccess_walk\u201d, \u201cdrt_walk\u201d, \u201cdrt_fallback\u201d were replaced by normal TransportMode.walk (automatic retrofit in PrepareForSimImpl), more precisely by calls to the RoutingModule for TransportMode.walk. This replaced many custom *walk routers and will allow routing \u201cwalk\u201d over the network in the future. This is a pretty old topic ( https://matsim.atlassian.net/browse/MATSIM-26 ), partly solves several Jira issues, e.g. ( https://matsim.atlassian.net/browse/MATSIM-943 , https://matsim.atlassian.net/browse/MATSIM-856 , https://matsim.atlassian.net/browse/MATSIM-473 ) and makes life easier for intermodal trips. The content is our long-discussed \"routing mode\", i.e. that trips memorize the router from which they were generated. The prime example is a trip which currently may have mode transit_walk ; in the future, it would have mode walk and routing mode pt . This also means that \"MainModeIdentifier\" will no longer be necessary. (We will keep it to retrofit older plans files.) In general, we are not using non_network_walk or transit_walk or drt_walk . The reasoning is that teleported bicycle is bike , not non_network_bike , and we have always done it like that. In consequence, if the walk router called from, say, the pt router is a teleportation router, it will still return plain walk . The only exception is a network-based walk router: In that case, we indeed have non_network_walk access to the walk network, then a walk leg along the network, and a non_network_walk to the final destination. The implementation currently is via Attributable . Since there is no trip, we attach it to every leg. Trips that have inconsistent routing modes in their legs will lead to an error. We should probably consider to elevate the routing mode to a typed argument with a future population file. \u201cnon_network_walk\u201c will now only be used by the walk router if walk is routed over the network and only for access/egress to the walk network. It is some kind of fallback layer to access the network. All other modes can use the walk router to access the network. Per default the walk router is still a pure teleportation router NOT routing over the network. So in the end what was a non_network_walk \u2192 pt interaction \u2192 pt \u2192 pt interaction \u2192 non_network_walk trip will now per default be a walk \u2192 pt interaction \u2192 pt \u2192 pt interaction \u2192 walk trip with the plansCalcRoute and scoring parameters of walk !. Keep in mind that what was previously a direct walk \u201ctransit_walk\u201d is now a walk leg with routingMode pt and has the same scoring and plansCalcRoute parameters as walk with routingMode walk, so mode shift from one to the other does not necessarily mean a real change (that problem already existed before as the default for transit_walk was to copy parameters from walk). Similar issues apply to the other fallback modes ( drt_walk , drt_fallback ). Previously we had only the MainModeIdentifier which was used for two rather incompatible purposes (see https://matsim.atlassian.net/browse/MATSIM-26 for details): to identify the correct routing module to identify the main mode according to transportation planning. One example where this becomes clear are the somewhat weird \"main mode\" definition in the German travel survey ... which just has an arbitrary hierarchy for multi-modal trips. So this varies from country to country, and maybe even from survey to survey. We now split them up: is now explictly saved in the attribute routingMode ( and uses MainModeIdentifier for retrofitting old plans) AnalysisMainModeIdentifier binding, defaults to routingMode for backwards compatibility, but can be overwritten separately from MainModeIdentifier with something more useful for mode share analysis. This is only an analysis problem, you can now plug in an AnalysisMainModeIdentifier to fix this in analysis, e.g. overwrite the default with an hierachical MainModeIdentifier such as TransportPlanningMainModeIdentifier .","title":"Summary:"},{"location":"news/2019-12-05-matsim-news-now-on-github/","text":"The blog on Confluence is now deprecated. Due to continued breakages caused by Atlassian/Confluence changes, we\u2019ve decided to move the MATSim news blog directly onto the MATSim website. We have been mirroring these posts onto the website for a long time anyway, so now everything will be in one place. We continue to welcome MATSim-related news items, job postings, and event announcements. Now, you\u2019ll submit news by creating a pull request on Github.com with the content of your news item in Markdown format. Explicit directions for submitting news items: see https://matsim.org/submit-news And if those instructions aren\u2019t clear enough just let us know! Thank you! Hopefully this transition will be straightforward.","title":"MATSim news is now on matsim.org"},{"location":"news/2019-12-20-matsim-user-meeting-registration/","text":"Registration for the user meeting is now open on the page of the event , until February 27th, 2020. We encourage you to register at your earliest convenience, even if you do not yet know whether you will be able to come . This will help make sure we have enough seats and food for all participants, and you will have the possibility to pay only when you are sure to come.","title":"Registration for the User Meeting is now open"},{"location":"news/2020-01-13-jobPostSBB/","text":"The SBB business development team, located in Berne, Switzerland, is looking for a Simulation expert. The position has one focus on transport simulations, including MATSim, and their applications in strategical company planning. More information can be found here.","title":"Job Posting: Mobility Expert at SBB"},{"location":"news/2020-02-13-events-comparison-in-tests/","text":"There are many tests that at some point run EventsFileComparator.compare( filename1, filename2 ) I have now, somewhat as an experiment, added coordinates into the person arrival events. This will break the strict events comparison. I have therefore made the events comparison somewhat more flexible; you can now write new EventsFileComparator() .setIgnoringCoordinates(true) .runComparison(filename1, filename2) This will then ignore the coordinates in the comparison, and thus make the test pass again (if nothing else is broken). Since we are planning to play around a bit more with this (in the context of visualization), I would recommend to use this switch rather than replacing the reference events files.","title":"Events comparison in regression tests"},{"location":"news/2020-02-19-itm-seattle-2020/","text":"The organizers of the upcoming TRB Innovations in Travel Modeling conference reached out to me directly to solicit any MATSim-related \"late-breaking research\". They are keen to include MATSim on the program. Specifically there are some \"gaps\" in the content that they think MATSim talks could fill: New approaches for representing network supply Approaches to understanding and representing shared mobilities The organizers are considering a \"special issue\" of TRR (Transportation Research Record) so that submissions have a place to be published -- which is specifically being done to encourage academic contributions this time. More details below: Did you want to be on the program for the TRB Innovations in Travel Modeling Conference but didn't have anything to submit back when the call for content was out last summer? Are you working on something new and interesting that we should know about? Do you have \"something to say\" about one of these specific topics that we are building sessions around: Machine learning applications in travel analysis Approaches utilized for considering uncertainty in forecasts and case studies for the considering uncertainty in decision-making. Modeling methodologies to address dynamics in travel behavior and demand Approaches to understanding and representing shared mobilities Generalizable travel model construction methodologies and strategies New approaches for representing network supply Travel analysis and research workflow examples (aka we can be efficient and effective at our jobs) Travel analysis \"software stack\" examples (aka what tools do you use) A data standards that the industry should know about and use The Innovations in Travel Modeling Conference Planning Team is seeking limited content submissions thru March 3rd. Submissions can be made online at: https://forms.gle/KDkG9V6qJXdiTxQe6 These will have a quick turn-around in order to meet the Early Bird Registration Deadline of March 15th For more general conference information and to get your Early Bird Registration squared away, please visit the conference website . Cheers! Elizabeth Sall, on behalf of the TRB ITM 2020 Innovations in Travel Modeling Conference Planning Team","title":"TRB Innovations in Travel Modeling - call for late breaking research"},{"location":"news/2020-03-12-mum-cancelled/","text":"The MATSim User Meeting , which was to take place in Warsaw, Poland, on April 6th, had to be cancelled due to travel restrictions in the context of the containment measures for the current coronavirus outbreak. The date for the next user meeting is not fixed yet, and will be communicated in due time. We apologize for this inconvenience, and hope to see you again in the next user meetings.","title":"MATSim User Meeting Cancelled"},{"location":"news/2020-07-15-matsim-12-released/","text":"We released MATSim 12.0 last month, bringing various improvements and optimizations to MATSim. There were some API changes, e.g. how we handle undefined times. So if you write code yourself that uses MATSim, you might need to adapt it in some places when upgrading. Download the latest version of MATSim now!","title":"MATSim 12.0 released"},{"location":"news/2020-10-08-episim-berlin/","text":"Dear MATSim-Community, In this post we want to shortly present MATSim-EpiSim of the MATSim group in Berlin. Episim is an open source framework which can be used to simulate, based on MATSim events, an epidemic outbreak. In EpiSim we attach an infection model to the already existing mobility model. Agents can infect each other if they are simultaneously in the same facility or vehicle. If two agents have contact, the probability of infection depends on the following parameters: duration (comes directly from mobility model) contact intensity (depends on room size and air exchange) mask usage location: indoors or outdoors For COVID-19, EpiSim uses a disease progression model taken from literature. This means that an infected agent may transition to showing symptoms or requiring hospital or intensive care with certain probabilities and that agents can go into quarantine. EpiSim can be used to investigate the effects of non pharmaceutical interventions. These include the reduction of out-of-home activities (for example closing of schools), reduced use of public transport, wearing of masks, contact tracing and reduced disease import. Current simulation results for Berlin can be found here: https://covid-sim.info For more details, see the following preprint: https://doi.org/10.1101/2020.07.22.20160093 .","title":"EpiSim with MATSim"},{"location":"news/2020-10-08-open-positions-politechnique-montreal/","text":"MATSim Positions available at Polytechnique Montreal at the PhD/PostDoc level. Various topics available including: continuous calibration, integration of machine learning techniques, epidemic modeling. If interested please contact me at francesco.ciari@polymtl.ca","title":"MATSim Positions available at Polytechnique Montreal"},{"location":"news/2020-10-30-hermes/","text":"1. Introduction As means of transportation evolve, as the preferences of individuals change, and as the population increases, we need to understand what changes are required to our transportation networks in order to provide optimal service. One key element towards delivering this is large-scale simulation. However, the state-of-the-art tools we currently have at hand are unable to support such magnitudes (e.g. country-wide level such as Switzerland). For instance, using its default simulator, QSim, MATSim is expected to require roughly 116 days to carry out 1000 simulation iterations of Switzerland at 100% population. It is obvious that such execution times make large-scale scenarios impractical. After analyzing MATSim, we have found that the main scalability inhibitors are the data structures and algorithms in the simulation core, QSim. To this extent, we propose a novel, high-performance, scalable simulator for MATSim called Hermes. 2. Hermes Overview Hermes is a high-performance simulator which supports large-scale scenarios and repetitive what-if runs. It focuses on efficiently implementing the concepts behind transport simulation, and functions as an alternative to QSim. Figure 1 shows the new MATSim architecture with Hermes as its simulation core. Fig. 1: MATSim Architecture with the Hermes Simulator Hermes is built around one critical observation: in large-scale simulations, at every iteration, events are concentrated around a sparse set of areas in the graph. Hence, traversing the entire graph is wasteful. Hermes capitalizes on this point by exploiting an event-driven execution, where only the events taking place at a specific iteration are processed. This is in opposition to QSim's approach of processing each link and agent at each iteration. Hermes also introduces additional improvements, such as: optimized code paths for common events, optimized data structures, pre-computation and memoization, as well as efficient code which makes extensive use of primitive types. These features, together with the event-driven approach, enable Hermes to deliver efficient, large-scale simulations. It should be noted that Hermes does not compromise on extensibility, and allows users to plug in experimental events into the simulation. To the best of our knowledge, this is the only extension in the MATSim ecosystem which is both scalable and abides to the ecosystem's principles of extensibility and community-driven development. Quite notably, Hermes does not provide all the functionality that QSim has to offer, but focuses on the core, \"standard\" functionality. Different vehicle types and both private and public transport can be simulated in a similar way as with QSim. Special extensions such as dynamic vehicle routing, within-day replanning or traffic signals are however not supported. Nevertheless, a dual use of Hermes and QSim is in theory possible, where Hermes is used for some iterations and Qsim for others. 3. Hermes Architecture and Workflow Hermes' architecture consists of three main stages: Scenario Importer, Simulation Core, and Event Manager, as shown in Figure 1. We further describe what each stage does. Scenario Setup: Prepares the data structures used by the Simulation Core. These structures refer to the links that form the network, the agents that participate in the simulation, as well as other helpful data structures. Considering that an event defines what , when and how something happens in the network, and that we can readily extract the what and how from an agent plan, it follows that we can pre-compute all the events during the simulation by initially omitting the when . This latter piece of information is added at simulation time. Simulation Core: Performs the simulation itself using an event-driven algorithm. In its implementation, this stage employs a set of optimizations, which refer to: Avoiding Objectification, Avoiding Non-Contiguous Data Structures, Avoiding Polymorphism, and striving for Compact Hot-Code Paths . Event Processor: Processes events generated by the Simulation Core, and converts them to MATSim compatible structures. 4. Results Hermes has already been adopted by the SBB where it is being used in production. Here, we perform a simulation of Switzerland with 10% population (roughly 1M agents and 1.5M network links) over 301 iterations. We use a machine equipped with a Xeon Platinum 8168 (48 cores in total) at 2.70GHz, and 768GBs of RAM. Hermes uses 48 threads, while QSim uses 18 threads during simulation. Both simulations only use 130GBs of RAM. The average iteration time in Hermes is 3:33 minutes, while in QSim it is 8:45 minutes. This is a 2.5x speedup . The total simulation runtime is reduced by 40% , and is now dominated by MATSim's Replanning Step. Due to the differences in Hermes' and QSim's logic, the simulation results are not identical. These discrepancies are however very slight, and do not affect the overall quality of the results. For instance, transfer times and road congestion times in Hermes are marginally higher. Transportation mode distributions can also be subject to small differences, such as lower car usage in Hermes (around 1%), as can be seen in Figure 2. 5. Usage Hermes is part of the current MATSim snapshots and weekly releases and can be used out of the box by setting the \"mobsim\" parameter in the Controller Config-Group to \"hermes\". There is an additional Hermes Config Group, where some parameters should be set, many of them are similar to those in QSim: <module name=\"hermes\" > <!-- Simulation End Time --> <param name=\"endTime\" value=\"32:00:00\" /> <param name=\"flowCapacityFactor\" value=\"0.25\" /> <param name=\"mainMode\" value=\"car\" /> <param name=\"storageCapacityFactor\" value=\"0.25\" /> <!-- time in seconds. Time after which the frontmost vehicle on a link is called `stuck' if it does not move. Set to Integer.MAX_VALUE to disable this behavior --> <param name=\"stuckTime\" value=\"30\" /> <!-- treats PT as deterministic. PT vehicles will run with a steady speed according to their timetable. --> <param name=\"useDeterministicPt\" value=\"true\" /> </module> In addition to that, the event handling needs to be set to oneThreadPerHandler <module name=\"parallelEventHandling\" > \u2026 <param name=\"oneThreadPerHandler\" value=\"true\" /> \u2026 </module> Note: The FlowCapacityFactor setting should be set in accordance with the population sample size. The storageCapacityFactor might be set a little bit higher for small sample sizes (=< 10%). Hermes supports different vehicle types and PCUs. If PT is used on a congested network, the PCU equivalent for the transit vehicles should be defined in accordance with the sample size (i.e., for a 10% sample, a PT vehicle's PCUe should be set to 10%). For all other vehicles, an automatic scaling is performed. 6. Conclusions We have presented Hermes, a novel simulator for MATSim, which delivers high-performance and scalability using an event-driven design and numerous optimizations to the code and the data structures. We have shown Hermes' improved efficiency over QSim through production-level results. Moreover, Hermes is currently being successfully used in production by the SBB to simulate transportation networks within Switzerland. The simulator is currently integrated in MATSim, and is available via the latest weekly releases of MATSim 13 ( https://matsim.org/downloads/ ). 7. Acknowledgements We would like to thank the SBB for their generous support towards funding the project as part of the Mobility Initiative, and for the many fruitful discussions we have had the SBB Planning team. We would also like to thank Dr. Michel M\u00fcller (ETH), Dr. Marcel Rieser (SBB/Simunto), Prof. Gustavo Alonso (ETH), Prof. Torsten Hoefler (ETH) and Wolfgang Scherr (SBB) for their many contributions and ideas on this project.","title":"Introducing HERMES"},{"location":"news/2020-12-07-news-item/","text":"Under the project \u201cSustainable Transport Under Pandemic Context\u201d, University of Littoral has an immediate position for a postdoc researcher to work on MATsim. The project is related to transport modeling in the North of France with a focus on the improvement of calibration techniques and the implementation of epidemiological model. The position is for a period of 12 months with a net salary about 2,200 \u20ac per month. We are seeking a candidate who is familiar with agent-based traffic modelling, who have and experience with MATsim (or similar simulators). The selection will be based on the main criteria: technical skills in transport modeling, data gathering and processing (databases) model calibration output analysis and experience with MATsim (or similar tools) motivation to work on transport modeling familiarities with Java/Eclipse environment ability to process XML files Other criteria that will be considered: * skills in the manipulation of geographical information systems * big data and statistical analysis * knowledge of epidemiological models * experience with mathematical optimisation methods For more information please contact Prof Moez KILANI moez.kilani@univ-littoral.fr or Prof Daniel DE WOLF daniel.dewolf@univ-littoral.fr .","title":"Postdoc position"},{"location":"news/2021-01-05-ulco-murdasp/","text":"Under the project \u201cSustainable Transport Under Pandemic Context\u201d, University of Littoral has an immediate position for a postdoc researcher to work on MATsim. The project is related to transport modeling in the North of France with a focus on the improvement of calibration techniques and the implementation of epidemiological model. The position is for a period of 12 months with a net salary about 2,200 \u20ac per month. We are seeking a candidate who is familiar with agent-based traffic modelling, who have and experience with MATsim (or similar simulators). Selection criteria \u00b6 The selection will be based on the main criteria: technical skills in transport modeling, data gathering and processing (databases) model calibration output analysis and experience with MATsim (or similar tools) motivation to work on transport modeling familiarities with Java/Eclipse environment ability to process XML files Other criteria that will be considered: * skills in the manipulation of geographical information systems * big data and statistical analysis * knowledge of epidemiological models * experience with mathematical optimisation methods Contact \u00b6 For more information please contact Prof Moez KILANI moez.kilani@univ-littoral.fr or Prof Daniel DE WOLF daniel.dewolf@univ-littoral.fr .","title":"Postdoc position at University of Littoral (Dunkerque)"},{"location":"news/2021-01-05-ulco-murdasp/#selection-criteria","text":"The selection will be based on the main criteria: technical skills in transport modeling, data gathering and processing (databases) model calibration output analysis and experience with MATsim (or similar tools) motivation to work on transport modeling familiarities with Java/Eclipse environment ability to process XML files Other criteria that will be considered: * skills in the manipulation of geographical information systems * big data and statistical analysis * knowledge of epidemiological models * experience with mathematical optimisation methods","title":"Selection criteria"},{"location":"news/2021-01-05-ulco-murdasp/#contact","text":"For more information please contact Prof Moez KILANI moez.kilani@univ-littoral.fr or Prof Daniel DE WOLF daniel.dewolf@univ-littoral.fr .","title":"Contact"},{"location":"news/2021-02-10-matsim-user-meeting-2021/","text":"The recordings and presentations form the MATSim User Meeting 2021 are available at the IVT webpage . MATSim User Meeting 2021 will be organized as a virtual event on March 22, 2021. If you would like to present your work we invite you to submit a short abstract until 01.03. at: Abstract Submission Page We will try to accommodate all time zones and to give everyone a chance to present their work. All the updates regarding the Meeting will be published here. The attendance will be free of charge. For those that do not want to present, but are still interested to attend the meeting, please fill out this form: Non-presenter Registration Link The schedule can be downloaded from here . In case of questions please contact Milos Balac or Stefano Penazzi .","title":"MATSim User Meeting 2021"},{"location":"news/2021-04-12-matsim-13-released/","text":"MATSim 13.0 \u00b6 We're happy to announce the release of MATSim 13.0. Among many small changes and improvements, here are a few highlights of this release: SwissRailRaptor is now the default transit router. If you have enabled SwissRailRaptor yourself in the code (e.g. with controler.addOverridingModule(new SwissRailRaptorModule()); ), you should now remove this line as not to enable it twice. There is a new, faster routing algorithm names SpeedyALT available for network (e.g. car ) routing. It can be enabled in the config and used in place of Dijkstra , AStarLandmarks or any of the other existing routing algorithms. Adding Hermes, a faster alternative to QSim for some scenarios (Hermes does not support all features that QSim does). Vehicles can have attributes. Support for cordon toll was removed from road pricing. In addition, several contribs saw major work going on (e.g. the whole MAAS group: DRT, DVRP, ...), so if you are not yet on a recent weekly snapshot, make sure to upgrade to version 13.0 soon to benefit from all the work. To use the new version from your code as a Maven dependency, please note that you need to update the repository, as outlined in the next section. New Maven Repository \u00b6 For the last few years, we've hosted our jar-files in a Maven repository hosted by BinTray. Recently, BinTray announced that it shuts down its service for open source projects. We have thus migrated our MATSim releases to a new Maven repository. Please update your pom.xml to use the following repository: <repository> <!-- Repository for MATSim releases and snapshots (MATSim is not on Maven central) --> <id> matsim </id> <url> https://repo.matsim.org/repository/matsim </url> </repository> The two old repositories for releases ( dl.bintray.com/matsim/matsim ) and for snapshots ( https://oss.jfrog.org/libs-snapshot ) can be removed from the pom.","title":"MATSim 13.0 released, and new Maven Repository"},{"location":"news/2021-04-12-matsim-13-released/#matsim-130","text":"We're happy to announce the release of MATSim 13.0. Among many small changes and improvements, here are a few highlights of this release: SwissRailRaptor is now the default transit router. If you have enabled SwissRailRaptor yourself in the code (e.g. with controler.addOverridingModule(new SwissRailRaptorModule()); ), you should now remove this line as not to enable it twice. There is a new, faster routing algorithm names SpeedyALT available for network (e.g. car ) routing. It can be enabled in the config and used in place of Dijkstra , AStarLandmarks or any of the other existing routing algorithms. Adding Hermes, a faster alternative to QSim for some scenarios (Hermes does not support all features that QSim does). Vehicles can have attributes. Support for cordon toll was removed from road pricing. In addition, several contribs saw major work going on (e.g. the whole MAAS group: DRT, DVRP, ...), so if you are not yet on a recent weekly snapshot, make sure to upgrade to version 13.0 soon to benefit from all the work. To use the new version from your code as a Maven dependency, please note that you need to update the repository, as outlined in the next section.","title":"MATSim 13.0"},{"location":"news/2021-04-12-matsim-13-released/#new-maven-repository","text":"For the last few years, we've hosted our jar-files in a Maven repository hosted by BinTray. Recently, BinTray announced that it shuts down its service for open source projects. We have thus migrated our MATSim releases to a new Maven repository. Please update your pom.xml to use the following repository: <repository> <!-- Repository for MATSim releases and snapshots (MATSim is not on Maven central) --> <id> matsim </id> <url> https://repo.matsim.org/repository/matsim </url> </repository> The two old repositories for releases ( dl.bintray.com/matsim/matsim ) and for snapshots ( https://oss.jfrog.org/libs-snapshot ) can be removed from the pom.","title":"New Maven Repository"},{"location":"news/2021-04-26-PR-labelled-releases/","text":"PR-labelled releases \u00b6 In mid-April, we introduced PR-labelled releases (or shortly, PR releases). It basically means that every time a pull request (PR) is merged, a PR-labelled MATSim version is released. Their version ID is structured in the following way: ${matsim_version_id}-PR${pull_request_id} . The first PR-labelled version released is 14.0-PR1452 , which can be read as \"pre-release PR1452 of MATSim 14.0\" . The RP-labelled releases is a high-frequency (after every PR is merged), low-latency (< 10 minutes) release stream that allows you to stay in sync with the latest features introduced to MATSim without the need of relying on the snapshot releases (i.e. ${matsim_version_id}-SNAPSHOT , e.g. 14.0-SNAPSHOT ). Why to use PR releases? \u00b6 Using snapshot releases as dependencies is always risky. 14.0-SNAPSHOT is a moving target until it gets released as 14.0 (only then it becomes an immutable artifact). While depending on the snapshot version, you may experience situations when something that worked once may not work (or work differently) next time, because there have been some changes introduced to MATSim in the meantime. On the other hand, weekly releases, being immutable artifacts, are stable, but they are not released frequently enough for developers or users to stay in sync with the very latest changes in MATSim. The PR releases fill the gap between these two release types. Moreover, their high frequency of releasing simplifies analysing a potential impact of each individual PR on the project that uses MATSim. How to use PR releases? \u00b6 Since we have recently migrated our maven repository, this requires a few simple changes in pom.xml of any project that depends on MATSim. As an example, please have a look at commit c971f24 that switches the MATSim version ID from 13.0-SNAPSHOT to 14.0-PR1452 and changes the MATSim maven repository in the MATSim MaaS project. Weekly releases \u00b6 In addition to the new PR releases, you can still use the weekly releases (released every Monday). From week 17, 2021, we release them as non-snapshots, so their name will not be suffixed with -SNAPSHOT (e.g. 14.0-2021w17 instead of 14.0-2021w17-SNAPSHOT ). How to use weekly releases? \u00b6 If you want to use the latest weekly releases ( 2021w15-SNAPSHOT and newer), adjust the MATSim version ID and the repository accordingly ( similar to How to use PR releases? ). However, if you want to keep on using older weekly releases ( 2021w14-SNAPSHOT and older), you do not need to update anything (the old weekly releases are available from the old snapshot repository, hosted by jFrog). Improved CI build pipelines \u00b6 Since November 2020, we have been migrating the most time-critical continuous integration workflows to GitHub Actions. By doing so, we are now able to: verify each pushed commit in 15-30 min release the PR-labelled and snapshot versions in 5-10 min (after merging a PR) This should significantly improve your experiences in developing or using the new features in MATSim.","title":"PR-labelled releases"},{"location":"news/2021-04-26-PR-labelled-releases/#pr-labelled-releases","text":"In mid-April, we introduced PR-labelled releases (or shortly, PR releases). It basically means that every time a pull request (PR) is merged, a PR-labelled MATSim version is released. Their version ID is structured in the following way: ${matsim_version_id}-PR${pull_request_id} . The first PR-labelled version released is 14.0-PR1452 , which can be read as \"pre-release PR1452 of MATSim 14.0\" . The RP-labelled releases is a high-frequency (after every PR is merged), low-latency (< 10 minutes) release stream that allows you to stay in sync with the latest features introduced to MATSim without the need of relying on the snapshot releases (i.e. ${matsim_version_id}-SNAPSHOT , e.g. 14.0-SNAPSHOT ).","title":"PR-labelled releases"},{"location":"news/2021-04-26-PR-labelled-releases/#why-to-use-pr-releases","text":"Using snapshot releases as dependencies is always risky. 14.0-SNAPSHOT is a moving target until it gets released as 14.0 (only then it becomes an immutable artifact). While depending on the snapshot version, you may experience situations when something that worked once may not work (or work differently) next time, because there have been some changes introduced to MATSim in the meantime. On the other hand, weekly releases, being immutable artifacts, are stable, but they are not released frequently enough for developers or users to stay in sync with the very latest changes in MATSim. The PR releases fill the gap between these two release types. Moreover, their high frequency of releasing simplifies analysing a potential impact of each individual PR on the project that uses MATSim.","title":"Why to use PR releases?"},{"location":"news/2021-04-26-PR-labelled-releases/#how-to-use-pr-releases","text":"Since we have recently migrated our maven repository, this requires a few simple changes in pom.xml of any project that depends on MATSim. As an example, please have a look at commit c971f24 that switches the MATSim version ID from 13.0-SNAPSHOT to 14.0-PR1452 and changes the MATSim maven repository in the MATSim MaaS project.","title":"How to use PR releases?"},{"location":"news/2021-04-26-PR-labelled-releases/#weekly-releases","text":"In addition to the new PR releases, you can still use the weekly releases (released every Monday). From week 17, 2021, we release them as non-snapshots, so their name will not be suffixed with -SNAPSHOT (e.g. 14.0-2021w17 instead of 14.0-2021w17-SNAPSHOT ).","title":"Weekly releases"},{"location":"news/2021-04-26-PR-labelled-releases/#how-to-use-weekly-releases","text":"If you want to use the latest weekly releases ( 2021w15-SNAPSHOT and newer), adjust the MATSim version ID and the repository accordingly ( similar to How to use PR releases? ). However, if you want to keep on using older weekly releases ( 2021w14-SNAPSHOT and older), you do not need to update anything (the old weekly releases are available from the old snapshot repository, hosted by jFrog).","title":"How to use weekly releases?"},{"location":"news/2021-04-26-PR-labelled-releases/#improved-ci-build-pipelines","text":"Since November 2020, we have been migrating the most time-critical continuous integration workflows to GitHub Actions. By doing so, we are now able to: verify each pushed commit in 15-30 min release the PR-labelled and snapshot versions in 5-10 min (after merging a PR) This should significantly improve your experiences in developing or using the new features in MATSim.","title":"Improved CI build pipelines"},{"location":"news/2021-05-03-job-opening-moia/","text":"The mobility analytics & research section of MOIA is looking for a Transport Modeling/Simulation Specialist in Hamburg or Berlin. A focus of the position is the development and application of MATSim to develop MOIA's future ride-pooling system. More information can be found here .","title":"Job posting: Transport Modeling Specialist at MOIA"},{"location":"news/2021-05-27-research-assistant-covid19/","text":"[For English please see below] Bei der Technischen Universit\u00e4t Berlin ist die folgende Stelle zu besetzen: Wiss. Mitarbeiter*in (d/m/w) - Entgeltgruppe 13 TV-L Berliner Hochschulen Im Rahmen des BMBF-gef\u00f6rderten Projektes \u201eModellgest\u00fctzte Untersuchung von Schulschlie\u00dfungen und weiteren Ma\u00dfnahmen zur Eind\u00e4mmung von COVID-19\u201c. Teilzeitbesch\u00e4ftigung ist ggf. m\u00f6glich Fakult\u00e4t V - Institut f\u00fcr Land- und Seeverkehr / FG Verkehrssystemplanung und Verkehrstelematik Kennziffer: V-258/21 (besetzbar ab sofort / befristet bis 31.03.2024, Verl\u00e4ngerung wird angestrebt / Bewerbungsfristende 18.06.2021) Aufgabenbeschreibung: Mitarbeit im Forschungsprojekt MODUS-COVID. Zentraler Bestandteil des Forschungsprojektes ist die simulationsbasierte Untersuchung von Infektionsdynamiken im urbanen, regionalen und bundesweiten Kontext. Das Ziel ist dabei, die Reaktion der Infektionsdynamik auf unterschiedliche Eingriffe (z.B. Schulschlie\u00dfungen) zu prognostizieren und anschlie\u00dfend eine Bewertung der Wirksamkeit dieser Eingriffe vorzunehmen. Mitarbeit am Fachgebiet in Forschung sowie Unterst\u00fctzung der Lehre. Zusammenarbeit mit nationalen und internationalen Partnern. Erwartete Qualifikationen: Erforderlich: Erfolgreich abgeschlossenes wissenschaftliches Hochschulstudium (Master, Diplom oder \u00c4quivalent) im technisch-naturwissenschaftlichem Bereich. Organisationstalent, Kommunikationsf\u00e4higkeiten und Durchsetzungsverm\u00f6gen. Klar erkennbare strukturierte und prozessorientierte Arbeitsweise. Kenntnisse im Umgang mit Analysesoftware (z.B. R oder Python). Gute Deutsch- und Englischkenntnisse in Wort und Schrift. Gute analytische F\u00e4higkeiten, Teamf\u00e4higkeit. Interesse am Thema. Vorteilhaft: Erfahrungen im Umgang mit agentenbasierten Modellen und / oder epidemiologischen Modellen. Multidisziplin\u00e4re Ausrichtung. Erfahrungen mit Java, Versionierungs- und Shared-Programming-Infrastrukturen (z.B. Git) und / oder gr\u00f6\u00dferen Programmierprojekten. Eine Verl\u00e4ngerung nach Ende der Projektlaufzeit wird angestrebt. In Verbindung mit der ausgeschriebenen T\u00e4tigkeit ist die Durchf\u00fchrung einer Promotion m\u00f6glich und ausdr\u00fccklich erw\u00fcnscht. Die Ausschreibung richtet sich jedoch ausdr\u00fccklich auch an bereits promovierte Interessenten. Ihre Bewerbung richten Sie bitte unter Angabe der Kennziffer mit den \u00fcblichen Unterlagen (Lebenslauf, Schulabschlusszeugnisse, Studienabschlusszeugnisse, ggf. Arbeitszeugnisse) ausschlie\u00dflich per E-Mail in einem zusammengefassten pdf-Dokument an Prof. Dr. Nagel unter bewerbung@vsp.tu-berlin.de . Mit der Abgabe einer Onlinebewerbung geben Sie als Bewerber*in Ihr Einverst\u00e4ndnis, dass Ihre Daten elektronisch verarbeitet und gespeichert werden. Wir weisen darauf hin, dass bei ungesch\u00fctzter \u00dcbersendung Ihrer Bewerbung auf elektronischem Wege keine Gew\u00e4hr f\u00fcr die Sicherheit \u00fcbermittelter pers\u00f6nlicher Daten \u00fcbernommen werden kann. Datenschutzrechtliche Hinweise zur Verarbeitung Ihrer Daten gem. DSGVO finden Sie auf der Webseite der Personalabteilung oder Direktzugang: 214041. Zur Wahrung der Chancengleichheit zwischen Frauen und M\u00e4nnern sind Bewerbungen von Frauen mit der jeweiligen Qualifikation ausdr\u00fccklich erw\u00fcnscht. Schwerbehinderte werden bei gleicher Eignung bevorzugt ber\u00fccksichtigt. Die TU Berlin sch\u00e4tzt die Vielfalt ihrer Mitglieder und verfolgt die Ziele der Chancengleichheit. Technische Universit\u00e4t Berlin - Der Pr\u00e4sident - Fakult\u00e4t V, Institut f\u00fcr Land- und Seeverkehr, FG Verkehrssystemplanung und Verkehrstelematik, Prof. Dr. Nagel, Sekr. SG 12, Salzufer 17-19, 10587 Berlin Die Stellenausschreibung ist auch im Internet abrufbar unter: http://www.personalabteilung.tu-berlin.de/menue/jobs/ English Technische Universit\u00e4t Berlin offers an open position: Research Assistant - salary grade E13 TV-L Berliner Hochschulen In the context of the BMBF-funded project \"Model-supported investigation of school closures and further measures for the containment of COVID-19\". Part-time employment may be possible. Faculty V - Institute of Land and Sea Transport Systems / Transport Systems Planning and Transport Telematics Reference number: V-258/21 (starting at the earliest possible / limited until 31.03.2024, an extension of the contract is desired / closing date for applications 18/06/21) Working field: Collaboration in the MODUS-COVID research project. The central component of the research project is the simulation- based investigation of infection dynamics in an urban, regional and nationwide context. The goal is to predict the response of infection dynamics to different interventions (e.g., school closures) and subsequently evaluate the effectiveness of these interventions. Assisting the department in teaching and research. Collaborate with national and international partners. Requirements: Required: Successfully completed university degree (Master, Diplom or equivalent) in a technical/scientific field. Organizational talent, communication skills and assertiveness. Clearly recognizable structured and process-oriented way of working. Knowledge of using analytical software (e.g. R or Python). Good German and English skills, both written and spoken. Good analytical skills, ability to work in a team. Interest in the topic. Advantageous: Experience in working with agent-based models and / or epidemiological models. Multidisciplinary orientation. Experience with Java, versioning and shared programming infrastructures (e.g. Git) and / or larger programming projects. An extension of the contract after the end of the project duration is intended if possible. In connection with the advertised position, the completion of a PhD is possible and explicitly desired. However, the position is also explicitly directed at interested parties who already hold a doctorate. Please send your application with the reference number and the usual documents (curriculum vitae, A-level exam certificates, Diplom/Master certificate and, if applicable, references) only by email combined in a single pdf file to Prof. Dr. Nagel at bewerbung@vsp.tu-berlin.de . By submitting your application via email you consent to having your data electronically processed and saved. Please note that we do not provide a guaranty for the protection of your personal data when submitted as unprotected file. Please find our data protection notice acc. DSGVO (General Data Protection Regulation) at the TU staff department homepage or quick access 214041. To ensure equal opportunities between women and men, applications by women with the required qualifications are explicitly desired. Qualified individuals with disabilities will be favored. The TU Berlin values the diversity of its members and is committed to the goals of equal opportunities. Technische Universit\u00e4t Berlin - Der Pr\u00e4sident - Fakult\u00e4t V, Institut f\u00fcr Land- und Seeverkehr, FG Verkehrssystemplanung und Verkehrstelematik, Prof. Dr. Nagel, Sekr. SG 12, Salzufer 17-19, 10587 Berlin The vacancy is also available on the internet at http://www.personalabteilung.tu-berlin.de/menue/jobs/","title":"Research assistant/PhD candidate position at Transport Systems Planning and Transport Telematics, TU Berlin"},{"location":"news/2021-05-27-research-position-bmvi/","text":"[For English please see below] Bei der Technischen Universit\u00e4t Berlin ist folgende Stelle zu besetzen: Wiss. Mitarbeiter*in (d/m/w) - Entgeltgruppe 13 TV-L Berliner Hochschulen Teilzeitbesch\u00e4ftigung ist ggf. m\u00f6glich Fakult\u00e4t V - Institut f\u00fcr Land- und Seeverkehr / FG Verkehrssystemplanung und Verkehrstelematik **Kennziffer: V-280/21** (besetzbar ab sofort / befristet bis 31.12.2023, Verl\u00e4ngerung wird angestrebt / Bewerbungsfristende 18.06.2021) Aufgabenbeschreibung Wissenschaftliche Mitarbeit im Rahmen des BMVI-gef\u00f6rderten Projektes \u201eImplementierung eines wetterunabh\u00e4ngigen und hochautomatisierten Ridesharing-Dienstes unter Anwendung von KI im Landkreis Kelheim als Erg\u00e4nzung zum regionalen \u00d6PNV und zur Erm\u00f6glichung von Mobilit\u00e4t f\u00fcr eine erweiterte Zielgruppe Teilvorhaben: Simulationsgest\u00fctzte Untersuchung von Verkehrs- und Umweltwirkungen\u201c. Koordination des obigen Forschungsprojektes. Mitarbeit am Fachgebiet in Forschung sowie Unterst\u00fctzung der Lehre. Zusammenarbeit mit nationalen und internationalen Partnern. In Verbindung mit der ausgeschriebenen T\u00e4tigkeit ist die Durchf\u00fchrung einer Promotion m\u00f6glich und ausdr\u00fccklich erw\u00fcnscht. Die Ausschreibung richtet sich jedoch ausdr\u00fccklich auch an bereits promovierte Interessenten. Erwartete Qualifikationen: Erfolgreich abgeschlossenes wissenschaftliches Hochschulstudium (Diplom, Master oder \u00c4quivalent) in Verkehrswesen, Wirtschaftsingenieurwesen oder Wirtschaftswissenschaften oder vergleichbar. Organisationstalent, Kommunikationsf\u00e4higkeiten und Durchsetzungsverm\u00f6gen. Klar erkennbare strukturierte und prozessorientierte Arbeitsweise. Kenntnisse im Bereich der Verkehrsplanung. Kenntnisse im Umgang mit Analysesoftware (z.B. R oder Python). Sehr gute Deutschkenntnisse in Wort und Schrift. Gute Englischkenntnisse in Wort und Schrift. Gute analytische F\u00e4higkeiten, Teamf\u00e4higkeit. Interesse am Thema. Vorteilhaft Erfahrungen mit Simulationen. Multidisziplin\u00e4re Ausrichtung. Erfahrungen mit Java, Versionierungs- und Shared-Programming-Infrastrukturen (z.B. Git) und / oder gr\u00f6\u00dferen Pro- grammierprojekten. Ihre Bewerbung richten Sie bitte unter Angabe der Kennziffer mit den \u00fcblichen Unterlagen (Lebenslauf, Schulabschlusszeugnisse, Studienabschlusszeugnisse, ggf. Arbeitszeugnisse) ausschlie\u00dflich per E-Mail in einem zusammengefassten pdf-Dokument an Prof. Dr. Nagel \u00fcber bewerbung@vsp.tu-berlin.de . Mit der Abgabe einer Onlinebewerbung geben Sie als Bewerber*in Ihr Einverst\u00e4ndnis, dass Ihre Daten elektronisch verarbeitet und gespeichert werden. Wir weisen darauf hin, dass bei ungesch\u00fctzter \u00dcbersendung Ihrer Bewerbung auf elektronischem Wege keine Gew\u00e4hr f\u00fcr die Sicherheit \u00fcbermittelter pers\u00f6nlicher Daten \u00fcbernommen werden kann. Datenschutzrechtliche Hinweise zur Verarbeitung Ihrer Daten gem. DSGVO finden Sie auf der Webseite der Personalabteilung oder Direktzugang: 214041. Zur Wahrung der Chancengleichheit zwischen Frauen und M\u00e4nnern sind Bewerbungen von Frauen mit der jeweiligen Qualifikation ausdr\u00fccklich erw\u00fcnscht. Schwerbehinderte werden bei gleicher Eignung bevorzugt ber\u00fccksichtigt. Die TU Berlin sch\u00e4tzt die Vielfalt Ihrer Mitglieder und verfolgt die Ziele der Chancengleichheit. Technische Universit\u00e4t Berlin - Der Pr\u00e4sident - Fakult\u00e4t V, Institut f\u00fcr Land- und Seeverkehr, FG Verkehrssystemplanung und Verkehrstelematik, Sekr. SG 12, Salzufer 17-19, 10587 Berlin Die Stellenausschreibung ist auch im Internet abrufbar unter: http://www.personalabteilung.tu-berlin.de/menue/jobs/ ENGLISH Technische Universit\u00e4t Berlin offers an open position: Research assistant - salary grade E 13 TV-L Berliner Hochschulen part-time employment may be possible. Faculty V - Institute of Land and Maritime Transport / Chair of Transport System Planning and Transport Telematics Reference number: V-280/21 (starting at the earliest possible / limited until 31/12/2023, prolongation is disired / closing date for applications 18/06/21) Working field: Research in the context of the BMVI-funded project \"Implementation of a weather-independent and highly automated ridesharing service using AI in the district of Kelheim as a complement to regional public transport and to enable mobility for an extended target group subproject: Simulation-based investigation of traffic and environmental impacts\". Coordination of the aforementioned research project. Assisting the department in teaching and research. Collaboration with national and international partners. In connection with this position, the completion of a PhD is possible and explicitly desired. However, the position is also explicitly directed at interested parties who already hold a doctorate. Requirements: Successfully completed university degree (Diplom, Master or equivalent) in transport planning, industrial engineering, economics or comparable. Organizational talent, communication skills and assertiveness. Clearly identifiable structured and process-oriented approach to work. Knowledge in the field of transportation planning. Competent with analytical programming languages (e.g. R or Python). Very good knowledge of German, both written and spoken. Good English skills, both written and spoken. Good analytical skills, team spirit. Interest in the topic. Desirable Experience with simulations. Multidisciplinary orientation. Experience with Java, versioning and shared programming infrastructures (e.g. Git) and / or larger programming projects. Please send your application with the reference number and the usual documents (curriculum vitae, A-level exam certificates, Diplom/Master certificate and, if applicable, references) only by e-mail in one summarized pdf document to Prof. Dr. Nagel via bewerbung@vsp.tu-berlin.de . By submitting your application via email you consent to having your data electronically processed and saved. Please note that we do not provide a guaranty for the protection of your personal data when submitted as unprotected file. Please find our data protection notice acc. DSGVO (General Data Protection Regulation) at the TU staff department homepage or quick access 214041. To ensure equal opportunities between women and men, applications by women with the required qualifications are explicitly desired. Qualified individuals with disabilities will be favored. The TU Berlin values the diversity of its members and is committed to the goals of equal opportunities. Technische Universit\u00e4t Berlin - Der Pr\u00e4sident - Fakult\u00e4t V, Institut f\u00fcr Land- und Seeverkehr, FG Verkehrssystemplanung und Verkehrstelematik, Sekr. SG 12, Salzufer 17-19, 10587 Berlin The vacancy is also available on the internet at http://www.personalabteilung.tu-berlin.de/menue/jobs/","title":"Research assistant/PhD candidate position at Transport Systems Planning and Transport Telematics, TU Berlin"},{"location":"news/2021-05-27-research-position-v/","text":"[For English please see below] Im Rahmen verschiedener Forschungsprojekte im Umfeld der Verkehrsmodellierung mit MATsim suchen wir Verst\u00e4rkung f\u00fcr unser Team. Wiss. Mitarbeiter*in (d/m/w) - Entgeltgruppe 13 TV-L Berliner Hochschulen Teilzeitbesch\u00e4ftigung ist ggf. m\u00f6glich Fakult\u00e4t V - Institut f\u00fcr Land- und Seeverkehr / FG Verkehrssystemplanung und Verkehrstelematik Kennziffer: V-279/21 (besetzbar ab sofort / befristet bis 31.03.2024, Verl\u00e4ngerung wird angestrebt / Bewerbungsfristende 18.06.2021) Aufgabenbeschreibung: Mitarbeit nach Interesse in verschiedenen Forschungsprojekten im Bereich der Modellierung von CO2-freiem Verkehr, autonomen Fahrzeugen und Virusdynamik. Mitarbeit am Fachgebiet in Forschung sowie Unterst\u00fctzung der Lehre. Weiterentwicklung von Multiagentensimulationsmodellen in MATSim. Zusammenarbeit mit nationalen und internationalen Partnern. In Verbindung mit der ausgeschriebenen T\u00e4tigkeit ist die Durchf\u00fchrung einer Promotion m\u00f6glich und ausdr\u00fccklich erw\u00fcnscht. Erwartete Qualifikationen: Erfolgreich abgeschlossenes wissenschaftliches Hochschulstudium (Diplom, Master oder \u00c4quivalent) in Planung und Betrieb im Verkehrswesen oder vergleichbar oder Wirtschaftsingenieurwesen oder Informatik. Erfahrungen mit Simulationswerkzeugen. Gute Programmierkenntnisse, vorzugsweise in Java. Gute Englisch- oder Deutschkenntnisse in Wort und Schrift. Gute analytische F\u00e4higkeiten, Teamf\u00e4higkeit. Interesse am Thema. Erw\u00fcnscht: Erfahrungen im Umgang mit der Simulationssoftware MATSim. Erfahrungen mit der Benutzung von Versionierungs- und Shared-Programming-Infrastrukturen, z.B. Git/GitHub oder SVN. Erfahrungen mit gr\u00f6\u00dferen Programmierprojekten. Kenntnisse bzgl. der Kalibrierung von Simulationsszenarien. Multidisziplin\u00e4re Ausrichtung. Ihre Bewerbung richten Sie bitte unter Angabe der Kennziffer mit den \u00fcblichen Unterlagen (Lebenslauf, Schulabschlusszeugnisse, Studienabschlusszeugnisse, ggf. Arbeitszeugnisse) ausschlie\u00dflich per E-Mail in einem zusammengefassten pdf-Dokument an Prof. Dr. Nagel \u00fcber bewerbung@vsp.tu-berlin.de . Mit der Abgabe einer Onlinebewerbung geben Sie als Bewerber*in Ihr Einverst\u00e4ndnis, dass Ihre Daten elektronisch verarbeitet und gespeichert werden. Wir weisen darauf hin, dass bei ungesch\u00fctzter \u00dcbersendung Ihrer Bewerbung auf elektronischem Wege keine Gew\u00e4hr f\u00fcr die Sicherheit \u00fcbermittelter pers\u00f6nlicher Daten \u00fcbernommen werden kann. Datenschutzrechtliche Hinweise zur Verarbeitung Ihrer Daten gem. DSGVO finden Sie auf der Webseite der Personalabteilung oder Direktzugang: 214041. Zur Wahrung der Chancengleichheit zwischen Frauen und M\u00e4nnern sind Bewerbungen von Frauen mit der jeweiligen Qualifikation ausdr\u00fccklich erw\u00fcnscht. Schwerbehinderte werden bei gleicher Eignung bevorzugt ber\u00fccksichtigt. Die TU Berlin sch\u00e4tzt die Vielfalt Ihrer Mitglieder und verfolgt die Ziele der Chancengleichheit. Technische Universit\u00e4t Berlin - Der Pr\u00e4sident - Fakult\u00e4t V, Institut f\u00fcr Land- und Seeverkehr, FG Verkehrssystemplanung und Verkehrstelematik, Sekr. SG 12, Salzufer 17-19, 10587 Berlin Die Stellenausschreibung ist auch im Internet abrufbar unter: http://www.personalabteilung.tu-berlin.de/menue/jobs/ English: In the context of various research projects in the field of traffic modeling with MATSim, we are looking for a reinforcement for our team. Research assistant - salary grade E 13 TV-L Berliner Hochschulen part-time employment may be possible. Faculty V - Institute of Land and Maritime Transport / Chair of Transport System Planning and Transport Telematics Reference number: V-279/21 (starting at the earliest possible / limited until 31/03/2024, prolongation is disired / closing date for applications 18/06/21) Working field: Collaboration in various research projects in the field of modeling CO2-free traffic, autonomous vehicles and virus dynamics. Assisting the department in research as well as teaching. Further development of multi-agent simulation models in MATSim. Collaboration with national and international partners. In connection with the advertised position, the completion of a doctorate is possible and expressly desired. Requirements: Successfully completed university degree (Diplom, Master or equivalent) in transport planning or similar, industrial engineering or computer science. Experience with simulation tools. Good programming skills, preferably in Java. Good English or German language skills, both written and spoken. Good analytical skills. Team spirit. Interest in the topic. Desirable: Experience in using the simulation software MATSim. Experience with using versioning and shared programming infrastructures, e.g. Git/GitHub or SVN. Experience with larger programming projects. Knowledge regarding calibration of simulation scenarios. Multidisciplinary orientation. Please send your application with the reference number and the usual documents (curriculum vitae, A-level exam certificates, Diplom/Master certificate and, if applicable, references) only by e-mail in one summarized pdf document to Prof. Dr. Nagel via bewerbung@vsp.tu-berlin.de . By submitting your application via email you consent to having your data electronically processed and saved. Please note that we do not provide a guaranty for the protection of your personal data when submitted as unprotected file. Please find our data protection notice acc. DSGVO (General Data Protection Regulation) at the TU staff department homepage or quick access 214041. To ensure equal opportunities between women and men, applications by women with the required qualifications are explicitly desired. Qualified individuals with disabilities will be favored. The TU Berlin values the diversity of its members and is committed to the goals of equal opportunities. Technische Universit\u00e4t Berlin - Der Pr\u00e4sident - Fakult\u00e4t V, Institut f\u00fcr Land- und Seeverkehr, FG Verkehrssystemplanung und Verkehrstelematik, Sekr. SG 12, Salzufer 17-19, 10587 Berlin The vacancy is also available on the internet at http://www.personalabteilung.tu-berlin.de/menue/jobs/","title":"Research assistant/PhD candidate position at Transport Systems Planning and Transport Telematics, TU Berlin"},{"location":"news/2021-06-08-research-position/","text":"Estimating traffic-related energy consumption and pollutant emissions is a complex problem that is relevant for a wide range of problems, from planning to operations. In particular, energy efficiency and pollution metrics play a fundamental role in the environmental impact assessment of new technologies, such as smart cities or connected, cooperative, and autonomous mobility, in order to evaluate new algorithms or the impact of upcoming products. Besides the characteristics of the road network, the key role in determining these environmental metrics is played by the speed trajectories followed by the vehicles in the network. Most of existing methods provide only mean-value estimations per road-link. However, mean speed is largely insufficient to capture the dynamic behavior that is responsible for local peaks and affects substantially the total amount. Therefore instantaneous speed profile (ISP) estimation is needed on the various road-links that compose the road network considered. The approach proposed consists of (i) generating mobility data with a \u201cmesoscopic\u201d traffic simulator (MATSim) using a limited amount of publicly available information, (ii) using the average speed/flows calculated as the input of an ISP estimator, (iii) evaluating the ISP per road-link fulfilling these averages and satisfying spatial and time correlation. Overall, the proposed approach would fill the existing gap between macroscopic data and instantaneous/local consumptions and emissions. Once the coupling made, possible applications of the approach should be tested. To this purpose, a case study shall be defined, modeled, and analyzed. A baseline scenario should be defined from a current situation in a chosen road network (at a region or urban area level). Then changes in the infrastructure, in the car fleet, in the mobility offer could be analyzed and benefits in terms of energy consumption and local emissions could be evaluated. Doctoral School: ED580 - STIC Sciences et Technologies de l'Information et de la Communication Supervisor: Dr. Antonio SCIARRETTA, IFP Energies nouvelles, antonio.sciarretta@ifpen.fr Co- supervisor: Dr. Milos BALAC, Institute for Transport Planning and Systems (IVT), ETH Zurich, Switzerland, milos.balac@ivt.baug.ethz.ch PhD location: IFP Energies nouvelles, Rueil-Malmaison, France Duration and start date: 3 years, starting in fourth quarter 2021 Employer: IFP Energies nouvelles, Rueil-Malmaison, France Academic requirements: University Master's degree in Transportation Engineering, Information Engineering, Dynamical Systems or Control Science Language requirements: Fluency in English. Fluency in, or willingness to learn, French To apply, please send your cover letter and CV to the IFPEN supervisor indicated here above.","title":"PhD position at IFP Energies nouvelles (IFPEN)"},{"location":"news/2021-06-08-teralytics-job-posting/","text":"Teralytics uses data from telecommunication networks to provide mobility insights. In this internship, you will be part of a small product-focused team, working to release a new software and data product to market. MATSim is used as part of the computation pipeline, making this a great opportunity to get experience in using agent-based models in customer-facing products. More information and applications on the job posting's page on Teralytics' website . For more information, feel free to reach out to Thibaut Dubernet","title":"Job Posting: Transport Model Development Intern, Berlin"},{"location":"news/2021-10-04-job-post-sbb/","text":"Machen Sie was Grosses. Bewegen Sie mit uns die Schweiz als Mobilit\u00e4tsexperte/-expertin mit Fokus Simulationen und Mobilit\u00e4tsszenarien \u00b6 at Swiss Federal Railways (SBB) Bern Bollwerk / Work Smart, ab 01.01.2022 oder nach Vereinbarung, 80-100%, Job ID 53801 Weitere Informationen zur Stellenausschreibung finden sich hier .","title":"Job posting SBB"},{"location":"news/2021-10-04-job-post-sbb/#mobilitatsexperte-expertin-mit-fokus-simulationen-und-mobilitatsszenarien","text":"at Swiss Federal Railways (SBB) Bern Bollwerk / Work Smart, ab 01.01.2022 oder nach Vereinbarung, 80-100%, Job ID 53801 Weitere Informationen zur Stellenausschreibung finden sich hier .","title":"Mobilit\u00e4tsexperte/-expertin mit Fokus Simulationen und Mobilit\u00e4tsszenarien"},{"location":"news/2021-12-03-matsim-um/","text":"We are happy to announce that MATSim User Meeting in 2022 will be held in conjunction with the 10th Symposium of the European Association for Research in Transportation (hEART 2022). A full day meeting will be held on 31.05. at KU Leuven, Belgium. We are now accepting submissions of 1-2 pages extended abstracts that should describe your recent MATSim work: Submission page Submissions page will close on 07.03. at 11:59 CET. If you plan to attend the meeting (either as an author, co-author, or attendee) there is a registration fee of 55 CHF to cover for the venue and food expenses (coffees and food). You can register at the following link: Registration page Preliminary schedule Any questions or comments you can direct to matsimum2022@gmail.com","title":"MATSim User Meeting 2022"},{"location":"news/2022-02-10-abm-modelling-uae/","text":"CDM Smith engineering company is offering a job opportunity in UAE for two modelling experts with activity-based as well as agent-based modelling experience. Here are the job descriptions: Modelling Specialist 1: The candidate should have a minimum of 10 years of experience developing tour-based activity-driven transport models and freight modeling. Experience with DSTM Is for this role; and Modeling Specialist 2: The candidate should have a minimum of 10 years of experience in transport modeling. Experience In the development of agent-based activity-driven transport modeling is a must for this role. Experience with use of agent-based activity driven transport model for the assessment of new form of transport technologies and services Is desirable for this role; Key Requirements: Demonstrated experience working on multidisciplinary transport projects, with medium and high complexity; Strong understanding of theoretical transport modelling concepts and application. Participate In the development and application of the strategic transportation models; Transport model development with tasks Including but not limited to model building, calibration/validation, model testing and auditing, checking and analysis of model outputs; Good experience with the latest methodologies, processes and software packages (VISUM, CUBE, etc); Model development experience both traditional activity-based models and agent-based models; Hands-on experience in development and preparation of travel daily survey and SP design; Experience in analysis and Interpretation of outputs from transport modelling software packages; The contract person for further information on these positions is Dr. Afaf Al Azzawi, Transportation & Traffic Manager at CDM Smith. alazzawia@cdmsmith.com","title":"ABM Modelling job opportunity in UAE"},{"location":"news/2022-02-10-job-post-boku/","text":"Job opportunity for MATSim community in Vienna: https://euraxess.ec.europa.eu/jobs/739651 .","title":"Job opportunity at BOKU in Vienna"},{"location":"news/2022-03-08-job-dresden/","text":"To contribute to research around topics of agent-based transport simulation (in particular, but not limited to: sustainable mobility, active mobility, open-data-based model development, accessibility analyses and land-use/transport interaction), the Chair Integrated Transport Planning at TU Dresden is hiring a researcher / PhD student. For details, see here: https://www.verw.tu-dresden.de/StellAus/download.asp?file=03-2022%5CGerike_WIMI_eng_040222_w056.pdf","title":"Position as researcher / PhD student / TU Dresden"},{"location":"news/2022-05-10-job-opening-sbb/","text":"Bern Wankdorf / Work Smart, 01.09.2022, 60-100% Du hast die Chance, bei der Anwendung und dem Betrieb eines aktivit\u00e4ten- und agentenbasierten Verkehrsmodells mitzuwirken, welches auf dem neusten Stand von Praxis und Forschung basiert. Mit diesen Modellergebnissen lieferst du einen massgebenden Beitrag f\u00fcr Entscheidungen \u00fcber zuk\u00fcnftige Ausbauten des Bahn-, resp. \u00d6V-Angebots in der Schweiz. F\u00fchlst du dich angesprochen? Hier geht's zur Bewerbung","title":"Job posting SBB"},{"location":"news/archive/","text":"SUBMIT NEWS MATSim News Archive \u00b6 {% assign years = \"2025|2024|2023|2022|2021|2020|2019\" | split: \"|\" %} {% capture strnowyear %}{{'now' | date: '%Y'}}{% endcapture %} {% for stryear in years %} {% assign year = stryear | plus: 0 %} {% if year <= nowyear %} {{year}} {% for post in site.posts %} {% capture postyear %} {{post.date | date: '%Y'}}{% endcapture %} {{ post.title }} \u00bb by {{ post.author }} on {{ post.date | date_to_string }} {% endif %} {% endif %}","title":"Archive"},{"location":"news/archive/#matsim-news-archive","text":"{% assign years = \"2025|2024|2023|2022|2021|2020|2019\" | split: \"|\" %} {% capture strnowyear %}{{'now' | date: '%Y'}}{% endcapture %} {% for stryear in years %} {% assign year = stryear | plus: 0 %} {% if year <= nowyear %} {{year}} {% for post in site.posts %} {% capture postyear %} {{post.date | date: '%Y'}}{% endcapture %} {{ post.title }} \u00bb by {{ post.author }} on {{ post.date | date_to_string }} {% endif %} {% endif %}","title":"MATSim News Archive"},{"location":"news/authors/","text":"MATSim News Archive \u00b6 {% assign years = \"2025|2024|2023|2022|2021|2020|2019\" | split: \"|\" %} {% capture strnowyear %}{{'now' | date: '%Y'}}{% endcapture %} {% for stryear in years %} {% assign year = stryear | plus: 0 %} {% if year <= nowyear %} {{year}} {% for post in site.posts %} {% capture postyear %} {{post.date | date: '%Y'}}{% endcapture %} {{ post.title }} \u00bb by {{ post.author }} on {{ post.date | date_to_string }} {% endif %} {% endif %}","title":"Archive"},{"location":"news/authors/#matsim-news-archive","text":"{% assign years = \"2025|2024|2023|2022|2021|2020|2019\" | split: \"|\" %} {% capture strnowyear %}{{'now' | date: '%Y'}}{% endcapture %} {% for stryear in years %} {% assign year = stryear | plus: 0 %} {% if year <= nowyear %} {{year}} {% for post in site.posts %} {% capture postyear %} {{post.date | date: '%Y'}}{% endcapture %} {{ post.title }} \u00bb by {{ post.author }} on {{ post.date | date_to_string }} {% endif %} {% endif %}","title":"MATSim News Archive"},{"location":"news/template/","text":"Here is my news item. Use regular markdown for the full news item content. The header at the top of the file must contain an author, title, and summary","title":"MATSim in the news"},{"location":"pi-hole/abbreviations/","text":"","title":"Abbreviations"},{"location":"pi-hole/core/pihole-command/","text":"Pi-hole makes use of many commands, and here we will break down those required to administer the program via the command-line Interface. Index Invocation Core Script pihole Web Script pihole -a Pi-hole Core \u00b6 Feature Invocation Core pihole Whitelisting, Blacklisting and Regex pihole -w , pihole -b , pihole -regex , pihole -wild Debugger pihole debug Log Flush pihole flush Reconfigure pihole reconfigure Tail pihole tail Admin pihole -a Chronometer pihole chronometer Gravity pihole updateGravity Logging pihole logging Query pihole query Update pihole updatePihole Version pihole version Uninstall pihole uninstall Status pihole status Enable & Disable pihole enable Restart DNS pihole restartdns Checkout pihole checkout Core Script \u00b6 Help Command pihole --help Script Location /usr/local/bin/pihole Example Usage pihole -b advertiser.example.com The core script of Pi-hole provides the ability to tie many DNS related functions into a simple and user-friendly management system, so that one may easily block unwanted content such as advertisements. For both the Command-line Interface (CLI) and Web Interface, we achieve this through the pihole command (this helps minimize code duplication, and allows users to read exactly what's happening using bash scripting). This \"wrapper\" elevates the current user (whether it be your own user account, or www-data ) using sudo , but restricts the elevation to solely what can be called through the wrapper. Whitelisting, Blacklisting and Regex \u00b6 Help Command pihole -w --help , pihole -b --help , pihole -regex --help , pihole -wild --help Script Location /opt/pihole/list.sh Example Usage pihole -regex '^example.com$' '.*\\.example2.net' Administrators need to be able to manually add and remove domains for various purposes, and these commands serve that purpose. See Regex Blocking for more information about using Regex. Basic Script Process : Each domain is validated using regex (except when using -regex ), to ensure invalid domains and IDNs are not added A domain gets added to or removed from the domainlist table in /etc/pihole/gravity.db The DNS server is then reloaded Debugger \u00b6 Help Command N/A Script Location /opt/pihole/piholeDebug.sh Example Usage pihole debug The Pi-hole debugger will attempt to diagnose any issues, and link to an FAQ with instructions as to how an admin can rectify the issue. Once the debugger has finished, the admin has the option to upload the generated log to the Pi-hole developers, who can help with diagnosing and rectifying persistent issues. Log Flush \u00b6 Help Command N/A Script Location /opt/pihole/piholeLogFlush.sh Example Usage pihole flush When invoked manually, this command will allow you to empty Pi-hole's log, which is located at /var/log/pihole.log . The command also serves to rotate the log daily, if the logrotate application is installed. Reconfigure \u00b6 Help Command N/A Script Location /etc/.pihole/automated install/basic-install.sh Example Usage pihole reconfigure There are times where the administrator will need to repair or reconfigure the Pi-hole installation, which is performed via this command. Basic Script Process : basic-install.sh will be run Reconfigure will run through the first-time installation prompts, asking for upstream DNS provider, IP protocols, etc Repair will retain your existing settings and will attempt to repair any scripts or dependencies as necessary The rest of basic-install.sh will then run as appropriate Tail \u00b6 Help Command N/A Script Location /usr/local/bin/pihole Example Usage pihole tail Since Pi-hole will log DNS queries by default, using this command to watch the log in real-time can be useful for debugging a problematic site, or even just for sheer curiosities sake. Admin \u00b6 Help Command pihole -a --help Script Location /opt/pihole/webpage.sh Example Usage pihole -a -p secretpassword Detailed information on this is found here . Chronometer \u00b6 Help Command pihole -c --help Script Location /opt/pihole/chronometer.sh Example Usage pihole -c -e Chronometer is a console dashboard of real-time stats, which can be displayed via ssh or on an LCD screen attached directly to your hardware. The script is capable of detecting the size of your screen and adjusting output to try and best suit it. Image courtesy of /u/super_nicktendo22 Gravity \u00b6 Help Command N/A Script Location /opt/pihole/gravity.sh Example Usage pihole -g Gravity is one of the most important scripts of Pi-hole. Its main purpose is to retrieve blocklists, and then consolidate them into one unique list for the built-in DNS server to use, but it also serves to complete the process of manual whitelisting, blacklisting and wildcard update. It is run automatically each week, but it can be invoked manually at any time. Basic Script Process : It will determine Internet connectivity, and give time for pihole-FTL to be resolvable on low-end systems if has just been restarted It extracts all URLs and domains from the adlists table in /etc/pihole/gravity.db It runs through each URL, downloading it if necessary curl checks the servers Last-Modified header to ensure it is getting a newer version It will attempt to parse the file into a domains-only format if necessary Lists are merged, comments removed, sorted uniquely and stored in the gravity table of /etc/pihole/gravity.db Gravity cleans up temporary content and reloads the DNS server Logging \u00b6 Help Command pihole logging --help Script Location /usr/local/bin/pihole Example Usage pihole logging off This command specifies whether the Pi-hole log should be used, by commenting out log-queries within /etc/dnsmasq.d/01-pihole.conf and flushing the log. Query \u00b6 Help Command pihole query --help Script Location /usr/local/bin/pihole Example Usage pihole -q -exact -adlist example.domain.com This command will query your whitelist, blacklist, wildcards and adlists for a specified domain. Basic Script Process : User-specified options are handled Using idn , it will convert Internationalized domain names into punycode Database at /etc/pihole/gravity.db is queried to return a list of adlists in which the queried domain exists. Update \u00b6 Help Command pihole updatePihole Script Location /opt/pihole/update.sh Example Usage pihole -up Check Pi-hole Core, Web Interface and FTL repositories to determine what upgrades (if any) are required. It will then automatically update and reinstall if necessary. Basic Script Process : Script determines if updates are available by querying GitHub Updated files are downloaded to the local filesystem using git basic-install.sh is run Version \u00b6 Help Command pihole version Script Location /opt/pihole/version.sh Example Usage pihole -v -c Shows installed versions of Pi-hole, Web Interface & FTL. It also provides options to configure which details will be printed, such as the current version, latest version, hash and subsystem. Uninstall \u00b6 Help Command N/A Script Location /etc/.pihole/automated install/uninstall.sh Example Usage pihole uninstall Uninstall Pi-hole from your system, giving the option to remove each dependency individually. Status \u00b6 Help Command N/A Script Location /usr/local/bin/pihole Example Usage pihole status Display the running status of Pi-hole's DNS and blocking services. Enable & Disable \u00b6 Help Command pihole disable --help Script Location /usr/local/bin/pihole Example Usage pihole disable 5m Toggle Pi-hole's ability to block unwanted domains. The disable option has the option to set a specified time before blocking is automatically re-enabled. Restart DNS \u00b6 Help Command N/A Script Location /usr/local/bin/pihole Example Usage pihole restartdns Restart Pi-hole's DNS service. Checkout \u00b6 Help Command pihole checkout --help Script Location /opt/pihole/piholeCheckout.sh Example Usage pihole checkout dev Switch Pi-hole subsystems to a different GitHub branch. An admin can specify repositories as well as branches. Pi-hole Web \u00b6 Feature Invocation Web Script pihole -a Password pihole -a password Teleport pihole -a -t Temperature Unit pihole -a celsius , pihole -a fahrenheit , pihole -a kelvin Host Record pihole -a hostrecord Email Address pihole -a email Interface pihole -a interface Web Script \u00b6 Help Command pihole -a --help Script Location /opt/pihole/webpage.sh Example Usage pihole -a -p secretpassword Set options for the Web Interface. This script is used to tie in all Web Interface features which are not already covered by the Core Script . Password \u00b6 Help Command N/A Script Location /opt/pihole/webpage.sh Example Usage pihole -a -p secretpassword Set the Web Interface password. Password can be entered as an option (e.g: pihole -a -p secretpassword ), or separately as to not display on the screen (e.g: pihole -a -p ). Teleport \u00b6 Help Command N/A Script Location N/A Example Usage pihole -a -t Create a configuration backup. The backup will be created in the directory from which the command is run. The backup can be imported using the Settings > Teleport page. Temperature Unit \u00b6 Help Command N/A Script Location /opt/pihole/webpage.sh Example Usage pihole -a -c Set the specified temperature unit as the preferred type. This preference will affect the Web Interface, as well as Chronometer. Email Address \u00b6 Help Command N/A Script Location /opt/pihole/webpage.sh Example Usage pihole -a email admin@domain.com Set an administrative contact address for the Block Page. This will create a hyperlink on the Block Page to the specified email address. Interface \u00b6 Help Command pihole -a interface --help Script Location /opt/pihole/webpage.sh Example Usage pihole -a interface local Specify interface listening behavior for pihole-FTL . When using pihole -a interface all , please ensure you use a firewall to prevent your Pi-hole from becoming an unwitting host to DNS amplification attackers . You may want to consider running Wireguard to grant your mobile devices access to the Pi-hole.","title":"The pihole command - Pi-hole documentation"},{"location":"pi-hole/core/pihole-command/#pi-hole-core","text":"Feature Invocation Core pihole Whitelisting, Blacklisting and Regex pihole -w , pihole -b , pihole -regex , pihole -wild Debugger pihole debug Log Flush pihole flush Reconfigure pihole reconfigure Tail pihole tail Admin pihole -a Chronometer pihole chronometer Gravity pihole updateGravity Logging pihole logging Query pihole query Update pihole updatePihole Version pihole version Uninstall pihole uninstall Status pihole status Enable & Disable pihole enable Restart DNS pihole restartdns Checkout pihole checkout","title":"Pi-hole Core"},{"location":"pi-hole/core/pihole-command/#core-script","text":"Help Command pihole --help Script Location /usr/local/bin/pihole Example Usage pihole -b advertiser.example.com The core script of Pi-hole provides the ability to tie many DNS related functions into a simple and user-friendly management system, so that one may easily block unwanted content such as advertisements. For both the Command-line Interface (CLI) and Web Interface, we achieve this through the pihole command (this helps minimize code duplication, and allows users to read exactly what's happening using bash scripting). This \"wrapper\" elevates the current user (whether it be your own user account, or www-data ) using sudo , but restricts the elevation to solely what can be called through the wrapper.","title":"Core Script"},{"location":"pi-hole/core/pihole-command/#whitelisting-blacklisting-and-regex","text":"Help Command pihole -w --help , pihole -b --help , pihole -regex --help , pihole -wild --help Script Location /opt/pihole/list.sh Example Usage pihole -regex '^example.com$' '.*\\.example2.net' Administrators need to be able to manually add and remove domains for various purposes, and these commands serve that purpose. See Regex Blocking for more information about using Regex. Basic Script Process : Each domain is validated using regex (except when using -regex ), to ensure invalid domains and IDNs are not added A domain gets added to or removed from the domainlist table in /etc/pihole/gravity.db The DNS server is then reloaded","title":"Whitelisting, Blacklisting and Regex"},{"location":"pi-hole/core/pihole-command/#debugger","text":"Help Command N/A Script Location /opt/pihole/piholeDebug.sh Example Usage pihole debug The Pi-hole debugger will attempt to diagnose any issues, and link to an FAQ with instructions as to how an admin can rectify the issue. Once the debugger has finished, the admin has the option to upload the generated log to the Pi-hole developers, who can help with diagnosing and rectifying persistent issues.","title":"Debugger"},{"location":"pi-hole/core/pihole-command/#log-flush","text":"Help Command N/A Script Location /opt/pihole/piholeLogFlush.sh Example Usage pihole flush When invoked manually, this command will allow you to empty Pi-hole's log, which is located at /var/log/pihole.log . The command also serves to rotate the log daily, if the logrotate application is installed.","title":"Log Flush"},{"location":"pi-hole/core/pihole-command/#reconfigure","text":"Help Command N/A Script Location /etc/.pihole/automated install/basic-install.sh Example Usage pihole reconfigure There are times where the administrator will need to repair or reconfigure the Pi-hole installation, which is performed via this command. Basic Script Process : basic-install.sh will be run Reconfigure will run through the first-time installation prompts, asking for upstream DNS provider, IP protocols, etc Repair will retain your existing settings and will attempt to repair any scripts or dependencies as necessary The rest of basic-install.sh will then run as appropriate","title":"Reconfigure"},{"location":"pi-hole/core/pihole-command/#tail","text":"Help Command N/A Script Location /usr/local/bin/pihole Example Usage pihole tail Since Pi-hole will log DNS queries by default, using this command to watch the log in real-time can be useful for debugging a problematic site, or even just for sheer curiosities sake.","title":"Tail"},{"location":"pi-hole/core/pihole-command/#admin","text":"Help Command pihole -a --help Script Location /opt/pihole/webpage.sh Example Usage pihole -a -p secretpassword Detailed information on this is found here .","title":"Admin"},{"location":"pi-hole/core/pihole-command/#chronometer","text":"Help Command pihole -c --help Script Location /opt/pihole/chronometer.sh Example Usage pihole -c -e Chronometer is a console dashboard of real-time stats, which can be displayed via ssh or on an LCD screen attached directly to your hardware. The script is capable of detecting the size of your screen and adjusting output to try and best suit it. Image courtesy of /u/super_nicktendo22","title":"Chronometer"},{"location":"pi-hole/core/pihole-command/#gravity","text":"Help Command N/A Script Location /opt/pihole/gravity.sh Example Usage pihole -g Gravity is one of the most important scripts of Pi-hole. Its main purpose is to retrieve blocklists, and then consolidate them into one unique list for the built-in DNS server to use, but it also serves to complete the process of manual whitelisting, blacklisting and wildcard update. It is run automatically each week, but it can be invoked manually at any time. Basic Script Process : It will determine Internet connectivity, and give time for pihole-FTL to be resolvable on low-end systems if has just been restarted It extracts all URLs and domains from the adlists table in /etc/pihole/gravity.db It runs through each URL, downloading it if necessary curl checks the servers Last-Modified header to ensure it is getting a newer version It will attempt to parse the file into a domains-only format if necessary Lists are merged, comments removed, sorted uniquely and stored in the gravity table of /etc/pihole/gravity.db Gravity cleans up temporary content and reloads the DNS server","title":"Gravity"},{"location":"pi-hole/core/pihole-command/#logging","text":"Help Command pihole logging --help Script Location /usr/local/bin/pihole Example Usage pihole logging off This command specifies whether the Pi-hole log should be used, by commenting out log-queries within /etc/dnsmasq.d/01-pihole.conf and flushing the log.","title":"Logging"},{"location":"pi-hole/core/pihole-command/#query","text":"Help Command pihole query --help Script Location /usr/local/bin/pihole Example Usage pihole -q -exact -adlist example.domain.com This command will query your whitelist, blacklist, wildcards and adlists for a specified domain. Basic Script Process : User-specified options are handled Using idn , it will convert Internationalized domain names into punycode Database at /etc/pihole/gravity.db is queried to return a list of adlists in which the queried domain exists.","title":"Query"},{"location":"pi-hole/core/pihole-command/#update","text":"Help Command pihole updatePihole Script Location /opt/pihole/update.sh Example Usage pihole -up Check Pi-hole Core, Web Interface and FTL repositories to determine what upgrades (if any) are required. It will then automatically update and reinstall if necessary. Basic Script Process : Script determines if updates are available by querying GitHub Updated files are downloaded to the local filesystem using git basic-install.sh is run","title":"Update"},{"location":"pi-hole/core/pihole-command/#version","text":"Help Command pihole version Script Location /opt/pihole/version.sh Example Usage pihole -v -c Shows installed versions of Pi-hole, Web Interface & FTL. It also provides options to configure which details will be printed, such as the current version, latest version, hash and subsystem.","title":"Version"},{"location":"pi-hole/core/pihole-command/#uninstall","text":"Help Command N/A Script Location /etc/.pihole/automated install/uninstall.sh Example Usage pihole uninstall Uninstall Pi-hole from your system, giving the option to remove each dependency individually.","title":"Uninstall"},{"location":"pi-hole/core/pihole-command/#status","text":"Help Command N/A Script Location /usr/local/bin/pihole Example Usage pihole status Display the running status of Pi-hole's DNS and blocking services.","title":"Status"},{"location":"pi-hole/core/pihole-command/#enable-disable","text":"Help Command pihole disable --help Script Location /usr/local/bin/pihole Example Usage pihole disable 5m Toggle Pi-hole's ability to block unwanted domains. The disable option has the option to set a specified time before blocking is automatically re-enabled.","title":"Enable &amp; Disable"},{"location":"pi-hole/core/pihole-command/#restart-dns","text":"Help Command N/A Script Location /usr/local/bin/pihole Example Usage pihole restartdns Restart Pi-hole's DNS service.","title":"Restart DNS"},{"location":"pi-hole/core/pihole-command/#checkout","text":"Help Command pihole checkout --help Script Location /opt/pihole/piholeCheckout.sh Example Usage pihole checkout dev Switch Pi-hole subsystems to a different GitHub branch. An admin can specify repositories as well as branches.","title":"Checkout"},{"location":"pi-hole/core/pihole-command/#pi-hole-web","text":"Feature Invocation Web Script pihole -a Password pihole -a password Teleport pihole -a -t Temperature Unit pihole -a celsius , pihole -a fahrenheit , pihole -a kelvin Host Record pihole -a hostrecord Email Address pihole -a email Interface pihole -a interface","title":"Pi-hole Web"},{"location":"pi-hole/core/pihole-command/#web-script","text":"Help Command pihole -a --help Script Location /opt/pihole/webpage.sh Example Usage pihole -a -p secretpassword Set options for the Web Interface. This script is used to tie in all Web Interface features which are not already covered by the Core Script .","title":"Web Script"},{"location":"pi-hole/core/pihole-command/#password","text":"Help Command N/A Script Location /opt/pihole/webpage.sh Example Usage pihole -a -p secretpassword Set the Web Interface password. Password can be entered as an option (e.g: pihole -a -p secretpassword ), or separately as to not display on the screen (e.g: pihole -a -p ).","title":"Password"},{"location":"pi-hole/core/pihole-command/#teleport","text":"Help Command N/A Script Location N/A Example Usage pihole -a -t Create a configuration backup. The backup will be created in the directory from which the command is run. The backup can be imported using the Settings > Teleport page.","title":"Teleport"},{"location":"pi-hole/core/pihole-command/#temperature-unit","text":"Help Command N/A Script Location /opt/pihole/webpage.sh Example Usage pihole -a -c Set the specified temperature unit as the preferred type. This preference will affect the Web Interface, as well as Chronometer.","title":"Temperature Unit"},{"location":"pi-hole/core/pihole-command/#email-address","text":"Help Command N/A Script Location /opt/pihole/webpage.sh Example Usage pihole -a email admin@domain.com Set an administrative contact address for the Block Page. This will create a hyperlink on the Block Page to the specified email address.","title":"Email Address"},{"location":"pi-hole/core/pihole-command/#interface","text":"Help Command pihole -a interface --help Script Location /opt/pihole/webpage.sh Example Usage pihole -a interface local Specify interface listening behavior for pihole-FTL . When using pihole -a interface all , please ensure you use a firewall to prevent your Pi-hole from becoming an unwitting host to DNS amplification attackers . You may want to consider running Wireguard to grant your mobile devices access to the Pi-hole.","title":"Interface"},{"location":"pi-hole/database/","text":"Pi-hole uses the well-known relational database management system SQLite3 both for its long-term storage of query data and for its domain management. In contrast to many other database management solutions, Pi-hole does not need a server database engine as the database engine is directly embedded in FTL DNS. It seems an obvious choice as it is probably the most widely deployed database engine - it is used today by several widespread web browsers, operating systems, and embedded systems (such as mobile phones), among others. Hence, it is rich in supported platforms and offered features. SQLite implements most of the SQL-92 standard for SQL and can be used for high-level queries. Details concerning the databases, their contained tables and exemplary SQL commands allowing even complex requests to Pi-hole's databases are described on the subpages of this category. Query database /etc/pihole/pihole-FTL.db Domain database /etc/pihole/gravity.db","title":"Index"},{"location":"pi-hole/database/ftl/","text":"Pi-hole FTL DNS uses the well-known relational database management system SQLite3 as its long-term storage of query data. In contrast to many other database management solutions, FTL DNS does not need a server database engine as the database engine is directly embedded in FTL DNS. It seems an obvious choice as it is probably the most widely deployed database engine - it is used today by several widespread web browsers, operating systems, and embedded systems (such as mobile phones), among others. Hence, it is rich in supported platforms and offered features. SQLite implements most of the SQL-92 standard for SQL and can be used for high-level queries. The long-term query database was the first database that was added to the Pi-hole project. We update this database periodically and on the exit of FTL DNS (triggered e.g. by a service pihole-FTL restart ). The updating frequency can be controlled by the parameter DBINTERVAL and defaults to once per minute. We think this interval is sufficient to protect against data losses due to power failure events. FTL DNS needs the database to populate its internal history of the most recent 24 hours. If the database is disabled, FTL DNS will show an empty query history after a restart. The location of the database can be configured by the config parameter DBFILE . It defaults to /etc/pihole/pihole-FTL.db . If the given file does not exist, FTL DNS will create a new (empty) database file. Another way of controlling the size of the long-term database is by setting a maximum age for log queries to keep using the config parameter MAXDBDAYS . It defaults to 365 days, i.e. queries that are older than one year get periodically removed to limit the growth of the long-term database file. The config parameter DBIMPORT controls whether FTL loads information from the database on startup. It needs to do this to populate the internal data structure with the most recent history. However, as importing from the database on disk can delay FTL on very large deploys, it can be disabled using this option. Split database \u00b6 You can split your long-term database by periodically rotating the database file (do this only when pihole-FTL is not running). The individual database contents can easily be merged when required. This could be implemented by running a monthly cron job such as: sudo service pihole-FTL stop sudo mv /etc/pihole/pihole-FTL.db /media/backup/pihole-FTL_ $( date + \"%m-%y\" ) .db sudo service pihole-FTL start Note that DNS resolution will not be available as long as pihole-FTL is stopped. Backup database \u00b6 The database can be backed up while FTL is running when using the SQLite3 Online backup method, e.g., sqlite3 /etc/pihole/pihole-FTL.db \".backup /home/pi/pihole-FTL.db.backup\" will create /home/pi/pihole-FTL.db.backup which is a copy of your long-term database. The long-term database contains several tables: Query Table \u00b6 Label Type Allowed to by empty Content id integer No autoincrement ID for the table, only used by SQLite3, not by FTL DNS timestamp integer No Unix timestamp when this query arrived at FTL DNS (used as index) type integer No Type of this query (see Supported query types ) status integer No How was this query handled by FTL DNS? (see Supported status types ) domain text No Requested domain client text No Requesting client (IP address) forward text Yes Forward destination used for this query (only set if status == 2 ) additional_info blob Yes Data-dependent content, see below reply_type integer Yes Type of the reply for this query (see Supported reply types ) reply_time real Yes Seconds it took until the final reply was received dnssec integer Yes Type of the DNSSEC status for this query (see DNSSEC status ) The queries VIEW is dynamically generated from the data actually stored in the query_storage table and the linking tables domain_by_id , client_by_id , forward_by_id , and addinfo_by_id (see below). The table query_storage will contains integer IDs pointing to the respective entries of the linking tables to save space and make searching the database faster. If you haven't upgraded for some time, the table may still contain strings instead of integer IDs. Data-dependent additional_info field \u00b6 The content and type of the additional_info row depends on the status of the given query. Query blocked due to a CNAME inspection (status 9, 10, 11) \u00b6 If a query was blocked due to a CNAME inspection (status 9, 10, 11), this field contains the domain which was the reason for blocking the entire CNAME chain (text). Query blocked due to a REGEX filter (status 4) \u00b6 If a query was blocked due to a regex rule (status 4), this field contains the ID of the blacklist regex responsible for blocking this domain (integer). Other \u00b6 For any other query status, this field is empty. You should, however, not rely on this field being empty as we may add content of any type for other status types in future releases. Counters table \u00b6 This table contains counter values integrated over the entire lifetime of the table Label Type Allowed to by empty Content id integer No ID for the table used to select a counter (see below) value integer No Value of a given counter ID Interpretation 0 Total number of queries 1 Total number of blocked queries FTL table \u00b6 The FTL table contains some data used by FTL DNS for determining which queries to save to the database. This table does not contain any entries of general interest. Supported query types \u00b6 ID Resource Record (a.k.a. query type) 1 A 2 AAAA 3 ANY 4 SRV 5 SOA 6 PTR 7 TXT 8 NAPTR 9 MX 10 DS 11 RRSIG 12 DNSKEY 13 NS 14 OTHER (any query type not covered elsewhere) 15 SVCB 16 HTTPS Supported status types \u00b6 ID Status Details 0 Unknown \u2754 Unknown status (not yet known) 1 Blocked \u274c Domain contained in gravity database 2 Allowed \u2705 Forwarded 3 Allowed \u2705 Known, replied to from cache 4 Blocked \u274c Domain matched by a regex blacklist filter 5 Blocked \u274c Domain contained in exact blacklist 6 Blocked \u274c By upstream server (known blocking page IP address) 7 Blocked \u274c By upstream server ( 0.0.0.0 or :: ) 8 Blocked \u274c By upstream server ( NXDOMAIN with RA bit unset) 9 Blocked \u274c Domain contained in gravity database Blocked during deep CNAME inspection 10 Blocked \u274c Domain matched by a regex blacklist filter Blocked during deep CNAME inspection 11 Blocked \u274c Domain contained in exact blacklist Blocked during deep CNAME inspection 12 Allowed \u2705 Retried query 13 Allowed \u2705 Retried but ignored query (this may happen during ongoing DNSSEC validation) 14 Allowed \u2705 Already forwarded, not forwarding again Supported reply types \u00b6 ID Reply type is 0 unknown (no reply so far) 1 NODATA 2 NXDOMAIN 3 CNAME 4 a valid IP record 5 DOMAIN 6 RRNAME 7 SERVFAIL 8 REFUSED 9 NOTIMP 10 OTHER 11 DNSSEC 12 NONE (query was dropped intentionally) 13 BLOB (binary data) DNSSEC status \u00b6 ID DNSSEC status is 0 unknown 1 SECURE 2 INSECURE 3 BOGUS 4 ABANDONED Linking tables \u00b6 The queries VIEW reads repeating properties from linked tables to reduce both database size and search complexity. These linking tables, domain_by_id , client_by_id , forward_by_id , and addinfo_by_id all have a similar structure: domain_by_id \u00b6 Label Type Allowed to by empty Content id integer No ID of the entry. Used by query_storage domain text No Domain name client_by_id \u00b6 Label Type Allowed to by empty Content id integer No ID of the entry. Used by query_storage ip text No Client IP address name text Yes Client host name forward_by_id \u00b6 Label Type Allowed to by empty Content id integer No ID of the entry. Used by query_storage forward text No Upstream server identifier ( <ipaddr>#<port> ) addinfo_by_id \u00b6 Label Type Allowed to by empty Content id integer No ID of the entry. Used by query_storage type integer No Type of the content field content blob No Type-dependent content Valid type IDs are currently ADDINFO_CNAME_DOMAIN = 1 if content is a CNAME pointer, and ADDINFO_REGEX_ID = 2 if content is an integer ID pointing to a regular expression in gravity.db Example for interaction with the long-term query database \u00b6 In addition to the interactions the Pi-hole database API offers, you can also run your own SQL commands against the database. If you want to obtain the three most queries domains for all time, you could use sqlite3 \"/etc/pihole/pihole-FTL.db\" \"SELECT domain,count(domain) FROM queries WHERE (STATUS == 2 OR STATUS == 3) GROUP BY domain ORDER BY count(domain) DESC LIMIT 3\" which would return something like discourse.pi-hole.net|421095 www.pi-hole.net|132483 posteo.de|130243 showing the domain and the number of times it was found in the long-term database. Note that such a request might take a very long time for computation as the entire history of queries has to be processed for this.","title":"Ftl"},{"location":"pi-hole/database/ftl/#split-database","text":"You can split your long-term database by periodically rotating the database file (do this only when pihole-FTL is not running). The individual database contents can easily be merged when required. This could be implemented by running a monthly cron job such as: sudo service pihole-FTL stop sudo mv /etc/pihole/pihole-FTL.db /media/backup/pihole-FTL_ $( date + \"%m-%y\" ) .db sudo service pihole-FTL start Note that DNS resolution will not be available as long as pihole-FTL is stopped.","title":"Split database"},{"location":"pi-hole/database/ftl/#backup-database","text":"The database can be backed up while FTL is running when using the SQLite3 Online backup method, e.g., sqlite3 /etc/pihole/pihole-FTL.db \".backup /home/pi/pihole-FTL.db.backup\" will create /home/pi/pihole-FTL.db.backup which is a copy of your long-term database. The long-term database contains several tables:","title":"Backup database"},{"location":"pi-hole/database/ftl/#query-table","text":"Label Type Allowed to by empty Content id integer No autoincrement ID for the table, only used by SQLite3, not by FTL DNS timestamp integer No Unix timestamp when this query arrived at FTL DNS (used as index) type integer No Type of this query (see Supported query types ) status integer No How was this query handled by FTL DNS? (see Supported status types ) domain text No Requested domain client text No Requesting client (IP address) forward text Yes Forward destination used for this query (only set if status == 2 ) additional_info blob Yes Data-dependent content, see below reply_type integer Yes Type of the reply for this query (see Supported reply types ) reply_time real Yes Seconds it took until the final reply was received dnssec integer Yes Type of the DNSSEC status for this query (see DNSSEC status ) The queries VIEW is dynamically generated from the data actually stored in the query_storage table and the linking tables domain_by_id , client_by_id , forward_by_id , and addinfo_by_id (see below). The table query_storage will contains integer IDs pointing to the respective entries of the linking tables to save space and make searching the database faster. If you haven't upgraded for some time, the table may still contain strings instead of integer IDs.","title":"Query Table"},{"location":"pi-hole/database/ftl/#data-dependent-additional_info-field","text":"The content and type of the additional_info row depends on the status of the given query.","title":"Data-dependent additional_info field"},{"location":"pi-hole/database/ftl/#additional_info_cname","text":"If a query was blocked due to a CNAME inspection (status 9, 10, 11), this field contains the domain which was the reason for blocking the entire CNAME chain (text).","title":"Blocked CNAME"},{"location":"pi-hole/database/ftl/#additional_info_regex","text":"If a query was blocked due to a regex rule (status 4), this field contains the ID of the blacklist regex responsible for blocking this domain (integer).","title":"Regular expression"},{"location":"pi-hole/database/ftl/#other","text":"For any other query status, this field is empty. You should, however, not rely on this field being empty as we may add content of any type for other status types in future releases.","title":"Other"},{"location":"pi-hole/database/ftl/#counters-table","text":"This table contains counter values integrated over the entire lifetime of the table Label Type Allowed to by empty Content id integer No ID for the table used to select a counter (see below) value integer No Value of a given counter ID Interpretation 0 Total number of queries 1 Total number of blocked queries","title":"Counters table"},{"location":"pi-hole/database/ftl/#ftl-table","text":"The FTL table contains some data used by FTL DNS for determining which queries to save to the database. This table does not contain any entries of general interest.","title":"FTL table"},{"location":"pi-hole/database/ftl/#supported-query-types","text":"ID Resource Record (a.k.a. query type) 1 A 2 AAAA 3 ANY 4 SRV 5 SOA 6 PTR 7 TXT 8 NAPTR 9 MX 10 DS 11 RRSIG 12 DNSKEY 13 NS 14 OTHER (any query type not covered elsewhere) 15 SVCB 16 HTTPS","title":"Supported query types"},{"location":"pi-hole/database/ftl/#supported-status-types","text":"ID Status Details 0 Unknown \u2754 Unknown status (not yet known) 1 Blocked \u274c Domain contained in gravity database 2 Allowed \u2705 Forwarded 3 Allowed \u2705 Known, replied to from cache 4 Blocked \u274c Domain matched by a regex blacklist filter 5 Blocked \u274c Domain contained in exact blacklist 6 Blocked \u274c By upstream server (known blocking page IP address) 7 Blocked \u274c By upstream server ( 0.0.0.0 or :: ) 8 Blocked \u274c By upstream server ( NXDOMAIN with RA bit unset) 9 Blocked \u274c Domain contained in gravity database Blocked during deep CNAME inspection 10 Blocked \u274c Domain matched by a regex blacklist filter Blocked during deep CNAME inspection 11 Blocked \u274c Domain contained in exact blacklist Blocked during deep CNAME inspection 12 Allowed \u2705 Retried query 13 Allowed \u2705 Retried but ignored query (this may happen during ongoing DNSSEC validation) 14 Allowed \u2705 Already forwarded, not forwarding again","title":"Supported status types"},{"location":"pi-hole/database/ftl/#supported-reply-types","text":"ID Reply type is 0 unknown (no reply so far) 1 NODATA 2 NXDOMAIN 3 CNAME 4 a valid IP record 5 DOMAIN 6 RRNAME 7 SERVFAIL 8 REFUSED 9 NOTIMP 10 OTHER 11 DNSSEC 12 NONE (query was dropped intentionally) 13 BLOB (binary data)","title":"Supported reply types"},{"location":"pi-hole/database/ftl/#dnssec-status","text":"ID DNSSEC status is 0 unknown 1 SECURE 2 INSECURE 3 BOGUS 4 ABANDONED","title":"DNSSEC status"},{"location":"pi-hole/database/ftl/#linking-tables","text":"The queries VIEW reads repeating properties from linked tables to reduce both database size and search complexity. These linking tables, domain_by_id , client_by_id , forward_by_id , and addinfo_by_id all have a similar structure:","title":"Linking tables"},{"location":"pi-hole/database/ftl/#domain_by_id","text":"Label Type Allowed to by empty Content id integer No ID of the entry. Used by query_storage domain text No Domain name","title":"domain_by_id"},{"location":"pi-hole/database/ftl/#client_by_id","text":"Label Type Allowed to by empty Content id integer No ID of the entry. Used by query_storage ip text No Client IP address name text Yes Client host name","title":"client_by_id"},{"location":"pi-hole/database/ftl/#forward_by_id","text":"Label Type Allowed to by empty Content id integer No ID of the entry. Used by query_storage forward text No Upstream server identifier ( <ipaddr>#<port> )","title":"forward_by_id"},{"location":"pi-hole/database/ftl/#addinfo_by_id","text":"Label Type Allowed to by empty Content id integer No ID of the entry. Used by query_storage type integer No Type of the content field content blob No Type-dependent content Valid type IDs are currently ADDINFO_CNAME_DOMAIN = 1 if content is a CNAME pointer, and ADDINFO_REGEX_ID = 2 if content is an integer ID pointing to a regular expression in gravity.db","title":"addinfo_by_id"},{"location":"pi-hole/database/ftl/#example-for-interaction-with-the-long-term-query-database","text":"In addition to the interactions the Pi-hole database API offers, you can also run your own SQL commands against the database. If you want to obtain the three most queries domains for all time, you could use sqlite3 \"/etc/pihole/pihole-FTL.db\" \"SELECT domain,count(domain) FROM queries WHERE (STATUS == 2 OR STATUS == 3) GROUP BY domain ORDER BY count(domain) DESC LIMIT 3\" which would return something like discourse.pi-hole.net|421095 www.pi-hole.net|132483 posteo.de|130243 showing the domain and the number of times it was found in the long-term database. Note that such a request might take a very long time for computation as the entire history of queries has to be processed for this.","title":"Example for interaction with the long-term query database"},{"location":"pi-hole/database/gravity/","text":"Pi-hole uses the well-known relational database management system SQLite3 for managing the various domains that are used to control the DNS filtering system. The database-based domain management has been added with Pi-hole v5.0. Domain tables ( domainlist ) \u00b6 The database stores white-, and blacklists which are directly relevant for Pi-hole's domain blocking behavior. The domainlist table contains all domains on the white- and blacklists. It has a few extra fields to store data related to a given domain such as the enabled state, the dates when the domain was added and when it was last modified, and an optional comment. The date fields are defined as INTEGER fields as they expect numerical timestamps also known as UNIX time . The date_added and date_modified fields are initialized with the current timestamp converted to UNIX time. The comment field is optional and can be empty. Pi-hole's FTL DNS reads the tables through the various view, omitting any disabled domains. Label Type Uniqueness enforced Content id integer Yes Unique ID for database operations type integer No 0 = exact whitelist, 1 = exact blacklist, 2 = regex whitelist, 3 = regex blacklist domain text Yes Domain enabled boolean No Flag whether domain should be used by pihole-FTL ( 0 = disabled, 1 = enabled) date_added integer No Timestamp when domain was added date_modified integer No Timestamp when domain was last modified, automatically updated when a record is changed comment text No Optional field for arbitrary user comments, only field that is allowed to be NULL Adlist Table ( adlist ) \u00b6 The adlist table contains all sources for domains to be collected by pihole -g . Just like the other tables, it has a few extra fields to store metadata related to a given source. Label Type Uniqueness enforced Content id integer Yes Unique ID for database operations address text Yes The URL of the list enabled boolean No Flag whether domain should be used by pihole-FTL ( 0 = disabled, 1 = enabled) date_added integer No Timestamp when domain was added date_modified integer No Timestamp when domain was last modified, automatically updated when a record is changed comment text No Optional field for arbitrary user comments date_updated integer No Timestamp when this list has last been updated ( pihole -g does not update this timestamp when the downloaded list did not change since the last pihole -g run) Gravity Table ( gravity ) \u00b6 The gravity table consists of the domains that have been processed by Pi-hole's gravity ( pihole -g ) command. The domains in this list are the collection of domains sourced from the configured sources (see the adlist table . During each run of pihole -g , this table is flushed and completely rebuilt from the newly obtained set of domains to be blocked. Label Type Content domain text Blocked domain compiled from adlist referenced by adlist_id adlist_id integer ID associated to adlists in table adlist Uniqueness is enforced on pairs of ( domain , adlist_id ). In other words: domains can be added multiple times, however, only when they are referencing different adlists as their origins. Client table ( client ) \u00b6 Clients are identified by their IP addresses. Each client automatically gets a unique identifier ( id ). Label Type Content id integer Client ID (autoincrementing) ip text IP address of the client (IPv4 or IPv6), Uniqueness is enforced date_added integer Timestamp when a client was added date_modified integer Timestamp when a client was last modified, automatically updated when a record is changed comment text Optional field for arbitrary user comments, the only field that is allowed to be NULL Clients can be identified by subnets. Arbitrary subnet configurations can be specified using the widely known Classless Inter-Domain Routing (CIDR) notation . This allows to specify \"broad clients\" such as 192.168.1.0/24 which will match al clients in the range 192.168.1.1 to 192.168.1.255 (256 devices), 10.8.0.0/16 will match all clients in the range 10.8.0.1 to 10.8.255.255 (65,536 devices), and 192.168.100.0/22 representing the 1024 IPv4 addresses from 192.168.100.0 to 192.168.103.255 . CIDR notation can be used for IPv6 subnets as well. The IPv6 block 2001:db8::/48 represents all IPv6 addresses from 2001:db8:0:0:0:0:0:0 to 2001:db8:0:ffff:ffff:ffff:ffff:ffff (1,208,925,819,614,629,174,706,176 = roughly one heptillion devices). Note that Pi-hole's implementation is more generic than what is written on the linked Wikipedia article as you can use any CIDR block (not only multiples of 4). Audit Table ( domain_audit ) \u00b6 The domain_audit table contains domains that have been audited by the user on the web interface. Label Type Uniqueness enforced Content id integer Yes Unique ID for database operations domain text Yes Domain date_added integer No Unix timestamp when domain was added","title":"Index"},{"location":"pi-hole/database/gravity/#domain-tables-domainlist","text":"The database stores white-, and blacklists which are directly relevant for Pi-hole's domain blocking behavior. The domainlist table contains all domains on the white- and blacklists. It has a few extra fields to store data related to a given domain such as the enabled state, the dates when the domain was added and when it was last modified, and an optional comment. The date fields are defined as INTEGER fields as they expect numerical timestamps also known as UNIX time . The date_added and date_modified fields are initialized with the current timestamp converted to UNIX time. The comment field is optional and can be empty. Pi-hole's FTL DNS reads the tables through the various view, omitting any disabled domains. Label Type Uniqueness enforced Content id integer Yes Unique ID for database operations type integer No 0 = exact whitelist, 1 = exact blacklist, 2 = regex whitelist, 3 = regex blacklist domain text Yes Domain enabled boolean No Flag whether domain should be used by pihole-FTL ( 0 = disabled, 1 = enabled) date_added integer No Timestamp when domain was added date_modified integer No Timestamp when domain was last modified, automatically updated when a record is changed comment text No Optional field for arbitrary user comments, only field that is allowed to be NULL","title":"Domain tables (domainlist)"},{"location":"pi-hole/database/gravity/#adlist-table-adlist","text":"The adlist table contains all sources for domains to be collected by pihole -g . Just like the other tables, it has a few extra fields to store metadata related to a given source. Label Type Uniqueness enforced Content id integer Yes Unique ID for database operations address text Yes The URL of the list enabled boolean No Flag whether domain should be used by pihole-FTL ( 0 = disabled, 1 = enabled) date_added integer No Timestamp when domain was added date_modified integer No Timestamp when domain was last modified, automatically updated when a record is changed comment text No Optional field for arbitrary user comments date_updated integer No Timestamp when this list has last been updated ( pihole -g does not update this timestamp when the downloaded list did not change since the last pihole -g run)","title":"Adlist Table (adlist)"},{"location":"pi-hole/database/gravity/#gravity-table-gravity","text":"The gravity table consists of the domains that have been processed by Pi-hole's gravity ( pihole -g ) command. The domains in this list are the collection of domains sourced from the configured sources (see the adlist table . During each run of pihole -g , this table is flushed and completely rebuilt from the newly obtained set of domains to be blocked. Label Type Content domain text Blocked domain compiled from adlist referenced by adlist_id adlist_id integer ID associated to adlists in table adlist Uniqueness is enforced on pairs of ( domain , adlist_id ). In other words: domains can be added multiple times, however, only when they are referencing different adlists as their origins.","title":"Gravity Table (gravity)"},{"location":"pi-hole/database/gravity/#client-table-client","text":"Clients are identified by their IP addresses. Each client automatically gets a unique identifier ( id ). Label Type Content id integer Client ID (autoincrementing) ip text IP address of the client (IPv4 or IPv6), Uniqueness is enforced date_added integer Timestamp when a client was added date_modified integer Timestamp when a client was last modified, automatically updated when a record is changed comment text Optional field for arbitrary user comments, the only field that is allowed to be NULL Clients can be identified by subnets. Arbitrary subnet configurations can be specified using the widely known Classless Inter-Domain Routing (CIDR) notation . This allows to specify \"broad clients\" such as 192.168.1.0/24 which will match al clients in the range 192.168.1.1 to 192.168.1.255 (256 devices), 10.8.0.0/16 will match all clients in the range 10.8.0.1 to 10.8.255.255 (65,536 devices), and 192.168.100.0/22 representing the 1024 IPv4 addresses from 192.168.100.0 to 192.168.103.255 . CIDR notation can be used for IPv6 subnets as well. The IPv6 block 2001:db8::/48 represents all IPv6 addresses from 2001:db8:0:0:0:0:0:0 to 2001:db8:0:ffff:ffff:ffff:ffff:ffff (1,208,925,819,614,629,174,706,176 = roughly one heptillion devices). Note that Pi-hole's implementation is more generic than what is written on the linked Wikipedia article as you can use any CIDR block (not only multiples of 4).","title":"Client table (client)"},{"location":"pi-hole/database/gravity/#audit-table-domain_audit","text":"The domain_audit table contains domains that have been audited by the user on the web interface. Label Type Uniqueness enforced Content id integer Yes Unique ID for database operations domain text Yes Domain date_added integer No Unix timestamp when domain was added","title":"Audit Table (domain_audit)"},{"location":"pi-hole/database/gravity/example/","text":"Per-client blocking example \u00b6 In this example, we describe how to set up a blocking rule for three specific clients. All remaining (and newly added) clients in the network are \"unmanaged\", i.e., they use Pi-hole as usual. The examples shown here are built upon each other, i.e., example 5 might make no sense without the context of example 3. Don't forget to run pihole restartdns reload-lists after your database modifications to have FTL flush its internal domain-blocking cache (separate from the DNS cache). Prerequisites \u00b6 Add three groups. The Default group has a special meaning and cannot be deleted. All domains, clients, and adlists without a specific group assignment are automatically managed through this group. Disabling this group will disable Pi-hole blocking for all unmanaged devices. Raw database instructions INSERT INTO \"group\" ( id , name ) VALUES ( 1 , 'Group 1' ); INSERT INTO \"group\" ( id , name ) VALUES ( 2 , 'Group 2' ); INSERT INTO \"group\" ( id , name ) VALUES ( 3 , 'Group 3' ); Add three clients. Add three clients at your will, their IP addresses might differ from the ones in this example. Raw database instructions INSERT INTO client ( id , ip ) VALUES ( 1 , '192.168.0.101' ); INSERT INTO client ( id , ip ) VALUES ( 2 , '192.168.0.102' ); INSERT INTO client ( id , ip ) VALUES ( 3 , '192.168.0.103' ); Link the clients to the created groups. Raw database instructions INSERT INTO client_by_group ( client_id , group_id ) VALUES ( 1 , 1 ); INSERT INTO client_by_group ( client_id , group_id ) VALUES ( 2 , 2 ); INSERT INTO client_by_group ( client_id , group_id ) VALUES ( 3 , 3 ); Example 1: Exclude from blocking \u00b6 Task: Exclude client 1 from Pi-hole's blocking by removing client 1 from the Default group. Raw database instructions DELETE FROM client_by_group WHERE client_id = 1 AND group_id = 0 ; Result Client Group membership Domain Blocked all other Default doubleclick.net Yes 192.168.0.101 Group 1 doubleclick.net No 192.168.0.102 Group 2 + Default doubleclick.net Yes 192.168.0.103 Group 3 + Default doubleclick.net Yes All three clients got automatically assigned to the default ( Default ) group when they were added. The default group includes all adlists and list domains (if not already changed by the user). When we remove the default group for client 192.168.0.101 , we effectively remove all associations to any adlists and domains. This leaves this client completely unblocked. Example 2: Blocklist management \u00b6 Task: Assign adlist with ID 1 to group 1 (in addition to the default assignment to group 0). This results in client 192.168.0.101 using only this adlist (we removed the default association in the last step). Raw database instructions INSERT INTO adlist_by_group ( adlist_id , group_id ) VALUES ( 1 , 1 ); Result Client Group membership Domain Blocked all other Default doubleclick.net Yes 192.168.0.101 Group 1 doubleclick.net Yes 192.168.0.102 Group 2 + Default doubleclick.net Yes 192.168.0.103 Group 3 + Default doubleclick.net Yes 192.168.0.101 gets doubleclick.net blocked as it uses an adlist including this domain. All other clients stay unchanged. Example 3: Blacklisting \u00b6 Task: Add a single domain that should be blacklisted only for group 1 (client 192.168.0.101 ). Step 1 \u00b6 Add the domain to be blocked Raw database instructions INSERT INTO domainlist ( type , domain , comment ) VALUES ( 1 , 'blacklisted.com' , 'Blacklisted for members of group 1' ); Result Client Group membership Domain Blocked all other Default blacklisted.com Yes 192.168.0.101 Group 1 blacklisted.com No 192.168.0.102 Group 2 + Default blacklisted.com Yes 192.168.0.103 Group 3 + Default blacklisted.com Yes Note that Pi-hole is not blocking this domain for client 192.168.0.101 as we removed the default assignment through group 0 above. All remaining clients are linked through the Default group to this domain and see it as being blocked. Step 2 \u00b6 Assign this domain to group 1 Raw database instructions INSERT INTO domainlist_by_group ( domainlist_id , group_id ) VALUES ( 1 , 1 ); (the domainlist_id might be different for you, check with SELECT last_insert_rowid(); after step 1) Result Client Group membership Domain Blocked all other Default blacklisted.com Yes 192.168.0.101 Group 1 blacklisted.com Yes 192.168.0.102 Group 2 + Default blacklisted.com Yes 192.168.0.103 Group 3 + Default blacklisted.com Yes All clients see this domain as being blocked: Client 1 due to a direct assignment through group 1, all remaining clients through the default group 0 (unchanged). Step 3 \u00b6 Remove default assignment to all clients not belonging to a group Raw database instructions DELETE FROM domainlist_by_group WHERE domainlist_id = 1 AND group_id = 0 ; (the domainlist_id might be different for you, see above) Result Client Group membership Domain Blocked all other Default blacklisted.com No 192.168.0.101 Group 1 blacklisted.com Yes 192.168.0.102 Group 2 + Default blacklisted.com No 192.168.0.103 Group 3 + Default blacklisted.com No While client 1 keeps its explicit assignment through group 1, the remaining clients lost their unassignments when we removed group 0 from the assignment. Example 4: Whitelisting \u00b6 Task: Add a single domain that should be whitelisted only for group 2 (client 192.168.0.102 ). Step 1 \u00b6 Add the domain to be whitelisted Raw database instructions INSERT INTO domainlist ( type , domain , comment ) VALUES ( 0 , 'doubleclick.net' , 'Whitelisted for members of group 2' ); Result Client Group membership Domain Blocked all other Default doubleclick.net No 192.168.0.101 Group 1 doubleclick.net Yes 192.168.0.102 Group 2 + Default doubleclick.net No 192.168.0.103 Group 3 + Default doubleclick.net No Client 192.168.0.101 is not whitelisting this domain as we removed the default assignment through group 0 above. All remaining clients are linked through the default group to this domain and see it as being whitelisted. Note that this is completely analog to step 1 of example 3 . Step 2 \u00b6 Remove default group assignment Raw database instructions DELETE FROM domainlist_by_group WHERE domainlist_id = 2 AND group_id = 0 ; Result Client Group membership Domain Blocked all other Default doubleclick.net Yes 192.168.0.101 Group 1 doubleclick.net Yes 192.168.0.102 Group 2 + Default doubleclick.net Yes 192.168.0.103 Group 3 + Default doubleclick.net Yes Requests from all clients are blocked as the new whitelist entry is not associated with any group and, hence, is not used by any client. Step 3 \u00b6 Assign this domain to group 2 Raw database instructions INSERT INTO domainlist_by_group ( domainlist_id , group_id ) VALUES ( 2 , 2 ); (the domainlist_id might be different for you, check with SELECT last_insert_rowid(); after step 1) Result Client Group membership Domain Blocked all other Default doubleclick.net Yes 192.168.0.101 Group 1 doubleclick.net Yes 192.168.0.102 Group 2 + Default doubleclick.net No 192.168.0.103 Group 3 + Default doubleclick.net Yes Client 2 got the whitelist entry explicitly assigned to. Accordingly, client 2 does not get the domain blocked whereas all remaining clients still see this domain as blocked.","title":"Per-client blocking example"},{"location":"pi-hole/database/gravity/example/#per-client-blocking-example","text":"In this example, we describe how to set up a blocking rule for three specific clients. All remaining (and newly added) clients in the network are \"unmanaged\", i.e., they use Pi-hole as usual. The examples shown here are built upon each other, i.e., example 5 might make no sense without the context of example 3. Don't forget to run pihole restartdns reload-lists after your database modifications to have FTL flush its internal domain-blocking cache (separate from the DNS cache).","title":"Per-client blocking example"},{"location":"pi-hole/database/gravity/example/#prerequisites","text":"Add three groups. The Default group has a special meaning and cannot be deleted. All domains, clients, and adlists without a specific group assignment are automatically managed through this group. Disabling this group will disable Pi-hole blocking for all unmanaged devices. Raw database instructions INSERT INTO \"group\" ( id , name ) VALUES ( 1 , 'Group 1' ); INSERT INTO \"group\" ( id , name ) VALUES ( 2 , 'Group 2' ); INSERT INTO \"group\" ( id , name ) VALUES ( 3 , 'Group 3' ); Add three clients. Add three clients at your will, their IP addresses might differ from the ones in this example. Raw database instructions INSERT INTO client ( id , ip ) VALUES ( 1 , '192.168.0.101' ); INSERT INTO client ( id , ip ) VALUES ( 2 , '192.168.0.102' ); INSERT INTO client ( id , ip ) VALUES ( 3 , '192.168.0.103' ); Link the clients to the created groups. Raw database instructions INSERT INTO client_by_group ( client_id , group_id ) VALUES ( 1 , 1 ); INSERT INTO client_by_group ( client_id , group_id ) VALUES ( 2 , 2 ); INSERT INTO client_by_group ( client_id , group_id ) VALUES ( 3 , 3 );","title":"Prerequisites"},{"location":"pi-hole/database/gravity/example/#example-1-exclude-from-blocking","text":"Task: Exclude client 1 from Pi-hole's blocking by removing client 1 from the Default group. Raw database instructions DELETE FROM client_by_group WHERE client_id = 1 AND group_id = 0 ; Result Client Group membership Domain Blocked all other Default doubleclick.net Yes 192.168.0.101 Group 1 doubleclick.net No 192.168.0.102 Group 2 + Default doubleclick.net Yes 192.168.0.103 Group 3 + Default doubleclick.net Yes All three clients got automatically assigned to the default ( Default ) group when they were added. The default group includes all adlists and list domains (if not already changed by the user). When we remove the default group for client 192.168.0.101 , we effectively remove all associations to any adlists and domains. This leaves this client completely unblocked.","title":"Example 1: Exclude from blocking"},{"location":"pi-hole/database/gravity/example/#example-2-blocklist-management","text":"Task: Assign adlist with ID 1 to group 1 (in addition to the default assignment to group 0). This results in client 192.168.0.101 using only this adlist (we removed the default association in the last step). Raw database instructions INSERT INTO adlist_by_group ( adlist_id , group_id ) VALUES ( 1 , 1 ); Result Client Group membership Domain Blocked all other Default doubleclick.net Yes 192.168.0.101 Group 1 doubleclick.net Yes 192.168.0.102 Group 2 + Default doubleclick.net Yes 192.168.0.103 Group 3 + Default doubleclick.net Yes 192.168.0.101 gets doubleclick.net blocked as it uses an adlist including this domain. All other clients stay unchanged.","title":"Example 2: Blocklist management"},{"location":"pi-hole/database/gravity/example/#example-3-blacklisting","text":"Task: Add a single domain that should be blacklisted only for group 1 (client 192.168.0.101 ).","title":"Example 3: Blacklisting"},{"location":"pi-hole/database/gravity/example/#step-1","text":"Add the domain to be blocked Raw database instructions INSERT INTO domainlist ( type , domain , comment ) VALUES ( 1 , 'blacklisted.com' , 'Blacklisted for members of group 1' ); Result Client Group membership Domain Blocked all other Default blacklisted.com Yes 192.168.0.101 Group 1 blacklisted.com No 192.168.0.102 Group 2 + Default blacklisted.com Yes 192.168.0.103 Group 3 + Default blacklisted.com Yes Note that Pi-hole is not blocking this domain for client 192.168.0.101 as we removed the default assignment through group 0 above. All remaining clients are linked through the Default group to this domain and see it as being blocked.","title":"Step 1"},{"location":"pi-hole/database/gravity/example/#step-2","text":"Assign this domain to group 1 Raw database instructions INSERT INTO domainlist_by_group ( domainlist_id , group_id ) VALUES ( 1 , 1 ); (the domainlist_id might be different for you, check with SELECT last_insert_rowid(); after step 1) Result Client Group membership Domain Blocked all other Default blacklisted.com Yes 192.168.0.101 Group 1 blacklisted.com Yes 192.168.0.102 Group 2 + Default blacklisted.com Yes 192.168.0.103 Group 3 + Default blacklisted.com Yes All clients see this domain as being blocked: Client 1 due to a direct assignment through group 1, all remaining clients through the default group 0 (unchanged).","title":"Step 2"},{"location":"pi-hole/database/gravity/example/#step-3","text":"Remove default assignment to all clients not belonging to a group Raw database instructions DELETE FROM domainlist_by_group WHERE domainlist_id = 1 AND group_id = 0 ; (the domainlist_id might be different for you, see above) Result Client Group membership Domain Blocked all other Default blacklisted.com No 192.168.0.101 Group 1 blacklisted.com Yes 192.168.0.102 Group 2 + Default blacklisted.com No 192.168.0.103 Group 3 + Default blacklisted.com No While client 1 keeps its explicit assignment through group 1, the remaining clients lost their unassignments when we removed group 0 from the assignment.","title":"Step 3"},{"location":"pi-hole/database/gravity/example/#example-4-whitelisting","text":"Task: Add a single domain that should be whitelisted only for group 2 (client 192.168.0.102 ).","title":"Example 4: Whitelisting"},{"location":"pi-hole/database/gravity/example/#step-1_1","text":"Add the domain to be whitelisted Raw database instructions INSERT INTO domainlist ( type , domain , comment ) VALUES ( 0 , 'doubleclick.net' , 'Whitelisted for members of group 2' ); Result Client Group membership Domain Blocked all other Default doubleclick.net No 192.168.0.101 Group 1 doubleclick.net Yes 192.168.0.102 Group 2 + Default doubleclick.net No 192.168.0.103 Group 3 + Default doubleclick.net No Client 192.168.0.101 is not whitelisting this domain as we removed the default assignment through group 0 above. All remaining clients are linked through the default group to this domain and see it as being whitelisted. Note that this is completely analog to step 1 of example 3 .","title":"Step 1"},{"location":"pi-hole/database/gravity/example/#step-2_1","text":"Remove default group assignment Raw database instructions DELETE FROM domainlist_by_group WHERE domainlist_id = 2 AND group_id = 0 ; Result Client Group membership Domain Blocked all other Default doubleclick.net Yes 192.168.0.101 Group 1 doubleclick.net Yes 192.168.0.102 Group 2 + Default doubleclick.net Yes 192.168.0.103 Group 3 + Default doubleclick.net Yes Requests from all clients are blocked as the new whitelist entry is not associated with any group and, hence, is not used by any client.","title":"Step 2"},{"location":"pi-hole/database/gravity/example/#step-3_1","text":"Assign this domain to group 2 Raw database instructions INSERT INTO domainlist_by_group ( domainlist_id , group_id ) VALUES ( 2 , 2 ); (the domainlist_id might be different for you, check with SELECT last_insert_rowid(); after step 1) Result Client Group membership Domain Blocked all other Default doubleclick.net Yes 192.168.0.101 Group 1 doubleclick.net Yes 192.168.0.102 Group 2 + Default doubleclick.net No 192.168.0.103 Group 3 + Default doubleclick.net Yes Client 2 got the whitelist entry explicitly assigned to. Accordingly, client 2 does not get the domain blocked whereas all remaining clients still see this domain as blocked.","title":"Step 3"},{"location":"pi-hole/database/gravity/groups/","text":"Group management \u00b6 Any blocklist or domain on the white-/black-/regex-lists can be managed through groups. This allows not only grouping them to highlight their relationship, but also enabling/disabling them together if one, for instance, wants to visit a specific service only temporarily. Groups are defined in the group table and can have an optional description in addition to the mandatory name of the group. Label Type Uniqueness enforced Content id integer Yes Unique ID for database operations enabled boolean No Flag whether domains in this group should be used ( 0 = disabled, 1 = enabled) name text Yes Mandatory group name description text No Optional field for arbitrary user comments Group management is implemented using so-called linking tables. Hence, it is possible to associate domains (and clients!) with any number of groups, manage adlists together with groups, use the same groups for black- and whitelisted domains at the same time. The linking tables are particularly simple, as they only link group id s with list id s. As an example, we describe the domainlist_by_group table. The adlist and client linking tables are constructed similarly. Label Type Content domainlist_id integer id of domain in the domainlist table group_id integer id of associated group in the group table Group Default ( group_id 0 ) is special as it is automatically assigned to domains and clients not being a member of other groups. Each newly added client or domain gets assigned to group zero when being added. Effect of group management \u00b6 The great flexibility to manage domains in zero, one, or multiple groups may result in unexpected behavior when, e.g., the domains are enabled in some but disabled in other groups. For the sake of convenience, we describe the possible configurations and whether FTL DNS uses these domains (\u2714) or not (\u2718) in such cases. Domain disabled: \u2718 Note that the domain is never imported by FTL DNS, even if it is contained in an enabled group. Domain enabled: It depends... Not managed by a group: \u2714 Contained in one or more groups (at least one enabled): \u2714 Contained in one or more groups (all disabled): \u2718","title":"Groups"},{"location":"pi-hole/database/gravity/groups/#group-management","text":"Any blocklist or domain on the white-/black-/regex-lists can be managed through groups. This allows not only grouping them to highlight their relationship, but also enabling/disabling them together if one, for instance, wants to visit a specific service only temporarily. Groups are defined in the group table and can have an optional description in addition to the mandatory name of the group. Label Type Uniqueness enforced Content id integer Yes Unique ID for database operations enabled boolean No Flag whether domains in this group should be used ( 0 = disabled, 1 = enabled) name text Yes Mandatory group name description text No Optional field for arbitrary user comments Group management is implemented using so-called linking tables. Hence, it is possible to associate domains (and clients!) with any number of groups, manage adlists together with groups, use the same groups for black- and whitelisted domains at the same time. The linking tables are particularly simple, as they only link group id s with list id s. As an example, we describe the domainlist_by_group table. The adlist and client linking tables are constructed similarly. Label Type Content domainlist_id integer id of domain in the domainlist table group_id integer id of associated group in the group table Group Default ( group_id 0 ) is special as it is automatically assigned to domains and clients not being a member of other groups. Each newly added client or domain gets assigned to group zero when being added.","title":"Group management"},{"location":"pi-hole/database/gravity/groups/#effect-of-group-management","text":"The great flexibility to manage domains in zero, one, or multiple groups may result in unexpected behavior when, e.g., the domains are enabled in some but disabled in other groups. For the sake of convenience, we describe the possible configurations and whether FTL DNS uses these domains (\u2714) or not (\u2718) in such cases. Domain disabled: \u2718 Note that the domain is never imported by FTL DNS, even if it is contained in an enabled group. Domain enabled: It depends... Not managed by a group: \u2714 Contained in one or more groups (at least one enabled): \u2714 Contained in one or more groups (all disabled): \u2718","title":"Effect of group management"},{"location":"pi-hole/database/gravity/recovery/","text":"If the gravity.db database has been damaged, Pi-hole offers two built-in methods to repair the database. Recover \u00b6 Try to recover a damaged gravity database file. Pi-hole tries to restore as much as possible from a corrupted gravity database. Run: pihole -g -r recover Recreate \u00b6 Create a new gravity database file from scratch. This will remove your existing gravity database and create a new file from scratch. If you still have the migration backup created when migrating to Pi-hole v5.0, Pi-hole will import these files. Run: pihole -g -r recreate Force recover (not recommended) \u00b6 Warning This option is meant to be a last resort. Recovery is a fragile task consuming a lot of resources and shouldn't be performed unnecessarily. Force Pi-hole to run the recovery process even when no damage is detected. Run: pihole -g -r recover force","title":"Recovery"},{"location":"pi-hole/database/gravity/recovery/#recover","text":"Try to recover a damaged gravity database file. Pi-hole tries to restore as much as possible from a corrupted gravity database. Run: pihole -g -r recover","title":"Recover"},{"location":"pi-hole/database/gravity/recovery/#recreate","text":"Create a new gravity database file from scratch. This will remove your existing gravity database and create a new file from scratch. If you still have the migration backup created when migrating to Pi-hole v5.0, Pi-hole will import these files. Run: pihole -g -r recreate","title":"Recreate"},{"location":"pi-hole/database/gravity/recovery/#force-recover-not-recommended","text":"Warning This option is meant to be a last resort. Recovery is a fragile task consuming a lot of resources and shouldn't be performed unnecessarily. Force Pi-hole to run the recovery process even when no damage is detected. Run: pihole -g -r recover force","title":"Force recover (not recommended)"},{"location":"pi-hole/docker/DHCP/","text":"Docker DHCP and Network Modes \u00b6 Docker runs in a separate network by default called a docker bridge network, which makes DHCP want to serve addresses to that network and not your LAN network where you probably want it. This document details why Docker Pi-hole DHCP is different from normal Pi-hole and how to fix the problem. Technical details \u00b6 Docker's bridge network mode is default and recommended as a more secure setting for containers because docker is all about isolation, they isolate processes by default and the bridge network isolates the networking by default too. You gain access to the isolated container's service ports by using port forwards in your container's runtime config; for example -p 67:67 is DHCP. However, DHCP protocol operates through a network 'broadcast' which cannot span multiple networks (docker's bridge, and your LAN network). In order to get DHCP on to your network there are a few approaches: Working network modes \u00b6 Here are details on setting up DHCP for Docker Pi-hole for various network modes available in docker. Docker Pi-hole with host networking mode \u00b6 Advantages : Simple, easy, and fast setup Possibly the simplest way to get DHCP working with Docker Pi-hole is to use host networking which makes the container be on your LAN Network like a regular Raspberry Pi-hole would be, allowing it to broadcast DHCP. It will have the same IP as your Docker host server in this mode so you may still have to deal with port conflicts. Inside your docker-compose.yml remove all ports and replace them with: network_mode: host docker run --net=host if you don't use docker-compose Docker Pi-hole with a Macvlan network \u00b6 Advantages : Works well with NAS devices or hard port conflicts A Macvlan network is the most advanced option since it requires more network knowledge and setup. This mode is similar to host network mode but instead of borrowing the IP of your docker host computer it grabs a new IP address off your LAN network. Having the container get its own IP not only solves the broadcast problem but avoids port conflicts you might have on devices such as NAS devices with web interfaces. Tony Lawrence detailed macvlan setup for Pi-hole first in the second part of his great blog series about Running Pi-hole on Synology Docker , check it out here: Free your Synology ports with Macvlan Docker Pi-hole with a bridge networking \u00b6 Advantages : Works well with container web reverse proxies like Nginx or Traefik If you want to use docker's bridged network mode then you need to run a DHCP relay. A relay points to your containers forwarded port 67 and spreads the broadcast signal from an isolated docker bridge onto your LAN network. Relays are very simple software, you just have to configure it to point to your Docker host's IP port 67. Although uncommon, if your router is an advanced enough router it may support a DHCP relay. Try googling for your router manufacturer + DHCP relay or looking in your router's configuration around the DHCP settings or advanced areas. If your router doesn't support it, you can run a software/container based DHCP relay on your LAN instead. The author of dnsmasq made a very tiny simple one called DHCP-helper . DerFetzer kindly shared his great setup of a DHCP-helper container on the Pi-hole Discourse forums. Warning about the Default bridge network \u00b6 The out of the box default bridge network has some limitations that a user created bridge network won't have. These limitations make it painful to use especially when connecting multiple containers together. Avoid using the built-in default docker bridge network, the simplest way to do this is just use a docker-compose setup since it creates its own network automatically. If compose isn't an option the bridge network docs should help you create your own.","title":"Docker DHCP and Network Modes"},{"location":"pi-hole/docker/DHCP/#docker-dhcp-and-network-modes","text":"Docker runs in a separate network by default called a docker bridge network, which makes DHCP want to serve addresses to that network and not your LAN network where you probably want it. This document details why Docker Pi-hole DHCP is different from normal Pi-hole and how to fix the problem.","title":"Docker DHCP and Network Modes"},{"location":"pi-hole/docker/DHCP/#technical-details","text":"Docker's bridge network mode is default and recommended as a more secure setting for containers because docker is all about isolation, they isolate processes by default and the bridge network isolates the networking by default too. You gain access to the isolated container's service ports by using port forwards in your container's runtime config; for example -p 67:67 is DHCP. However, DHCP protocol operates through a network 'broadcast' which cannot span multiple networks (docker's bridge, and your LAN network). In order to get DHCP on to your network there are a few approaches:","title":"Technical details"},{"location":"pi-hole/docker/DHCP/#working-network-modes","text":"Here are details on setting up DHCP for Docker Pi-hole for various network modes available in docker.","title":"Working network modes"},{"location":"pi-hole/docker/DHCP/#docker-pi-hole-with-host-networking-mode","text":"Advantages : Simple, easy, and fast setup Possibly the simplest way to get DHCP working with Docker Pi-hole is to use host networking which makes the container be on your LAN Network like a regular Raspberry Pi-hole would be, allowing it to broadcast DHCP. It will have the same IP as your Docker host server in this mode so you may still have to deal with port conflicts. Inside your docker-compose.yml remove all ports and replace them with: network_mode: host docker run --net=host if you don't use docker-compose","title":"Docker Pi-hole with host networking mode"},{"location":"pi-hole/docker/DHCP/#docker-pi-hole-with-a-macvlan-network","text":"Advantages : Works well with NAS devices or hard port conflicts A Macvlan network is the most advanced option since it requires more network knowledge and setup. This mode is similar to host network mode but instead of borrowing the IP of your docker host computer it grabs a new IP address off your LAN network. Having the container get its own IP not only solves the broadcast problem but avoids port conflicts you might have on devices such as NAS devices with web interfaces. Tony Lawrence detailed macvlan setup for Pi-hole first in the second part of his great blog series about Running Pi-hole on Synology Docker , check it out here: Free your Synology ports with Macvlan","title":"Docker Pi-hole with a Macvlan network"},{"location":"pi-hole/docker/DHCP/#docker-pi-hole-with-a-bridge-networking","text":"Advantages : Works well with container web reverse proxies like Nginx or Traefik If you want to use docker's bridged network mode then you need to run a DHCP relay. A relay points to your containers forwarded port 67 and spreads the broadcast signal from an isolated docker bridge onto your LAN network. Relays are very simple software, you just have to configure it to point to your Docker host's IP port 67. Although uncommon, if your router is an advanced enough router it may support a DHCP relay. Try googling for your router manufacturer + DHCP relay or looking in your router's configuration around the DHCP settings or advanced areas. If your router doesn't support it, you can run a software/container based DHCP relay on your LAN instead. The author of dnsmasq made a very tiny simple one called DHCP-helper . DerFetzer kindly shared his great setup of a DHCP-helper container on the Pi-hole Discourse forums.","title":"Docker Pi-hole with a bridge networking"},{"location":"pi-hole/docker/DHCP/#warning-about-the-default-bridge-network","text":"The out of the box default bridge network has some limitations that a user created bridge network won't have. These limitations make it painful to use especially when connecting multiple containers together. Avoid using the built-in default docker bridge network, the simplest way to do this is just use a docker-compose setup since it creates its own network automatically. If compose isn't an option the bridge network docs should help you create your own.","title":"Warning about the Default bridge network"},{"location":"pi-hole/ftldns/","text":"powered by Pi-hole\u00ae FTL DNS \u2122 ( pihole-FTL ) offers DNS services within the Pi-hole \u00ae project. It provides blazing fast DNS and DHCP services. It can also provide TFTP and more as the resolver part based on the popular dnsmasq . Furthermore, FTL offers an interactive API where extensive network analysis data and statistics may be queried.","title":"Index"},{"location":"pi-hole/ftldns/blockingmode/","text":"Pi-hole FTL DNS supports two different methods for blocking queries. Both have their advantages and drawbacks. They are summarized on this page. The blocking mode can be configured in /etc/pihole/pihole-FTL.conf . This setting can be updated by sending SIGHUP to pihole-FTL ( sudo killall -SIGHUP pihole-FTL ). Pi-hole's unspecified IP blocking (default) \u00b6 /etc/pihole/pihole-FTL.conf setting: BLOCKINGMODE=NULL Blocked queries will be answered with the unspecified address ;; QUESTION SECTION: ;doubleclick.net. IN ANY ;; ANSWER SECTION: doubleclick.net. 2 IN A 0.0.0.0 doubleclick.net. 2 IN AAAA :: This blocking mode is the Pi-hole developers' recommendation. Following RFC 3513, Internet Protocol Version 6 (IPv6) Addressing Architecture, section 2.5.2 , the address 0:0:0:0:0:0:0:0 (or :: for short) is the unspecified address. It must never be assigned to any node and indicates the absence of an address. Following RFC1122, section 3.2 , the address 0.0.0.0 can be understood as the IPv4 equivalent of :: . Advantages \u00b6 The client does not even try to establish a connection for the requested website Speedup and less traffic Solves potential HTTPS timeouts as requests are never performed No need to run a web server on your Pi-hole (reduces complexity when running other web services on the same machine) Disadvantage \u00b6 Blocking page cannot be shown and whitelisting has to be performed from the dashboard or CLI Pi-hole's IP (IPv6 NODATA) blocking \u00b6 Warning The block page can only be displayed for unencrypted http connections. Since the majority of web pages today are accessed over encrypted https connections, no block page will be displayed. This option may be removed in the future. /etc/pihole/pihole-FTL.conf setting: BLOCKINGMODE=IP-NODATA-AAAA Blocked queries will be answered with the local IPv4 addresses of your Pi-hole (see BLOCK_IP4 for additional options). Blocked AAAA queries will be answered with NODATA-IPV6 and clients will only try to reach your Pi-hole over its static IPv4 address ;; QUESTION SECTION: ;doubleclick.net. IN ANY ;; ANSWER SECTION: doubleclick.net. 2 IN A 192.168.2.11 Advantage \u00b6 Shows a blocking page from which blocked domains can be whitelisted Serves IPv4-only replies and hence mitigates issues with rotating IPv6 prefixes Disadvantages \u00b6 Requires a web server to run on your Pi-hole May cause time-outs for HTTPS content even with properly configured firewall rules Pi-hole's full IP blocking \u00b6 Warning The block page can only be displayed for unencrypted http connections. Since the majority of web pages today are accessed over encrypted https connections, no block page will be displayed. This option may be removed in the future. /etc/pihole/pihole-FTL.conf setting: BLOCKINGMODE=IP Blocked queries will be answered with the local IP addresses of your Pi-hole (see BLOCK_IP4 and BLOCK_IP6 for additional options) ;; QUESTION SECTION: ;doubleclick.net. IN ANY ;; ANSWER SECTION: doubleclick.net. 2 IN A 192.168.2.11 doubleclick.net. 2 IN AAAA fda2:2001:4756:0:ab27:beff:ef37:4242 Advantage \u00b6 Shows a blocking page from which blocked domains can be whitelisted Disadvantages \u00b6 Requires a web server to run on your Pi-hole May cause time-outs for HTTPS content even with properly configured firewall rules May cause problems with alternating prefixes on IPv6 addresses (see IP-AAAA-NODATA ) Pi-hole's NXDOMAIN blocking \u00b6 /etc/pihole/pihole-FTL.conf setting: BLOCKINGMODE=NXDOMAIN Blocked queries will be answered with an empty response (no answer section) and status NXDOMAIN ( no such domain ) ;; QUESTION SECTION: ;doubleclick.net. IN ANY Advantages & Disadvantages \u00b6 Similar to NULL blocking, but experiments suggest that clients may try to resolve blocked domains more often compared to NULL blocking. Pi-hole's NODATA blocking \u00b6 /etc/pihole/pihole-FTL.conf setting: BLOCKINGMODE=NODATA Blocked queries will be answered with an empty response (no answer section) and status NODATA (domain exists but there is no record for the requested query type) ;; QUESTION SECTION: ;doubleclick.net. IN ANY Advantages & Disadvantages \u00b6 Similar to NXDOMAIN blocking. Clients might have a better acceptance of NODATA replies compared to NXDOMAIN replies.","title":"Blockingmode"},{"location":"pi-hole/ftldns/blockingmode/#pi-holes-unspecified-ip-blocking-default","text":"/etc/pihole/pihole-FTL.conf setting: BLOCKINGMODE=NULL Blocked queries will be answered with the unspecified address ;; QUESTION SECTION: ;doubleclick.net. IN ANY ;; ANSWER SECTION: doubleclick.net. 2 IN A 0.0.0.0 doubleclick.net. 2 IN AAAA :: This blocking mode is the Pi-hole developers' recommendation. Following RFC 3513, Internet Protocol Version 6 (IPv6) Addressing Architecture, section 2.5.2 , the address 0:0:0:0:0:0:0:0 (or :: for short) is the unspecified address. It must never be assigned to any node and indicates the absence of an address. Following RFC1122, section 3.2 , the address 0.0.0.0 can be understood as the IPv4 equivalent of :: .","title":"Pi-hole's unspecified IP blocking (default)"},{"location":"pi-hole/ftldns/blockingmode/#advantages","text":"The client does not even try to establish a connection for the requested website Speedup and less traffic Solves potential HTTPS timeouts as requests are never performed No need to run a web server on your Pi-hole (reduces complexity when running other web services on the same machine)","title":"Advantages"},{"location":"pi-hole/ftldns/blockingmode/#disadvantage","text":"Blocking page cannot be shown and whitelisting has to be performed from the dashboard or CLI","title":"Disadvantage"},{"location":"pi-hole/ftldns/blockingmode/#pi-holes-ip-ipv6-nodata-blocking","text":"Warning The block page can only be displayed for unencrypted http connections. Since the majority of web pages today are accessed over encrypted https connections, no block page will be displayed. This option may be removed in the future. /etc/pihole/pihole-FTL.conf setting: BLOCKINGMODE=IP-NODATA-AAAA Blocked queries will be answered with the local IPv4 addresses of your Pi-hole (see BLOCK_IP4 for additional options). Blocked AAAA queries will be answered with NODATA-IPV6 and clients will only try to reach your Pi-hole over its static IPv4 address ;; QUESTION SECTION: ;doubleclick.net. IN ANY ;; ANSWER SECTION: doubleclick.net. 2 IN A 192.168.2.11","title":"Pi-hole's IP (IPv6 NODATA) blocking"},{"location":"pi-hole/ftldns/blockingmode/#advantage","text":"Shows a blocking page from which blocked domains can be whitelisted Serves IPv4-only replies and hence mitigates issues with rotating IPv6 prefixes","title":"Advantage"},{"location":"pi-hole/ftldns/blockingmode/#disadvantages","text":"Requires a web server to run on your Pi-hole May cause time-outs for HTTPS content even with properly configured firewall rules","title":"Disadvantages"},{"location":"pi-hole/ftldns/blockingmode/#pi-holes-full-ip-blocking","text":"Warning The block page can only be displayed for unencrypted http connections. Since the majority of web pages today are accessed over encrypted https connections, no block page will be displayed. This option may be removed in the future. /etc/pihole/pihole-FTL.conf setting: BLOCKINGMODE=IP Blocked queries will be answered with the local IP addresses of your Pi-hole (see BLOCK_IP4 and BLOCK_IP6 for additional options) ;; QUESTION SECTION: ;doubleclick.net. IN ANY ;; ANSWER SECTION: doubleclick.net. 2 IN A 192.168.2.11 doubleclick.net. 2 IN AAAA fda2:2001:4756:0:ab27:beff:ef37:4242","title":"Pi-hole's full IP blocking"},{"location":"pi-hole/ftldns/blockingmode/#advantage_1","text":"Shows a blocking page from which blocked domains can be whitelisted","title":"Advantage"},{"location":"pi-hole/ftldns/blockingmode/#disadvantages_1","text":"Requires a web server to run on your Pi-hole May cause time-outs for HTTPS content even with properly configured firewall rules May cause problems with alternating prefixes on IPv6 addresses (see IP-AAAA-NODATA )","title":"Disadvantages"},{"location":"pi-hole/ftldns/blockingmode/#pi-holes-nxdomain-blocking","text":"/etc/pihole/pihole-FTL.conf setting: BLOCKINGMODE=NXDOMAIN Blocked queries will be answered with an empty response (no answer section) and status NXDOMAIN ( no such domain ) ;; QUESTION SECTION: ;doubleclick.net. IN ANY","title":"Pi-hole's NXDOMAIN blocking"},{"location":"pi-hole/ftldns/blockingmode/#advantages-disadvantages","text":"Similar to NULL blocking, but experiments suggest that clients may try to resolve blocked domains more often compared to NULL blocking.","title":"Advantages &amp; Disadvantages"},{"location":"pi-hole/ftldns/blockingmode/#pi-holes-nodata-blocking","text":"/etc/pihole/pihole-FTL.conf setting: BLOCKINGMODE=NODATA Blocked queries will be answered with an empty response (no answer section) and status NODATA (domain exists but there is no record for the requested query type) ;; QUESTION SECTION: ;doubleclick.net. IN ANY","title":"Pi-hole's NODATA blocking"},{"location":"pi-hole/ftldns/blockingmode/#advantages-disadvantages_1","text":"Similar to NXDOMAIN blocking. Clients might have a better acceptance of NODATA replies compared to NXDOMAIN replies.","title":"Advantages &amp; Disadvantages"},{"location":"pi-hole/ftldns/cache_dump/","text":"Cache dump interpretation \u00b6 The dnsmasq core embedded into pihole-FTL prints a dump of the current cache content into the mail log file (default location /var/log/pihole.log ) when receiving SIGUSR1 , e.g. by sudo killall -USR1 pihole-FTL Such a cache dump looks like cache size 10000, 0/20984 cache insertions re-used unexpired cache entries. queries forwarded 10247, queries answered locally 14713 queries for authoritative zones 0 pool memory in use 22272, max 24048, allocated 480000 server 127.0.0.1#5353: queries sent 10801, retried or failed 69 server 192.168.2.1#53: queries sent 388, retried or failed 3 Host Address Flags Expires imap.strato.de 2a01:238:20a:202:54f0::1103 6F Wed Dec 15 20:51:59 2021 imap.strato.de 81.169.145.103 4F Wed Dec 15 20:51:59 2021 api.github.com 6F N Wed Dec 15 20:36:02 2021 www.googleapis.com 2a00:1450:4001:831::200a 6F Wed Dec 15 20:34:35 2021 www.googleapis.com 2a00:1450:4001:801::200a 6F Wed Dec 15 20:34:35 2021 www.googleapis.com 2a00:1450:4001:80e::200a 6F Wed Dec 15 20:34:35 2021 www.googleapis.com 2a00:1450:4001:80f::200a 6F Wed Dec 15 20:34:35 2021 www.googleapis.com 142.250.185.170 4F Wed Dec 15 20:34:35 2021 www.googleapis.com 142.250.185.202 4F Wed Dec 15 20:34:35 2021 www.googleapis.com 142.250.185.234 4F Wed Dec 15 20:34:35 2021 www.googleapis.com 142.250.181.234 4F Wed Dec 15 20:34:35 2021 www.googleapis.com 172.217.16.138 4F Wed Dec 15 20:34:35 2021 www.googleapis.com 142.250.186.42 4F Wed Dec 15 20:34:35 2021 www.googleapis.com 142.250.186.74 4F Wed Dec 15 20:34:35 2021 www.googleapis.com 142.250.186.106 4F Wed Dec 15 20:34:35 2021 www.googleapis.com 142.250.186.138 4F Wed Dec 15 20:34:35 2021 www.googleapis.com 142.250.186.170 4F Wed Dec 15 20:34:35 2021 www.googleapis.com 172.217.18.106 4F Wed Dec 15 20:34:35 2021 www.googleapis.com 142.250.184.202 4F Wed Dec 15 20:34:35 2021 www.googleapis.com 142.250.184.234 4F Wed Dec 15 20:34:35 2021 www.googleapis.com 216.58.212.138 4F Wed Dec 15 20:34:35 2021 www.googleapis.com 142.250.185.74 4F Wed Dec 15 20:34:35 2021 www.googleapis.com 142.250.185.106 4F Wed Dec 15 20:34:35 2021 KLA 192.168.2.246 4F D Thu Dec 16 12:49:00 2021 dominik-desktop 192.168.2.224 4F D Thu Dec 16 18:03:49 2021 fritz.repeater 192.168.2.3 4FRI H lan F D Thu Dec 16 20:08:29 2021 dominik-laptop.lan 192.168.2.206 4FR D Thu Dec 16 20:07:45 2021 dominik-laptop.lan 2a02:b30:f0c:cf00::1ac 6FR D Wed Dec 15 21:07:44 2021 dominik-laptop.lan fd00::1ac 6FR D Wed Dec 15 21:07:44 2021 Internet-Radio 192.168.2.239 4F D Thu Dec 16 12:54:33 2021 Internet-Radio.lan 192.168.2.239 4FR D Thu Dec 16 12:54:33 2021 textsecure-service.whispersyst 13.248.212.111 4F Wed Dec 15 20:32:00 2021 textsecure-service.whispersyst 76.223.92.165 4F Wed Dec 15 20:32:00 2021 textsecure-service.whispersyst 6F N Wed Dec 15 20:42:00 2021 arduino.hosted-by-discourse.co 184.104.202.141 4F Wed Dec 15 20:35:40 2021 arduino.hosted-by-discourse.co 2001:470:1:9a5::141 6F Wed Dec 15 20:35:40 2021 posteo.de 185.67.36.168 4F V Wed Dec 15 20:32:59 2021 posteo.de 2a05:bc0:1000::168:1 6F V Wed Dec 15 20:32:59 2021 posteo.de 23244 8 256 KF V Wed Dec 15 20:32:59 2021 posteo.de 53881 8 257 KF V Wed Dec 15 20:32:59 2021 posteo.de 53881 8 2 SF V Wed Dec 15 20:46:13 2021 strato.de SF N V Wed Dec 15 20:51:59 2021 ip6-allnodes ff02::1 6FRI H ubuntu.com SF N V Thu Dec 16 08:31:26 2021 fritz.2400 192.168.2.3 4F I H de 57564 8 256 KF V Wed Dec 15 20:32:59 2021 de 26755 8 257 KF V Wed Dec 15 20:32:59 2021 de 63015 8 256 KF V Wed Dec 15 20:32:59 2021 de 26755 8 2 SF V Thu Dec 16 16:38:18 2021 <Root> 20326 8 257 KF V Thu Dec 16 17:46:14 2021 <Root> 14748 8 256 KF V Thu Dec 16 17:46:14 2021 <Root> 20326 8 2 SF I i.stack.imgur.com ipv4.imgur.map.fastly.net CF Fri Dec 17 22:10:29 2021 [...] where we stripped lines like Dec 15 20:32:02 dnsmasq[4177892]: for the sake of readability. The format is pretty self-explanatory. Cache metrics \u00b6 cache size 10000, 0/20984 cache insertions re-used unexpired cache entries. tells us that the cache size is 10000 (Pi-hole's default value). None of the 20984 cache insertions had to overwrite still valid cache lines. If this number is zero, your cache was sufficiently large at any time. If this number is notably larger than zero, you should consider increasing the cache size. Query statistics \u00b6 queries forwarded 10247, queries answered locally 14713 queries for authoritative zones 0 Mostly self-explanatory. Queries answered locally can both be from local configuration, HOSTS files, DHCP leases, or from the local cache. Queries for authoritative zones can only appear when defining an authoritative zone ( dnsmasq option auth-server ). Blockdata statistics \u00b6 pool memory in use 22272, max 24048, allocated 480000 Blockdata is used to cache records that do not fit in normal cache records. These are SRV targets, and DNSKEY and DS key data objects. Negative (empty) entries do not occupy blockdata space. Blocks are preallocated to reduce heap fragmentation. Server statistics \u00b6 server 127.0.0.1#5353: queries sent 10801, retried or failed 69 server 192.168.2.1#53: queries sent 388, retried or failed 3 Self-explanatory: Queries sent, retried, and failed to the individual upstream servers. Cache content \u00b6 The first character of the flags describes the query type: Character Record type 4 A (IPv4 address) 6 AAAA (IPv6 address) C CNAME V SRV S DS K DNSKEY (empty) something else The rest of the flags can be almost any combination of the following bits: Bit Interpretation F Forward entry (domain-to-address record) R Reverse entry (address-to-domain, typically combined with D or H ) I Immortal cache entry (no expiry, typically from local configuration) D DHCP-provided record N Negative record (This record does not exist) X NXDOMAIN (No record exists at all for this domain) H From HOSTS file (always combined with I ) V DNSSEC verified The V flag in negative DS records has a different meaning. Only validated DS records are every cached, and the V bit is used to store information about the presence of an NS record for the domain, i.e., if there's a zone cut at that point. Examples \u00b6 A ( DHCP provided) \u00b6 Host Address Flags Expires Internet-Radio 192.168.2.239 4F D Thu Dec 16 12:54:33 2021 Internet-Radio.lan 192.168.2.239 4FR D Thu Dec 16 12:54:33 2021 Both cache entries describe an IPv4 cache record for a device in the local network. The Internet-Radio.lan has an R as it is the name to be served for a reverse lookup as it includes the local network domain lan . DNSKEY/DS \u00b6 Host Address Flags Expires de 57564 8 256 KF V Wed Dec 15 20:32:59 2021 de 26755 8 257 KF V Wed Dec 15 20:32:59 2021 de 63015 8 256 KF V Wed Dec 15 20:32:59 2021 de 26755 8 2 SF V Thu Dec 16 16:38:18 2021 <Root> 20326 8 257 KF V Thu Dec 16 17:46:14 2021 <Root> 14748 8 256 KF V Thu Dec 16 17:46:14 2021 <Root> 20326 8 2 SF I The first three cache records are DNSKEY records (type K ) of the de domain, the fifth and sixth cache records are DNSKEY records of the root zone. The three numbers in the address field correspond to the key tag, the algorithm ID, and the key flags. The fourth and seventh entry corresponds to a DS record (type S ) where the three numbers are the key tag, the used algorithm ID, and the digest. Note that DS records may have an empty address field when they are NODATA (flag N ) like Host Address Flags Expires hosted-by-discourse.com SF N V Sat Dec 18 11:06:03 2021 The DS of the root zone is marked immortal as it is given by the locally defined trust-anchor . CNAME \u00b6 Host Address Flags Expires i.stack.imgur.com ipv4.imgur.map.fastly.net CF Fri Dec 17 22:10:29 2021 The address field corresponds to the CNAME target record. SRV \u00b6 Host Address Flags Expires _sip._tcp.pcscf2.ims.telekom.d 100 10 5062 pspcscfhost2.ims.telekom.de VF Sat Dec 18 13:33:37 2021 The address field lists the priority ( 100 in the example), the weight ( 10 ), and the SRV port ( 5062 ), followed by the target ( pspcscfhost2.ims.telekom.de ).","title":"Cache dump"},{"location":"pi-hole/ftldns/cache_dump/#cache-dump-interpretation","text":"The dnsmasq core embedded into pihole-FTL prints a dump of the current cache content into the mail log file (default location /var/log/pihole.log ) when receiving SIGUSR1 , e.g. by sudo killall -USR1 pihole-FTL Such a cache dump looks like cache size 10000, 0/20984 cache insertions re-used unexpired cache entries. queries forwarded 10247, queries answered locally 14713 queries for authoritative zones 0 pool memory in use 22272, max 24048, allocated 480000 server 127.0.0.1#5353: queries sent 10801, retried or failed 69 server 192.168.2.1#53: queries sent 388, retried or failed 3 Host Address Flags Expires imap.strato.de 2a01:238:20a:202:54f0::1103 6F Wed Dec 15 20:51:59 2021 imap.strato.de 81.169.145.103 4F Wed Dec 15 20:51:59 2021 api.github.com 6F N Wed Dec 15 20:36:02 2021 www.googleapis.com 2a00:1450:4001:831::200a 6F Wed Dec 15 20:34:35 2021 www.googleapis.com 2a00:1450:4001:801::200a 6F Wed Dec 15 20:34:35 2021 www.googleapis.com 2a00:1450:4001:80e::200a 6F Wed Dec 15 20:34:35 2021 www.googleapis.com 2a00:1450:4001:80f::200a 6F Wed Dec 15 20:34:35 2021 www.googleapis.com 142.250.185.170 4F Wed Dec 15 20:34:35 2021 www.googleapis.com 142.250.185.202 4F Wed Dec 15 20:34:35 2021 www.googleapis.com 142.250.185.234 4F Wed Dec 15 20:34:35 2021 www.googleapis.com 142.250.181.234 4F Wed Dec 15 20:34:35 2021 www.googleapis.com 172.217.16.138 4F Wed Dec 15 20:34:35 2021 www.googleapis.com 142.250.186.42 4F Wed Dec 15 20:34:35 2021 www.googleapis.com 142.250.186.74 4F Wed Dec 15 20:34:35 2021 www.googleapis.com 142.250.186.106 4F Wed Dec 15 20:34:35 2021 www.googleapis.com 142.250.186.138 4F Wed Dec 15 20:34:35 2021 www.googleapis.com 142.250.186.170 4F Wed Dec 15 20:34:35 2021 www.googleapis.com 172.217.18.106 4F Wed Dec 15 20:34:35 2021 www.googleapis.com 142.250.184.202 4F Wed Dec 15 20:34:35 2021 www.googleapis.com 142.250.184.234 4F Wed Dec 15 20:34:35 2021 www.googleapis.com 216.58.212.138 4F Wed Dec 15 20:34:35 2021 www.googleapis.com 142.250.185.74 4F Wed Dec 15 20:34:35 2021 www.googleapis.com 142.250.185.106 4F Wed Dec 15 20:34:35 2021 KLA 192.168.2.246 4F D Thu Dec 16 12:49:00 2021 dominik-desktop 192.168.2.224 4F D Thu Dec 16 18:03:49 2021 fritz.repeater 192.168.2.3 4FRI H lan F D Thu Dec 16 20:08:29 2021 dominik-laptop.lan 192.168.2.206 4FR D Thu Dec 16 20:07:45 2021 dominik-laptop.lan 2a02:b30:f0c:cf00::1ac 6FR D Wed Dec 15 21:07:44 2021 dominik-laptop.lan fd00::1ac 6FR D Wed Dec 15 21:07:44 2021 Internet-Radio 192.168.2.239 4F D Thu Dec 16 12:54:33 2021 Internet-Radio.lan 192.168.2.239 4FR D Thu Dec 16 12:54:33 2021 textsecure-service.whispersyst 13.248.212.111 4F Wed Dec 15 20:32:00 2021 textsecure-service.whispersyst 76.223.92.165 4F Wed Dec 15 20:32:00 2021 textsecure-service.whispersyst 6F N Wed Dec 15 20:42:00 2021 arduino.hosted-by-discourse.co 184.104.202.141 4F Wed Dec 15 20:35:40 2021 arduino.hosted-by-discourse.co 2001:470:1:9a5::141 6F Wed Dec 15 20:35:40 2021 posteo.de 185.67.36.168 4F V Wed Dec 15 20:32:59 2021 posteo.de 2a05:bc0:1000::168:1 6F V Wed Dec 15 20:32:59 2021 posteo.de 23244 8 256 KF V Wed Dec 15 20:32:59 2021 posteo.de 53881 8 257 KF V Wed Dec 15 20:32:59 2021 posteo.de 53881 8 2 SF V Wed Dec 15 20:46:13 2021 strato.de SF N V Wed Dec 15 20:51:59 2021 ip6-allnodes ff02::1 6FRI H ubuntu.com SF N V Thu Dec 16 08:31:26 2021 fritz.2400 192.168.2.3 4F I H de 57564 8 256 KF V Wed Dec 15 20:32:59 2021 de 26755 8 257 KF V Wed Dec 15 20:32:59 2021 de 63015 8 256 KF V Wed Dec 15 20:32:59 2021 de 26755 8 2 SF V Thu Dec 16 16:38:18 2021 <Root> 20326 8 257 KF V Thu Dec 16 17:46:14 2021 <Root> 14748 8 256 KF V Thu Dec 16 17:46:14 2021 <Root> 20326 8 2 SF I i.stack.imgur.com ipv4.imgur.map.fastly.net CF Fri Dec 17 22:10:29 2021 [...] where we stripped lines like Dec 15 20:32:02 dnsmasq[4177892]: for the sake of readability. The format is pretty self-explanatory.","title":"Cache dump interpretation"},{"location":"pi-hole/ftldns/cache_dump/#cache-metrics","text":"cache size 10000, 0/20984 cache insertions re-used unexpired cache entries. tells us that the cache size is 10000 (Pi-hole's default value). None of the 20984 cache insertions had to overwrite still valid cache lines. If this number is zero, your cache was sufficiently large at any time. If this number is notably larger than zero, you should consider increasing the cache size.","title":"Cache metrics"},{"location":"pi-hole/ftldns/cache_dump/#query-statistics","text":"queries forwarded 10247, queries answered locally 14713 queries for authoritative zones 0 Mostly self-explanatory. Queries answered locally can both be from local configuration, HOSTS files, DHCP leases, or from the local cache. Queries for authoritative zones can only appear when defining an authoritative zone ( dnsmasq option auth-server ).","title":"Query statistics"},{"location":"pi-hole/ftldns/cache_dump/#blockdata-statistics","text":"pool memory in use 22272, max 24048, allocated 480000 Blockdata is used to cache records that do not fit in normal cache records. These are SRV targets, and DNSKEY and DS key data objects. Negative (empty) entries do not occupy blockdata space. Blocks are preallocated to reduce heap fragmentation.","title":"Blockdata statistics"},{"location":"pi-hole/ftldns/cache_dump/#server-statistics","text":"server 127.0.0.1#5353: queries sent 10801, retried or failed 69 server 192.168.2.1#53: queries sent 388, retried or failed 3 Self-explanatory: Queries sent, retried, and failed to the individual upstream servers.","title":"Server statistics"},{"location":"pi-hole/ftldns/cache_dump/#cache-content","text":"The first character of the flags describes the query type: Character Record type 4 A (IPv4 address) 6 AAAA (IPv6 address) C CNAME V SRV S DS K DNSKEY (empty) something else The rest of the flags can be almost any combination of the following bits: Bit Interpretation F Forward entry (domain-to-address record) R Reverse entry (address-to-domain, typically combined with D or H ) I Immortal cache entry (no expiry, typically from local configuration) D DHCP-provided record N Negative record (This record does not exist) X NXDOMAIN (No record exists at all for this domain) H From HOSTS file (always combined with I ) V DNSSEC verified The V flag in negative DS records has a different meaning. Only validated DS records are every cached, and the V bit is used to store information about the presence of an NS record for the domain, i.e., if there's a zone cut at that point.","title":"Cache content"},{"location":"pi-hole/ftldns/cache_dump/#examples","text":"","title":"Examples"},{"location":"pi-hole/ftldns/cache_dump/#a-dhcp-provided","text":"Host Address Flags Expires Internet-Radio 192.168.2.239 4F D Thu Dec 16 12:54:33 2021 Internet-Radio.lan 192.168.2.239 4FR D Thu Dec 16 12:54:33 2021 Both cache entries describe an IPv4 cache record for a device in the local network. The Internet-Radio.lan has an R as it is the name to be served for a reverse lookup as it includes the local network domain lan .","title":"A (DHCP provided)"},{"location":"pi-hole/ftldns/cache_dump/#dnskeyds","text":"Host Address Flags Expires de 57564 8 256 KF V Wed Dec 15 20:32:59 2021 de 26755 8 257 KF V Wed Dec 15 20:32:59 2021 de 63015 8 256 KF V Wed Dec 15 20:32:59 2021 de 26755 8 2 SF V Thu Dec 16 16:38:18 2021 <Root> 20326 8 257 KF V Thu Dec 16 17:46:14 2021 <Root> 14748 8 256 KF V Thu Dec 16 17:46:14 2021 <Root> 20326 8 2 SF I The first three cache records are DNSKEY records (type K ) of the de domain, the fifth and sixth cache records are DNSKEY records of the root zone. The three numbers in the address field correspond to the key tag, the algorithm ID, and the key flags. The fourth and seventh entry corresponds to a DS record (type S ) where the three numbers are the key tag, the used algorithm ID, and the digest. Note that DS records may have an empty address field when they are NODATA (flag N ) like Host Address Flags Expires hosted-by-discourse.com SF N V Sat Dec 18 11:06:03 2021 The DS of the root zone is marked immortal as it is given by the locally defined trust-anchor .","title":"DNSKEY/DS"},{"location":"pi-hole/ftldns/cache_dump/#cname","text":"Host Address Flags Expires i.stack.imgur.com ipv4.imgur.map.fastly.net CF Fri Dec 17 22:10:29 2021 The address field corresponds to the CNAME target record.","title":"CNAME"},{"location":"pi-hole/ftldns/cache_dump/#srv","text":"Host Address Flags Expires _sip._tcp.pcscf2.ims.telekom.d 100 10 5062 pspcscfhost2.ims.telekom.de VF Sat Dec 18 13:33:37 2021 The address field lists the priority ( 100 in the example), the weight ( 10 ), and the SRV port ( 5062 ), followed by the target ( pspcscfhost2.ims.telekom.de ).","title":"SRV"},{"location":"pi-hole/ftldns/compatibility/","text":"FTL DNS compatibility list \u00b6 We tested FTL DNS on the following devices: Board Tested OS CPU architecture Suitable binaries VirtualBox Ubuntu 16.10 amd64 linux-x86_64 Raspberry Pi Zero Raspbian Jessie, Stretch armv6l arm-linux-gnueabi Raspberry Pi 1 Raspbian Jessie, Stretch armv6 arm-linux-gnueabi Raspberry Pi 2 Raspbian Jessie, Stretch armv7l arm-linux-gnueabi and arm-linux-gnueabihf Raspberry Pi 3 Raspbian Jessie, Stretch armv7l arm-linux-gnueabi and arm-linux-gnueabihf Raspberry Pi 3 B+ Raspbian Jessie, Stretch armv7l arm-linux-gnueabi and arm-linux-gnueabihf Raspberry Pi 3 openSUSE aarch64 aarch64-linux-gnu NanoPi NEO armbian Ubuntu 16.04 armv7l arm-linux-gnueabihf Odroid-C2 Ubuntu 16.04 aarch64 aarch64-linux-gnu C.H.I.P Debian armv7l arm-linux-gnueabihf OrangePi Zero armbian Ubuntu 16.04 armv7l arm-linux-gnueabihf BeagleBone Black Debian Jessie, Stretch armv7l arm-linux-gnueabihf Devices we do not officially support include MIPS and armv5 (or lower) devices. You may, however, be successful with building binaries yourself from the source code, but we do not provide pre-built binaries for these targets.","title":"*FTL*DNS compatibility list"},{"location":"pi-hole/ftldns/compatibility/#ftldns-compatibility-list","text":"We tested FTL DNS on the following devices: Board Tested OS CPU architecture Suitable binaries VirtualBox Ubuntu 16.10 amd64 linux-x86_64 Raspberry Pi Zero Raspbian Jessie, Stretch armv6l arm-linux-gnueabi Raspberry Pi 1 Raspbian Jessie, Stretch armv6 arm-linux-gnueabi Raspberry Pi 2 Raspbian Jessie, Stretch armv7l arm-linux-gnueabi and arm-linux-gnueabihf Raspberry Pi 3 Raspbian Jessie, Stretch armv7l arm-linux-gnueabi and arm-linux-gnueabihf Raspberry Pi 3 B+ Raspbian Jessie, Stretch armv7l arm-linux-gnueabi and arm-linux-gnueabihf Raspberry Pi 3 openSUSE aarch64 aarch64-linux-gnu NanoPi NEO armbian Ubuntu 16.04 armv7l arm-linux-gnueabihf Odroid-C2 Ubuntu 16.04 aarch64 aarch64-linux-gnu C.H.I.P Debian armv7l arm-linux-gnueabihf OrangePi Zero armbian Ubuntu 16.04 armv7l arm-linux-gnueabihf BeagleBone Black Debian Jessie, Stretch armv7l arm-linux-gnueabihf Devices we do not officially support include MIPS and armv5 (or lower) devices. You may, however, be successful with building binaries yourself from the source code, but we do not provide pre-built binaries for these targets.","title":"FTLDNS compatibility list"},{"location":"pi-hole/ftldns/compile/","text":"We pre-compile FTL DNS for you to save you the trouble of compiling anything yourself. However, sometimes you may want to make your own modifications. To test them, you have to compile FTL DNS from source. Luckily, you don't have to be a programmer to build FTL DNS from source and install it on your system; you only have to know the basics we provide in here. With just a few commands, you can build FTL DNS from source like a pro. Installing the Required Software \u00b6 First, we'll install the basic software you'll need to compile from source, like the GCC compiler and other utilities. Install them by running the following command in a terminal: Debian / Ubuntu / Raspbian \u00b6 sudo apt install build-essential libgmp-dev m4 cmake libidn11-dev libreadline-dev xxd Fedora \u00b6 sudo dnf install gcc gmp-devel gmp-static m4 cmake libidn-devel readline-devel xxd Compile libnettle from source \u00b6 FTL DNS uses a cryptographic library ( libnettle ) for handling DNSSEC signatures. Compile and install a recent version using: wget https://ftp.gnu.org/gnu/nettle/nettle-3.7.2.tar.gz tar -xzf nettle-3.7.2.tar.gz cd nettle-3.7.2 ./configure --libdir = /usr/local/lib make -j $( nproc ) sudo make install Since Ubuntu 20.04, you need to specify the library directory explicitly. Otherwise, the library will be installed in custom locations where it would not be found by cmake . Get the source \u00b6 Now, clone the FTL DNS repo (or your own fork) to get the source code of FTL DNS: git clone https://github.com/pi-hole/FTL.git && cd FTL If you want to build another branch and not master , use checkout to get to this branch, like git checkout development Compile the source \u00b6 FTL DNS can now be compiled using either the build script ./build.sh or manually mkdir -p cmake && cd cmake cmake .. cmake --build . -- -j $( nproc ) Note that both ways are exactly equivalent and that you do not need root privileges here. Install the new binary system-wide \u00b6 Install the new binary using either ./build.sh install or cd cmake && sudo make install Finally, restart FTL DNS to use the new binary: sudo service pihole-FTL restart","title":"Compile"},{"location":"pi-hole/ftldns/compile/#installing-the-required-software","text":"First, we'll install the basic software you'll need to compile from source, like the GCC compiler and other utilities. Install them by running the following command in a terminal:","title":"Installing the Required Software"},{"location":"pi-hole/ftldns/compile/#debian-ubuntu-raspbian","text":"sudo apt install build-essential libgmp-dev m4 cmake libidn11-dev libreadline-dev xxd","title":"Debian / Ubuntu / Raspbian"},{"location":"pi-hole/ftldns/compile/#fedora","text":"sudo dnf install gcc gmp-devel gmp-static m4 cmake libidn-devel readline-devel xxd","title":"Fedora"},{"location":"pi-hole/ftldns/compile/#compile-libnettle-from-source","text":"FTL DNS uses a cryptographic library ( libnettle ) for handling DNSSEC signatures. Compile and install a recent version using: wget https://ftp.gnu.org/gnu/nettle/nettle-3.7.2.tar.gz tar -xzf nettle-3.7.2.tar.gz cd nettle-3.7.2 ./configure --libdir = /usr/local/lib make -j $( nproc ) sudo make install Since Ubuntu 20.04, you need to specify the library directory explicitly. Otherwise, the library will be installed in custom locations where it would not be found by cmake .","title":"Compile libnettle from source"},{"location":"pi-hole/ftldns/compile/#get-the-source","text":"Now, clone the FTL DNS repo (or your own fork) to get the source code of FTL DNS: git clone https://github.com/pi-hole/FTL.git && cd FTL If you want to build another branch and not master , use checkout to get to this branch, like git checkout development","title":"Get the source"},{"location":"pi-hole/ftldns/compile/#compile-the-source","text":"FTL DNS can now be compiled using either the build script ./build.sh or manually mkdir -p cmake && cd cmake cmake .. cmake --build . -- -j $( nproc ) Note that both ways are exactly equivalent and that you do not need root privileges here.","title":"Compile the source"},{"location":"pi-hole/ftldns/compile/#install-the-new-binary-system-wide","text":"Install the new binary using either ./build.sh install or cd cmake && sudo make install Finally, restart FTL DNS to use the new binary: sudo service pihole-FTL restart","title":"Install the new binary system-wide"},{"location":"pi-hole/ftldns/configfile/","text":"You can create a file /etc/pihole/pihole-FTL.conf that will be read by FTL DNS on startup. Note: comments need to start with #; to avoid issues with PHP and bash reading this file. (See https://github.com/pi-hole/pi-hole/pull/4081 for more details) Possible settings ( the option shown first is the default ): DNS settings \u00b6 BLOCKINGMODE=NULL|IP-NODATA-AAAA|IP|NXDOMAIN \u00b6 How should FTL reply to blocked queries? More details CNAME_DEEP_INSPECT=true|false (PR #663 ) \u00b6 Use this option to disable deep CNAME inspection. This might be beneficial for very low-end devices BLOCK_ESNI=true|false (PR #733 ) \u00b6 Encrypted Server Name Indication (ESNI) is certainly a good step into the right direction to enhance privacy on the web. It prevents on-path observers, including ISPs, coffee shop owners and firewalls, from intercepting the TLS Server Name Indication (SNI) extension by encrypting it. This prevents the SNI from being used to determine which websites users are visiting. ESNI will obviously cause issues for pixelserv-tls which will be unable to generate matching certificates on-the-fly when it cannot read the SNI. Cloudflare and Firefox are already enabling ESNI. According to the IEFT draft (link above), we can easily restore piselserv-tls 's operation by replying NXDOMAIN to _esni. subdomains of blocked domains as this mimics a \"not configured for this domain\" behavior. EDNS0_ECS=true|false (PR #851 ) \u00b6 Should we overwrite the query source when client information is provided through EDNS0 client subnet (ECS) information? This allows Pi-hole to obtain client IPs even if they are hidden behind the NAT of a router. This feature has been requested and discussed on Discourse where further information how to use it can be found. RATE_LIMIT=1000/60 (PR #1052 ) \u00b6 Control FTL's query rate-limiting. Rate-limited queries are answered with a REFUSED reply and not further processed by FTL. The default settings for FTL's rate-limiting are to permit no more than 1000 queries in 60 seconds. Both numbers can be customized independently. It is important to note that rate-limiting is happening on a per-client basis. Other clients can continue to use FTL while rate-limited clients are short-circuited at the same time. For this setting, both numbers, the maximum number of queries within a given time, and the length of the time interval (seconds) have to be specified. For instance, if you want to set a rate limit of 1 query per hour, the option should look like RATE_LIMIT=1/3600 . The time interval is relative to when FTL has finished starting (start of the daemon + possible delay by DELAY_STARTUP) then it will advance in steps of the rate-limiting interval. If a client reaches the maximum number of queries it will be blocked until the end of the current interval . This will be logged to /var/log/pihole-FTL.log , e.g. Rate-limiting 10.0.1.39 for at least 44 seconds . If the client continues to send queries while being blocked already and this number of queries during the blocking exceeds the limit the client will continue to be blocked until the end of the next interval ( pihole-FTL.log will contain lines like Still rate-limiting 10.0.1.39 as it made additional 5007 queries ). As soon as the client requests less than the set limit, it will be unblocked ( Ending rate-limitation of 10.0.1.39 ). Rate-limiting may be disabled altogether by setting RATE_LIMIT=0/0 (this results in the same behavior as before FTL v5.7). LOCAL_IPV4= (unset by default, PR #1293 ) \u00b6 By default, FTL determines the address of the interface a query arrived on and uses this address for replying to A queries with the most suitable address for the requesting client. This setting can be used to use a fixed, rather than the dynamically obtained, address when Pi-hole responds to the following names: pi.hole <the device's hostname> pi.hole.<local domain> <the device's hostname>.<local domain> LOCAL_IPV6= (unset by default, PR #1293 ) \u00b6 Used to overwrite the IP address for local AAAA queries. See LOCAL_IPV4 for details when this setting is used. BLOCK_IPV4= (unset by default, PR #1293 ) \u00b6 By default, FTL determines the address of the interface a query arrived on and uses this address for replying to A queries with the most suitable address for the requesting client. This setting can be used to use a fixed, rather than the dynamically obtained, address when Pi-hole responds in the following cases: IP blocking mode is used and this query is to be blocked A regular expression with the ;reply=IP regex extension is used BLOCK_IPV6= (unset by default, PR #1293 ) \u00b6 Used to overwrite the IP address for blocked AAAA queries. See BLOCK_IPV4 for details when this setting is used. REPLY_WHEN_BUSY=ALLOW|DROP|BLOCK|REFUSE (PR #1156 ) \u00b6 When the gravity database is locked/busy, how should Pi-hole handle queries? ALLOW - allow all queries when the database is busy BLOCK - block all queries when the database is busy. This uses the configured BLOCKINGMODE (default NULL ) REFUSE - refuse all queries which arrive while the database is busy DROP - just drop the queries, i.e., never reply to them at all. Despite REFUSE sounding similar to DROP , it turned out that many clients will just immediately retry, causing up to several thousands of queries per second. This does not happen in DROP mode. MOZILLA_CANARY=true|false (PR #1148 ) \u00b6 Should Pi-hole always replies with NXDOMAIN to A and AAAA queries of use-application-dns.net to disable Firefox automatic DNS-over-HTTP? This is following the recommendation on https://support.mozilla.org/en-US/kb/configuring-networks-disable-dns-over-https BLOCK_TTL=2 (PR #1173 ) \u00b6 FTL's internal TTL to be handed out for blocked queries. This settings allows users to select a value different from the dnsmasq config option local-ttl . This seems useful in context of locally used hostnames that are known to stay constant over long times (printers, etc.). Note that large values may render whitelisting ineffective due to client-side caching of blocked queries. BLOCK_ICLOUD_PR=true|false (PR #1171 ) \u00b6 Should Pi-hole always replies with NXDOMAIN to A and AAAA queries of mask.icloud.com and mask-h2.icloud.com to disable Apple's iCloud Private Relay to prevent Apple devices from bypassing Pi-hole? This is following the recommendation on https://developer.apple.com/support/prepare-your-network-for-icloud-private-relay Statistics settings \u00b6 MAXLOGAGE=24.0 \u00b6 Up to how many hours of queries should be imported from the database and logs? Values greater than the hard-coded maximum of 24h need a locally compiled FTL with a changed compile-time value. PRIVACYLEVEL=0|1|2|3 \u00b6 Which privacy level is used? More details IGNORE_LOCALHOST=no|yes \u00b6 Should FTL ignore queries coming from the local machine? AAAA_QUERY_ANALYSIS=yes|no \u00b6 Should FTL analyze AAAA queries? The DNS server will handle AAAA queries the same way, regardless of this setting. All this does is ignoring AAAA queries when computing the statistics of Pi-hole. This setting is considered obsolete and will be removed in a future version. ANALYZE_ONLY_A_AND_AAAA=false|true \u00b6 Should FTL only analyze A and AAAA queries? SHOW_DNSSEC=true|false \u00b6 Should FTL analyze and include automatically generated DNSSEC queries in the Query Log? Other settings \u00b6 SOCKET_LISTENING=localonly|all \u00b6 Listen only for local socket connections or permit all connections FTLPORT=4711 \u00b6 On which port should FTL be listening? RESOLVE_IPV6=yes|no \u00b6 Should FTL try to resolve IPv6 addresses to hostnames? RESOLVE_IPV4=yes|no \u00b6 Should FTL try to resolve IPv4 addresses to hostnames? PIHOLE_PTR=PI.HOLE|HOSTNAME|HOSTNAMEFQDN|NONE (PR #1111 , #1164 ) \u00b6 Controls whether and how FTL will reply with for address for which a local interface exists. Valid options are: PI.HOLE (the default) respond with pi.hole HOSTNAME serve the machine's global hostname HOSTNAMEFQDN serve the machine's global hostname as fully qualified domain by adding the local suffix. See note below. NONE Pi-hole will not respond automatically on PTR requests to local interface addresses. Ensure pi.hole and/or hostname records exist elsewhere. Note about HOSTNAMEFQDN : If no local suffix has been defined, FTL appends the local domain .no_fqdn_available . In this case you should either add domain=whatever.com to a custom config file inside /etc/dnsmasq.d/ (to set whatever.com as local domain) or use domain=# which will try to derive the local domain from /etc/resolv.conf (or whatever is set with resolv-file , when multiple search directives exist, the first one is used). DELAY_STARTUP=0 (PR #716 ) \u00b6 In certain configurations, you may want FTL to wait a given amount of time before trying to start the DNS revolver. This is typically found when network interfaces appear only late during system startup and the interface startup priorities are configured incorrectly. This setting takes any integer value between 0 and 300 seconds. NICE=-10 (PR #798 ) \u00b6 Can be used to change the niceness of Pi-hole FTL. Defaults to -10 and can be disabled altogether by setting a value of -999 . The nice value is an attribute that can be used to influence the CPU scheduler to favor or disfavor a process in scheduling decisions. The range of the nice value varies across UNIX systems. On modern Linux, the range is -20 (high priority = not very nice to other processes) to +19 (low priority). MAXNETAGE=[MAXDBDAYS] (PR #871 ) \u00b6 IP addresses (and associated host names) older than the specified number of days are removed to avoid dead entries in the network overview table. This setting defaults to the same value as MAXDBDAYS above but can be changed independently if needed. NAMES_FROM_NETDB=true|false (PR #784 ) \u00b6 Control whether FTL should use the fallback option to try to obtain client names from checking the network table. This behavior can be disabled with this option Assume an IPv6 client without a host names. However, the network table knows - though the client's MAC address - that this is the same device where we have a host name for another IP address (e.g., a DHCP server managed IPv4 address). In this case, we use the host name associated to the other address as this is the same device. REFRESH_HOSTNAMES=IPV4|ALL|UNKNOWN|NONE (PR #953 ) \u00b6 With this option, you can change how (and if) hourly PTR requests are made to check for changes in client and upstream server hostnames. The following options are available: REFRESH_HOSTNAMES=IPV4 - Do the hourly PTR lookups only for IPv4 addresses This is the new default since Pi-hole FTL v5.3.2. It should resolve issues with more and more very short-lived PE IPv6 addresses coming up in a lot of networks. REFRESH_HOSTNAMES=ALL - Do the hourly PTR lookups for all addresses This is the same as what we're doing with FTL v5.3(.1). This can create a lot of PTR queries for those with many IPv6 addresses in their networks. REFRESH_HOSTNAMES=UNKNOWN - Only resolve unknown hostnames Already existing hostnames are never refreshed, i.e., there will be no PTR queries made for clients where hostnames are known. This also means that known hostnames will not be updated once known. REFRESH_HOSTNAMES=NONE - Don't do any hourly PTR lookups This means we look host names up exactly once (when we first see a client) and never again. You may miss future changes of host names. PARSE_ARP_CACHE=true|false (PR #445 ) \u00b6 This setting can be used to disable ARP cache processing. When disabled, client identification and the network table will stop working reliably. CHECK_LOAD=true|false (PR #1249 ) \u00b6 Pi-hole is very lightweight on resources. Nevertheless, this does not mean that you should run Pi-hole on a server that is otherwise extremely busy as queuing on the system can lead to unnecessary delays in DNS operation as the system becomes less and less usable as the system load increases because all resources are permanently in use. To account for this, FTL regularly checks the system load. To bring this to your attention, FTL warns about excessive load when the 15 minute system load average exceeds the number of cores. This check can be disabled with this setting. CHECK_SHMEM=90 (PR #1249 ) \u00b6 FTL stores history in shared memory to allow inter-process communication with forked dedicated TCP workers. If FTL runs out of memory, it cannot continue to work as queries cannot be analyzed any further. Hence, FTL checks if enough shared memory is available on your system and warns you if this is not the case. By default, FTL warns if the shared-memory usage exceeds 90%. You can set any integer limit between 0 to 100 (interpreted as percentages) where 0 means that checking of shared-memory usage is disabled. CHECK_DISK=90 (PR #1249 ) \u00b6 FTL stores its long-term history in a database file on disk (see here ). Furthermore, FTL stores log files (see, e.g., here ). By default, FTL warns if usage of the disk holding any crucial file exceeds 90%. You can set any integer limit between 0 to 100 (interpreted as percentages) where 0 means that checking of disk usage is disabled. Long-term database settings \u00b6 Further details concerning the database DBIMPORT=yes|no \u00b6 Should FTL load information from the database on startup to be aware of the most recent history? MAXDBDAYS=365 \u00b6 How long should queries be stored in the database? Setting this to 0 disables the database DBINTERVAL=1.0 \u00b6 How often do we store queries in FTL's database [minutes]? DBFILE=/etc/pihole/pihole-FTL.db \u00b6 Specify the path and filename of FTL's SQLite3 long-term database. Setting this to DBFILE= disables the database altogether File options \u00b6 LOGFILE=/var/log/pihole-FTL.log \u00b6 The location of FTL's log file. If you want to move the log file to a different place, also consider this FAQ article . PIDFILE=/run/pihole-FTL.pid \u00b6 The file which contains the PID of FTL's main process. PORTFILE=/run/pihole-FTL.port \u00b6 The file containing the port FTL's API is listening on. SOCKETFILE=/run/pihole/FTL.sock \u00b6 The file containing the socket FTL's API is listening on. SETUPVARSFILE=/etc/pihole/setupVars.conf \u00b6 The config file of Pi-hole containing, e.g., the current blocking status (do not change). MACVENDORDB=/etc/pihole/macvendor.db \u00b6 The database containing MAC -> Vendor information for the network table. GRAVITYDB=/etc/pihole/gravity.db \u00b6 Specify path and filename of FTL's SQLite3 gravity database. This database contains all domains relevant for Pi-hole's DNS blocking Debugging options \u00b6 DEBUG_ALL=false|true \u00b6 Enable all debug flags. If this is set to true, all other debug config options are ignored. DEBUG_DATABASE=false|true \u00b6 Print debugging information about database actions. This prints performed SQL statements as well as some general information such as the time it took to store the queries and how many have been saved to the database. DEBUG_NETWORKING=false|true \u00b6 Prints a list of the detected interfaces on the startup of pihole-FTL . Also, prints whether these interfaces are IPv4 or IPv6 interfaces. DEBUG_EDNS0=false|true \u00b6 Print debugging information about received EDNS(0) data. DEBUG_LOCKS=false|true \u00b6 Print information about shared memory locks. Messages will be generated when waiting, obtaining, and releasing a lock. DEBUG_QUERIES=false|true \u00b6 Print extensive query information (domains, types, replies, etc.). This has always been part of the legacy debug mode of pihole-FTL . DEBUG_FLAGS=false|true \u00b6 Print flags of queries received by the DNS hooks. Only effective when DEBUG_QUERIES is enabled as well. DEBUG_SHMEM=false|true \u00b6 Print information about shared memory buffers. Messages are either about creating or enlarging shmem objects or string injections. DEBUG_GC=false|true \u00b6 Print information about garbage collection (GC): What is to be removed, how many have been removed and how long did GC take. DEBUG_ARP=false|true \u00b6 Print information about ARP table processing: How long did parsing take, whether read MAC addresses are valid, and if the macvendor.db file exists. DEBUG_REGEX=false|true \u00b6 Controls if FTL DNS should print extended details about regex matching into pihole-FTL.log . More details DEBUG_API=false|true \u00b6 Print extra debugging information during telnet API calls. Currently only used to send extra information when getting all queries. DEBUG_OVERTIME=false|true \u00b6 Print information about overTime memory operations, such as initializing or moving overTime slots. DEBUG_STATUS=false|true \u00b6 Print information about status changes for individual queries. This can be useful to identify unexpected unknown queries. DEBUG_CAPS=false|true \u00b6 Print information about capabilities granted to the pihole-FTL process. The current capabilities are printed on receipt of SIGHUP , i.e., the current set of capabilities can be queried without restarting pihole-FTL (by setting DEBUG_CAPS=true and thereafter sending killall -HUP pihole-FTL ). DEBUG_DNSMASQ_LINES=false|true \u00b6 Print file and line causing a dnsmasq event into FTL's log files. This is handy to implement additional hooks missing from FTL. DEBUG_VECTORS=false|true (PR #725 ) \u00b6 FTL uses dynamically allocated vectors for various tasks. This config option enables extensive debugging information such as information about allocation, referencing, deletion, and appending. DEBUG_RESOLVER=false|true (PR #728 ) \u00b6 Extensive information about hostname resolution like which DNS servers are used in the first and second hostname resolving tries (only affecting internally generated PTR queries). DEBUG_EDNS0=false|true (PR #851 ) \u00b6 Verbose logging during EDNS(0) header analysis. DEBUG_CLIENTS=false|true (PR #762 ) \u00b6 Log various important client events such as change of interface (e.g., client switching from WiFi to wired or VPN connection), as well as extensive reporting about how clients were assigned to its groups. DEBUG_ALIASCLIENTS=false|true (PR #880 ) \u00b6 Log information related to alias-client processing. DEBUG_EVENTS=false|true (PR #881 ) \u00b6 Log information regarding FTL's embedded event handling queue. DEBUG_HELPER=false|true (PR #914 ) \u00b6 Log information about script helpers, e.g., due to dhcp-script . ADDR2LINE=true|false (PR #774 ) \u00b6 Should FTL translate its own stack addresses into code lines during the bug backtrace? This improves the analysis of crashed significantly. It is recommended to leave the option enabled. This option should only be disabled when addr2line is known to not be working correctly on the machine because, in this case, the malfunctioning addr2line can prevent from generating any backtrace at all. DEBUG_EXTRA=false|true (PR #994 ) \u00b6 Temporary flag that may print additional information. This debug flag is meant to be used whenever needed for temporary investigations. The logged content may change without further notice at any time. Deprecated options \u00b6 REPLY_ADDR4= (unset by default, PR #965 ) \u00b6 This option is deprecated and may be removed in future versions, please use BLOCK_IPV4 and LOCAL_IPV4 instead If neither BLOCK_IPV4 nor LOCAL_IPV4 are set, this setting is used to set both of them. If either of the two is set, this setting is ignored altogether. REPLY_ADDR6= (unset by default, PR #965 ) \u00b6 This option is deprecated and may be removed in future versions, please use BLOCK_IPV6 and LOCAL_IPV6 instead If neither BLOCK_IPV6 nor LOCAL_IPV6 are set, this setting is used to set both of them. If either of the two is set, this setting is ignored altogether.","title":"Configfile"},{"location":"pi-hole/ftldns/configfile/#dns-settings","text":"","title":"DNS settings"},{"location":"pi-hole/ftldns/configfile/#blocking_mode","text":"How should FTL reply to blocked queries? More details","title":"Blocking Mode"},{"location":"pi-hole/ftldns/configfile/#cname_deep_inspect","text":"Use this option to disable deep CNAME inspection. This might be beneficial for very low-end devices","title":"Deep CNAME inspection"},{"location":"pi-hole/ftldns/configfile/#block_esni","text":"Encrypted Server Name Indication (ESNI) is certainly a good step into the right direction to enhance privacy on the web. It prevents on-path observers, including ISPs, coffee shop owners and firewalls, from intercepting the TLS Server Name Indication (SNI) extension by encrypting it. This prevents the SNI from being used to determine which websites users are visiting. ESNI will obviously cause issues for pixelserv-tls which will be unable to generate matching certificates on-the-fly when it cannot read the SNI. Cloudflare and Firefox are already enabling ESNI. According to the IEFT draft (link above), we can easily restore piselserv-tls 's operation by replying NXDOMAIN to _esni. subdomains of blocked domains as this mimics a \"not configured for this domain\" behavior.","title":"ESNI blocking"},{"location":"pi-hole/ftldns/configfile/#block_edns0_ecs","text":"Should we overwrite the query source when client information is provided through EDNS0 client subnet (ECS) information? This allows Pi-hole to obtain client IPs even if they are hidden behind the NAT of a router. This feature has been requested and discussed on Discourse where further information how to use it can be found.","title":"EDNS ECS overwrite"},{"location":"pi-hole/ftldns/configfile/#rate_limit","text":"Control FTL's query rate-limiting. Rate-limited queries are answered with a REFUSED reply and not further processed by FTL. The default settings for FTL's rate-limiting are to permit no more than 1000 queries in 60 seconds. Both numbers can be customized independently. It is important to note that rate-limiting is happening on a per-client basis. Other clients can continue to use FTL while rate-limited clients are short-circuited at the same time. For this setting, both numbers, the maximum number of queries within a given time, and the length of the time interval (seconds) have to be specified. For instance, if you want to set a rate limit of 1 query per hour, the option should look like RATE_LIMIT=1/3600 . The time interval is relative to when FTL has finished starting (start of the daemon + possible delay by DELAY_STARTUP) then it will advance in steps of the rate-limiting interval. If a client reaches the maximum number of queries it will be blocked until the end of the current interval . This will be logged to /var/log/pihole-FTL.log , e.g. Rate-limiting 10.0.1.39 for at least 44 seconds . If the client continues to send queries while being blocked already and this number of queries during the blocking exceeds the limit the client will continue to be blocked until the end of the next interval ( pihole-FTL.log will contain lines like Still rate-limiting 10.0.1.39 as it made additional 5007 queries ). As soon as the client requests less than the set limit, it will be unblocked ( Ending rate-limitation of 10.0.1.39 ). Rate-limiting may be disabled altogether by setting RATE_LIMIT=0/0 (this results in the same behavior as before FTL v5.7).","title":"Query rate limiting"},{"location":"pi-hole/ftldns/configfile/#local_ipv4","text":"By default, FTL determines the address of the interface a query arrived on and uses this address for replying to A queries with the most suitable address for the requesting client. This setting can be used to use a fixed, rather than the dynamically obtained, address when Pi-hole responds to the following names: pi.hole <the device's hostname> pi.hole.<local domain> <the device's hostname>.<local domain>","title":"Force local A reply"},{"location":"pi-hole/ftldns/configfile/#local_ipv6","text":"Used to overwrite the IP address for local AAAA queries. See LOCAL_IPV4 for details when this setting is used.","title":"Force local AAAA reply"},{"location":"pi-hole/ftldns/configfile/#block_ipv4","text":"By default, FTL determines the address of the interface a query arrived on and uses this address for replying to A queries with the most suitable address for the requesting client. This setting can be used to use a fixed, rather than the dynamically obtained, address when Pi-hole responds in the following cases: IP blocking mode is used and this query is to be blocked A regular expression with the ;reply=IP regex extension is used","title":"Force blocked A reply"},{"location":"pi-hole/ftldns/configfile/#block_ipv6","text":"Used to overwrite the IP address for blocked AAAA queries. See BLOCK_IPV4 for details when this setting is used.","title":"Force blocked AAAA reply"},{"location":"pi-hole/ftldns/configfile/#reply_when_busy","text":"When the gravity database is locked/busy, how should Pi-hole handle queries? ALLOW - allow all queries when the database is busy BLOCK - block all queries when the database is busy. This uses the configured BLOCKINGMODE (default NULL ) REFUSE - refuse all queries which arrive while the database is busy DROP - just drop the queries, i.e., never reply to them at all. Despite REFUSE sounding similar to DROP , it turned out that many clients will just immediately retry, causing up to several thousands of queries per second. This does not happen in DROP mode.","title":"Database busy reply"},{"location":"pi-hole/ftldns/configfile/#mozilla_canary","text":"Should Pi-hole always replies with NXDOMAIN to A and AAAA queries of use-application-dns.net to disable Firefox automatic DNS-over-HTTP? This is following the recommendation on https://support.mozilla.org/en-US/kb/configuring-networks-disable-dns-over-https","title":"Mozilla canary domain handling"},{"location":"pi-hole/ftldns/configfile/#block_ttl","text":"FTL's internal TTL to be handed out for blocked queries. This settings allows users to select a value different from the dnsmasq config option local-ttl . This seems useful in context of locally used hostnames that are known to stay constant over long times (printers, etc.). Note that large values may render whitelisting ineffective due to client-side caching of blocked queries.","title":"Blocked domains lifetime"},{"location":"pi-hole/ftldns/configfile/#icloud_private_relay","text":"Should Pi-hole always replies with NXDOMAIN to A and AAAA queries of mask.icloud.com and mask-h2.icloud.com to disable Apple's iCloud Private Relay to prevent Apple devices from bypassing Pi-hole? This is following the recommendation on https://developer.apple.com/support/prepare-your-network-for-icloud-private-relay","title":"iCloud Private Relay domain handling"},{"location":"pi-hole/ftldns/configfile/#statistics-settings","text":"","title":"Statistics settings"},{"location":"pi-hole/ftldns/configfile/#maxlogage","text":"Up to how many hours of queries should be imported from the database and logs? Values greater than the hard-coded maximum of 24h need a locally compiled FTL with a changed compile-time value.","title":"Max Log Age"},{"location":"pi-hole/ftldns/configfile/#privacylevel","text":"Which privacy level is used? More details","title":"Privacy Level"},{"location":"pi-hole/ftldns/configfile/#ignore_localhost","text":"Should FTL ignore queries coming from the local machine?","title":"Ignore localhost"},{"location":"pi-hole/ftldns/configfile/#aaaa_query_analysis","text":"Should FTL analyze AAAA queries? The DNS server will handle AAAA queries the same way, regardless of this setting. All this does is ignoring AAAA queries when computing the statistics of Pi-hole. This setting is considered obsolete and will be removed in a future version.","title":"AAAA Query Analysis"},{"location":"pi-hole/ftldns/configfile/#analyze_only_a_and_aaaa","text":"Should FTL only analyze A and AAAA queries?","title":"Analyze A and AAAA Only"},{"location":"pi-hole/ftldns/configfile/#show_dnssec","text":"Should FTL analyze and include automatically generated DNSSEC queries in the Query Log?","title":"Show automatic DNSSEC queries"},{"location":"pi-hole/ftldns/configfile/#other-settings","text":"","title":"Other settings"},{"location":"pi-hole/ftldns/configfile/#socket_listening","text":"Listen only for local socket connections or permit all connections","title":"Socket Listening"},{"location":"pi-hole/ftldns/configfile/#ftlport","text":"On which port should FTL be listening?","title":"FTLDNS Port"},{"location":"pi-hole/ftldns/configfile/#resolve_ipv6","text":"Should FTL try to resolve IPv6 addresses to hostnames?","title":"Resolve IPV6"},{"location":"pi-hole/ftldns/configfile/#resolve_ipv4","text":"Should FTL try to resolve IPv4 addresses to hostnames?","title":"Resolve IPV4"},{"location":"pi-hole/ftldns/configfile/#pihole_ptr","text":"Controls whether and how FTL will reply with for address for which a local interface exists. Valid options are: PI.HOLE (the default) respond with pi.hole HOSTNAME serve the machine's global hostname HOSTNAMEFQDN serve the machine's global hostname as fully qualified domain by adding the local suffix. See note below. NONE Pi-hole will not respond automatically on PTR requests to local interface addresses. Ensure pi.hole and/or hostname records exist elsewhere. Note about HOSTNAMEFQDN : If no local suffix has been defined, FTL appends the local domain .no_fqdn_available . In this case you should either add domain=whatever.com to a custom config file inside /etc/dnsmasq.d/ (to set whatever.com as local domain) or use domain=# which will try to derive the local domain from /etc/resolv.conf (or whatever is set with resolv-file , when multiple search directives exist, the first one is used).","title":"Pi-hole PTR"},{"location":"pi-hole/ftldns/configfile/#delay_startup","text":"In certain configurations, you may want FTL to wait a given amount of time before trying to start the DNS revolver. This is typically found when network interfaces appear only late during system startup and the interface startup priorities are configured incorrectly. This setting takes any integer value between 0 and 300 seconds.","title":"Delay resolver startup"},{"location":"pi-hole/ftldns/configfile/#nice","text":"Can be used to change the niceness of Pi-hole FTL. Defaults to -10 and can be disabled altogether by setting a value of -999 . The nice value is an attribute that can be used to influence the CPU scheduler to favor or disfavor a process in scheduling decisions. The range of the nice value varies across UNIX systems. On modern Linux, the range is -20 (high priority = not very nice to other processes) to +19 (low priority).","title":"Set niceness"},{"location":"pi-hole/ftldns/configfile/#maxnetage","text":"IP addresses (and associated host names) older than the specified number of days are removed to avoid dead entries in the network overview table. This setting defaults to the same value as MAXDBDAYS above but can be changed independently if needed.","title":"Network table cleaning"},{"location":"pi-hole/ftldns/configfile/#names_from_netdb","text":"Control whether FTL should use the fallback option to try to obtain client names from checking the network table. This behavior can be disabled with this option Assume an IPv6 client without a host names. However, the network table knows - though the client's MAC address - that this is the same device where we have a host name for another IP address (e.g., a DHCP server managed IPv4 address). In this case, we use the host name associated to the other address as this is the same device.","title":"Load names from network table"},{"location":"pi-hole/ftldns/configfile/#refresh_hostnames","text":"With this option, you can change how (and if) hourly PTR requests are made to check for changes in client and upstream server hostnames. The following options are available: REFRESH_HOSTNAMES=IPV4 - Do the hourly PTR lookups only for IPv4 addresses This is the new default since Pi-hole FTL v5.3.2. It should resolve issues with more and more very short-lived PE IPv6 addresses coming up in a lot of networks. REFRESH_HOSTNAMES=ALL - Do the hourly PTR lookups for all addresses This is the same as what we're doing with FTL v5.3(.1). This can create a lot of PTR queries for those with many IPv6 addresses in their networks. REFRESH_HOSTNAMES=UNKNOWN - Only resolve unknown hostnames Already existing hostnames are never refreshed, i.e., there will be no PTR queries made for clients where hostnames are known. This also means that known hostnames will not be updated once known. REFRESH_HOSTNAMES=NONE - Don't do any hourly PTR lookups This means we look host names up exactly once (when we first see a client) and never again. You may miss future changes of host names.","title":"Refresh hostnames"},{"location":"pi-hole/ftldns/configfile/#parse_arp_cache","text":"This setting can be used to disable ARP cache processing. When disabled, client identification and the network table will stop working reliably.","title":"Parse ARP cache"},{"location":"pi-hole/ftldns/configfile/#check_load","text":"Pi-hole is very lightweight on resources. Nevertheless, this does not mean that you should run Pi-hole on a server that is otherwise extremely busy as queuing on the system can lead to unnecessary delays in DNS operation as the system becomes less and less usable as the system load increases because all resources are permanently in use. To account for this, FTL regularly checks the system load. To bring this to your attention, FTL warns about excessive load when the 15 minute system load average exceeds the number of cores. This check can be disabled with this setting.","title":"Check system load"},{"location":"pi-hole/ftldns/configfile/#check_shmem","text":"FTL stores history in shared memory to allow inter-process communication with forked dedicated TCP workers. If FTL runs out of memory, it cannot continue to work as queries cannot be analyzed any further. Hence, FTL checks if enough shared memory is available on your system and warns you if this is not the case. By default, FTL warns if the shared-memory usage exceeds 90%. You can set any integer limit between 0 to 100 (interpreted as percentages) where 0 means that checking of shared-memory usage is disabled.","title":"Check shared-memory limits"},{"location":"pi-hole/ftldns/configfile/#check_disk","text":"FTL stores its long-term history in a database file on disk (see here ). Furthermore, FTL stores log files (see, e.g., here ). By default, FTL warns if usage of the disk holding any crucial file exceeds 90%. You can set any integer limit between 0 to 100 (interpreted as percentages) where 0 means that checking of disk usage is disabled.","title":"Check disk space"},{"location":"pi-hole/ftldns/configfile/#long-term-database-settings","text":"Further details concerning the database","title":"Long-term database settings"},{"location":"pi-hole/ftldns/configfile/#dbimport","text":"Should FTL load information from the database on startup to be aware of the most recent history?","title":"Use database"},{"location":"pi-hole/ftldns/configfile/#maxdbdays","text":"How long should queries be stored in the database? Setting this to 0 disables the database","title":"Max age"},{"location":"pi-hole/ftldns/configfile/#dbinterval","text":"How often do we store queries in FTL's database [minutes]?","title":"Storing Interval"},{"location":"pi-hole/ftldns/configfile/#dbfile","text":"Specify the path and filename of FTL's SQLite3 long-term database. Setting this to DBFILE= disables the database altogether","title":"Database Filename"},{"location":"pi-hole/ftldns/configfile/#file-options","text":"","title":"File options"},{"location":"pi-hole/ftldns/configfile/#file_LOGFILE","text":"The location of FTL's log file. If you want to move the log file to a different place, also consider this FAQ article .","title":"Log file"},{"location":"pi-hole/ftldns/configfile/#file_PIDFILE","text":"The file which contains the PID of FTL's main process.","title":"Process identifier file"},{"location":"pi-hole/ftldns/configfile/#file_PORTFILE","text":"The file containing the port FTL's API is listening on.","title":"Port file"},{"location":"pi-hole/ftldns/configfile/#file_SOCKETFILE","text":"The file containing the socket FTL's API is listening on.","title":"Socket file"},{"location":"pi-hole/ftldns/configfile/#file_SETUPVARSFILE","text":"The config file of Pi-hole containing, e.g., the current blocking status (do not change).","title":"setupVars file"},{"location":"pi-hole/ftldns/configfile/#file_MACVENDORDB","text":"The database containing MAC -> Vendor information for the network table.","title":"MacVendor database file"},{"location":"pi-hole/ftldns/configfile/#file_GRAVITYDB","text":"Specify path and filename of FTL's SQLite3 gravity database. This database contains all domains relevant for Pi-hole's DNS blocking","title":"Gravity database"},{"location":"pi-hole/ftldns/configfile/#debugging-options","text":"","title":"Debugging options"},{"location":"pi-hole/ftldns/configfile/#debug_all","text":"Enable all debug flags. If this is set to true, all other debug config options are ignored.","title":"All"},{"location":"pi-hole/ftldns/configfile/#debug_database","text":"Print debugging information about database actions. This prints performed SQL statements as well as some general information such as the time it took to store the queries and how many have been saved to the database.","title":"Database"},{"location":"pi-hole/ftldns/configfile/#debug_networking","text":"Prints a list of the detected interfaces on the startup of pihole-FTL . Also, prints whether these interfaces are IPv4 or IPv6 interfaces.","title":"Networking"},{"location":"pi-hole/ftldns/configfile/#debug_edns0","text":"Print debugging information about received EDNS(0) data.","title":"EDNS0"},{"location":"pi-hole/ftldns/configfile/#debug_locks","text":"Print information about shared memory locks. Messages will be generated when waiting, obtaining, and releasing a lock.","title":"Locks"},{"location":"pi-hole/ftldns/configfile/#debug_queries","text":"Print extensive query information (domains, types, replies, etc.). This has always been part of the legacy debug mode of pihole-FTL .","title":"Queries"},{"location":"pi-hole/ftldns/configfile/#debug_flags","text":"Print flags of queries received by the DNS hooks. Only effective when DEBUG_QUERIES is enabled as well.","title":"Flags"},{"location":"pi-hole/ftldns/configfile/#debug_shmem","text":"Print information about shared memory buffers. Messages are either about creating or enlarging shmem objects or string injections.","title":"Shared Memory"},{"location":"pi-hole/ftldns/configfile/#debug_gc","text":"Print information about garbage collection (GC): What is to be removed, how many have been removed and how long did GC take.","title":"Garbage Collection"},{"location":"pi-hole/ftldns/configfile/#debug_arp","text":"Print information about ARP table processing: How long did parsing take, whether read MAC addresses are valid, and if the macvendor.db file exists.","title":"Neighbor parsing"},{"location":"pi-hole/ftldns/configfile/#debug_regex","text":"Controls if FTL DNS should print extended details about regex matching into pihole-FTL.log . More details","title":"Regular expressions"},{"location":"pi-hole/ftldns/configfile/#debug_api","text":"Print extra debugging information during telnet API calls. Currently only used to send extra information when getting all queries.","title":"Telnet"},{"location":"pi-hole/ftldns/configfile/#debug_overtime","text":"Print information about overTime memory operations, such as initializing or moving overTime slots.","title":"Over Time Data"},{"location":"pi-hole/ftldns/configfile/#debug_status","text":"Print information about status changes for individual queries. This can be useful to identify unexpected unknown queries.","title":"Query status"},{"location":"pi-hole/ftldns/configfile/#debug_caps","text":"Print information about capabilities granted to the pihole-FTL process. The current capabilities are printed on receipt of SIGHUP , i.e., the current set of capabilities can be queried without restarting pihole-FTL (by setting DEBUG_CAPS=true and thereafter sending killall -HUP pihole-FTL ).","title":"Linux capabilities"},{"location":"pi-hole/ftldns/configfile/#debug_dnsmasq_lines","text":"Print file and line causing a dnsmasq event into FTL's log files. This is handy to implement additional hooks missing from FTL.","title":"Analyze dnsmasq log lines"},{"location":"pi-hole/ftldns/configfile/#debug_vectors","text":"FTL uses dynamically allocated vectors for various tasks. This config option enables extensive debugging information such as information about allocation, referencing, deletion, and appending.","title":"Vectors"},{"location":"pi-hole/ftldns/configfile/#debug_resolver","text":"Extensive information about hostname resolution like which DNS servers are used in the first and second hostname resolving tries (only affecting internally generated PTR queries).","title":"Resolver details"},{"location":"pi-hole/ftldns/configfile/#debug_edns0","text":"Verbose logging during EDNS(0) header analysis.","title":"EDNS0"},{"location":"pi-hole/ftldns/configfile/#debug_clients","text":"Log various important client events such as change of interface (e.g., client switching from WiFi to wired or VPN connection), as well as extensive reporting about how clients were assigned to its groups.","title":"Clients"},{"location":"pi-hole/ftldns/configfile/#debug_aliasclients","text":"Log information related to alias-client processing.","title":"Aliasclients"},{"location":"pi-hole/ftldns/configfile/#debug_events","text":"Log information regarding FTL's embedded event handling queue.","title":"Events"},{"location":"pi-hole/ftldns/configfile/#debug_helper","text":"Log information about script helpers, e.g., due to dhcp-script .","title":"Script helpers"},{"location":"pi-hole/ftldns/configfile/#addr2line","text":"Should FTL translate its own stack addresses into code lines during the bug backtrace? This improves the analysis of crashed significantly. It is recommended to leave the option enabled. This option should only be disabled when addr2line is known to not be working correctly on the machine because, in this case, the malfunctioning addr2line can prevent from generating any backtrace at all.","title":"Addr2Line"},{"location":"pi-hole/ftldns/configfile/#debug_extra","text":"Temporary flag that may print additional information. This debug flag is meant to be used whenever needed for temporary investigations. The logged content may change without further notice at any time.","title":"Misc."},{"location":"pi-hole/ftldns/configfile/#deprecated-options","text":"","title":"Deprecated options"},{"location":"pi-hole/ftldns/configfile/#reply_addr4","text":"This option is deprecated and may be removed in future versions, please use BLOCK_IPV4 and LOCAL_IPV4 instead If neither BLOCK_IPV4 nor LOCAL_IPV4 are set, this setting is used to set both of them. If either of the two is set, this setting is ignored altogether.","title":"Force A reply"},{"location":"pi-hole/ftldns/configfile/#reply_addr6","text":"This option is deprecated and may be removed in future versions, please use BLOCK_IPV6 and LOCAL_IPV6 instead If neither BLOCK_IPV6 nor LOCAL_IPV6 are set, this setting is used to set both of them. If either of the two is set, this setting is ignored altogether.","title":"Force AAAA reply"},{"location":"pi-hole/ftldns/debugging/","text":"Debugging FTLDNS using gdb \u00b6 Once you are used to it, you can skip most of the steps. Debugging FTL DNS is quite easy. pihole-FTL has been designed so that a debugger can be attached to an already running process. This will give you insights into how software (not limited to pihole-FTL ) works. Prerequirements (only required once) \u00b6 Install screen and gdb using sudo apt-get install screen gdb Start a screen session (it will allow you to come back even if the SSH connection died) If you don't know about screen , then read about it (you will love it!) Start a screen session using screen Configure gdb by installing a globally valid initialization file: echo \"handle SIGHUP nostop SIGPIPE nostop SIGTERM nostop SIG32 nostop SIG34 nostop SIG35 nostop\" | sudo tee /root/.gdbinit You can omit this step, however, you will have to remember to run the quoted line on every start of gdb in order to properly debug FTL. Start of debugging session \u00b6 Use sudo gdb -p $(pidof pihole-FTL) to attach the debugger to the already running pihole-FTL process Once loading of the symbols has finished (the (gdb) input prompt is shown), enter continue to continue the operation of pihole-FTL inside the debugger. All debugger features are now available. When pihole-FTL has crashed, copy & paste the terminal output into a (new) issue. Also, type backtrace and include its output. We might ask for additional information in order to isolate your particular issue.","title":"Debugging FTLDNS using `gdb`"},{"location":"pi-hole/ftldns/debugging/#debugging-ftldns-using-gdb","text":"Once you are used to it, you can skip most of the steps. Debugging FTL DNS is quite easy. pihole-FTL has been designed so that a debugger can be attached to an already running process. This will give you insights into how software (not limited to pihole-FTL ) works.","title":"Debugging FTLDNS using gdb"},{"location":"pi-hole/ftldns/debugging/#prerequirements-only-required-once","text":"Install screen and gdb using sudo apt-get install screen gdb Start a screen session (it will allow you to come back even if the SSH connection died) If you don't know about screen , then read about it (you will love it!) Start a screen session using screen Configure gdb by installing a globally valid initialization file: echo \"handle SIGHUP nostop SIGPIPE nostop SIGTERM nostop SIG32 nostop SIG34 nostop SIG35 nostop\" | sudo tee /root/.gdbinit You can omit this step, however, you will have to remember to run the quoted line on every start of gdb in order to properly debug FTL.","title":"Prerequirements (only required once)"},{"location":"pi-hole/ftldns/debugging/#start-of-debugging-session","text":"Use sudo gdb -p $(pidof pihole-FTL) to attach the debugger to the already running pihole-FTL process Once loading of the symbols has finished (the (gdb) input prompt is shown), enter continue to continue the operation of pihole-FTL inside the debugger. All debugger features are now available. When pihole-FTL has crashed, copy & paste the terminal output into a (new) issue. Also, type backtrace and include its output. We might ask for additional information in order to isolate your particular issue.","title":"Start of debugging session"},{"location":"pi-hole/ftldns/dns-cache/","text":"pihole-FTL offers an efficient DNS cache that helps speed up your Internet experience. This DNS cache is part of the embedded dnsmasq server. Setting the cache size to zero disables caching. The DNS TTL value is used for determining the caching period. pihole-FTL clears its cache on receiving SIGHUP . Warning There is no benefit in increasing this number unless the number of DNS cache evictions is greater than zero. A larger cache will consume more memory on your node, leaving less memory available for other caches of your Pi-hole. If you push this number to the extremes, it may even be that your Pi-hole gets short on memory and does not operate as expected. You can not reduce the cache size below 150 when DNSSEC is enabled because the DNSSEC validation process uses the cache. Cache metrics \u00b6 The Settings page (System panel, FTL table) gives live information about the cache usage. It obtains its information from http://pi.hole/admin/api.php?getCacheInfo . DNS cache size \u00b6 Size of the DNS domain cache, defaulting to 10,000 entries. It is the number of entries that can be actively cached at the same time. This information may also be queried using dig +short chaos txt cachesize.bind The cache size is set in /etc/dnsmasq.d/01-pihole.conf . However, note that this setting does not survive Pi-hole updates. If you want to change the cache size permanently, add a setting CACHE_SIZE=12345 in /etc/pihole/setupVars.conf and run pihole -r (Repair) to get the cache size changed for you automatically. DNS cache insertions \u00b6 Number of total insertions into the cache. This number can be substantially larger than DNS cache size as expiring cache entries naturally make room for new insertions over time. Each lookup with a non-zero TTL will be cached. This information may also be queried using dig +short chaos txt insertions.bind DNS cache evictions \u00b6 The number of cache entries that had to be removed although the corresponding entries were not expired. Old cache entries get removed if the cache is full to make space for more recent domains. The cache size should be increased when this number is larger than zero. This information may also be queried using dig +short chaos txt evictions.bind","title":"Dns cache"},{"location":"pi-hole/ftldns/dns-cache/#cache-metrics","text":"The Settings page (System panel, FTL table) gives live information about the cache usage. It obtains its information from http://pi.hole/admin/api.php?getCacheInfo .","title":"Cache metrics"},{"location":"pi-hole/ftldns/dns-cache/#dns-cache-size","text":"Size of the DNS domain cache, defaulting to 10,000 entries. It is the number of entries that can be actively cached at the same time. This information may also be queried using dig +short chaos txt cachesize.bind The cache size is set in /etc/dnsmasq.d/01-pihole.conf . However, note that this setting does not survive Pi-hole updates. If you want to change the cache size permanently, add a setting CACHE_SIZE=12345 in /etc/pihole/setupVars.conf and run pihole -r (Repair) to get the cache size changed for you automatically.","title":"DNS cache size"},{"location":"pi-hole/ftldns/dns-cache/#dns-cache-insertions","text":"Number of total insertions into the cache. This number can be substantially larger than DNS cache size as expiring cache entries naturally make room for new insertions over time. Each lookup with a non-zero TTL will be cached. This information may also be queried using dig +short chaos txt insertions.bind","title":"DNS cache insertions"},{"location":"pi-hole/ftldns/dns-cache/#dns-cache-evictions","text":"The number of cache entries that had to be removed although the corresponding entries were not expired. Old cache entries get removed if the cache is full to make space for more recent domains. The cache size should be increased when this number is larger than zero. This information may also be queried using dig +short chaos txt evictions.bind","title":"DNS cache evictions"},{"location":"pi-hole/ftldns/dns-resolver/","text":"FTL DNS comes with a lightweight but powerful inbuilt DNS/DHCP/TFTP/... server eliminating the need to install dnsmasq separately (we used to do this before Pi-hole v4.0). However, it is important to understand that we are not moving away from dnsmasq , but, in contrast, are coupling even closer to it by incorporating it into FTL. This provides us with a much more reliable monolith DNS solution where we can be sure that the versions of FTL and the DNS internals are always 100% compatible with each other. As we maintain our own fork of dnsmasq we have been able to apply some minimal changes to the source code which might bring substantial benefits for our users. However, although the potential for changes is endless, we want to include as few modifications as possible. As a purely volunteer-driven project, you will surely understand that it was already a major undertaking to get FTL DNS set up and running. It was much more than just copy-pasting dnsmasq into place. We have always been very explicit about how we will react to feature requests that target the resolver part (from the initial FTL DNS beta test announcement): Think of FTL DNS as dnsmasq with Pi-hole\u2019s special sauce. This allows us to easily merge any upstream changes that get added, while still allowing us to continue to develop Pi-hole as we have been. If we would start to modify the resolver code in too many places, then this would probably make us deviate too much from dnsmasq 's code base and we couldn't apply patches easily preventing us from being able to ship important security updates. Implemented modifications in dnsmasq 's source code \u00b6 FTL hooks \u00b6 We place hooks in a lot of places in the resolver that branch out into FTL code to process queries and responses. By this, we keep the resolver code itself clean. Remove limit on maximum cache size \u00b6 Users can configure the size of the resolver's name cache. The default is 150 names. Setting the cache size to zero disables caching. We think users should be allowed to set the cache size to any value they find appropriate. However, dnsmasq 's source code contains a condition that limits the maximum size of the cache to 10,000 names. We removed this hard-coded upper limit in and submitted a patch to remove this hard-coded limit in the upstream version of dnsmasq . It was accepted for dnsmasq v2.81 . Improve detection algorithm for determining the \"best\" forward destination \u00b6 The DNS forward destination determination algorithm in FTL DNS's is modified to be much less restrictive than the original algorithm in dnsmasq . We keep using the fastest responding server now for 1000 queries or 10 minutes (whatever happens earlier) instead of 50 queries or 10 seconds (default values in dnsmasq ). We keep the exceptions, i.e., we try all possible forward destinations if SERVFAIL or REFUSED is received or if a timeout occurs. Overall, this change has proven to greatly reduce the number of actually performed queries in typical Pi-hole environments. It may even be understood as being preferential in terms of privacy (as we send queries much less often to all servers). This has been implemented in commit d1c163e .","title":"Dns resolver"},{"location":"pi-hole/ftldns/dns-resolver/#implemented-modifications-in-dnsmasqs-source-code","text":"","title":"Implemented modifications in dnsmasq's source code"},{"location":"pi-hole/ftldns/dns-resolver/#ftl-hooks","text":"We place hooks in a lot of places in the resolver that branch out into FTL code to process queries and responses. By this, we keep the resolver code itself clean.","title":"FTL hooks"},{"location":"pi-hole/ftldns/dns-resolver/#remove-limit-on-maximum-cache-size","text":"Users can configure the size of the resolver's name cache. The default is 150 names. Setting the cache size to zero disables caching. We think users should be allowed to set the cache size to any value they find appropriate. However, dnsmasq 's source code contains a condition that limits the maximum size of the cache to 10,000 names. We removed this hard-coded upper limit in and submitted a patch to remove this hard-coded limit in the upstream version of dnsmasq . It was accepted for dnsmasq v2.81 .","title":"Remove limit on maximum cache size"},{"location":"pi-hole/ftldns/dns-resolver/#improve-detection-algorithm-for-determining-the-best-forward-destination","text":"The DNS forward destination determination algorithm in FTL DNS's is modified to be much less restrictive than the original algorithm in dnsmasq . We keep using the fastest responding server now for 1000 queries or 10 minutes (whatever happens earlier) instead of 50 queries or 10 seconds (default values in dnsmasq ). We keep the exceptions, i.e., we try all possible forward destinations if SERVFAIL or REFUSED is received or if a timeout occurs. Overall, this change has proven to greatly reduce the number of actually performed queries in typical Pi-hole environments. It may even be understood as being preferential in terms of privacy (as we send queries much less often to all servers). This has been implemented in commit d1c163e .","title":"Improve detection algorithm for determining the \"best\" forward destination"},{"location":"pi-hole/ftldns/dnsmasq_warn/","text":"Known dnsmasq warnings \u00b6 Warnings commonly seen in dnsmasq 's log file ( /var/log/pihole.log ) and the Pi-hole diagnosis system. ignoring zone transfer request from ADDRESS Zone transfer requests (AXFR) are refused unless auth-sec-servers or auth-peers is set. The address requesting the AXFR is logged. DHCP request for unsupported hardware type ( X ) received on Y dnsmasq only supports Ethernet on *BSD. The integer X describes the hardware type (see /usr/include/linux/if_arp.h for definitions). Y is the name of the receiving interface. Unknown protocol version from route socket As the warning says. No action is performed in this case. No IPv4 address found for HOSTNAME Lookup for an A record in the cache returned no result. HOSTNAME is a CNAME, not giving it to the DHCP lease of ADDRESS A hostname claimed by a DHCP client is a known CNAME. dnsmasq does not allow the DHCP clients to take this name. not giving name HOSTNAME to the DHCP lease of ADDRESS because the name exists in SOURCE with address CACHE_ADDR If HOSTNAME is known through a HOSTS file or config (see SOURCE ) and the DHCP address ADDRESS does not match the address in the cache ( CACHE_ADDR ), dnsmasq prevents giving the name to a DHCP client. This prevents possible hostname hijacking by malicious devices. unknown interface IF_NAME in bridge-interface If the interface on which the DHCPv6 request was received is an alias of some other interface (as specified by the bridge-interface option), dnsmasq needs to look for DHCPv6 contexts associated with the aliased interface instead of with the aliasing one. This warning complains that the referenced interface does not exist. DHCP packet received on IF_NAME which has no address No DHCP context has been configured for this interface. Check your DHCP settings. Error sending DHCP packet to ADDRESS : MSG This can fail when, e.g., iptables DROPS destination 255.255.255.255 . Check your firewall settings. DHCP range ADDRESS_FROM -- ADDRESS_TO is not consistent with netmask SUBNET_MASK This warning highlights that one of the two addresses is outside of the configured subnet mask. As a consequence, not all addresses may be reachable from configured hosts leading to unexpected behavior on the clients. Make your DHCP settings consistent. Ignoring duplicate dhcp-option OPTNUM DHCP options specified more than once are ignored. The corresponding option ID is given by OPTNUM HOSTNAME has more than one address in hostsfile, using ADDRESS for DHCP Some people like to keep all static IP addresses in /etc/hosts . dnsmasq goes through /etc/hosts and sets static addresses for any DHCP config records which don't have an address and whose name matches where dnsmasq maintains the invariant that any IP address can appear in at least one DHCP host. duplicate IP address ADDRESS ( HOSTNAME ) in dhcp-config directive As the warning says. cache size greater than 10000 may cause performance issues, and is unlikely to be useful. This causes the cache to consume a lot on memory and slows down cache lookups. As expiring cache entries naturally make room for new records, a large cache does not give any advantages beyond a certain level. This level is typically not very high. Try reducing the cache. Watch out for cache-evictions. If they are zero over a long time, your cache is larger than what you need. warning: failed to change owner of PIDFILE : MSG Changing the ownership of the PID file ( PIDFILE ) to the user dnsmasq will be running as failed. A descriptive error message ( MSG ) is given to explain why the chown failed. setting --bind-interfaces option because of OS limitations Only affects non-Linux builds. bind-dynamic is not supported on non-Linux. dnsmasq falls back to bind-interfaces warning: interface NAME does not currently exist As the warning says. Likely caused by an interface=NAME option where the interface NAME does not exist. Check if your operating system may have changed from simple (like eth0 ) to predictable (like enp2s0 ) interface names. Update your configuration accordingly. warning: ignoring resolv-file flag because no-resolv is set This points to a conflicting configuration that may not behave as expected. Remove either the resolv-file or the --no-resolv option. warning: no upstream servers configured Only local names can be answered as no server=... lines are defined. warning: PATH inaccessible The TFTP prefix (set by tftp-prefix ) is inaccessible or not a directory. warning: TFTP directory PATH inaccessible One of the defined TFTP prefix (comma-separated arguments of tftp-prefix ) is inaccessible or not a directory. restricting maximum simultaneous TFTP transfers to NUMBER If a limited range of ports is in use, this also limits the number of concurrent TFTP transfers. script process killed by signal SIGNUM A script helper was killed by an external signal ( SIGNUM ). script process exited with status EXITCODE A script helper exited with a non-success return code ( EXITCODE ). failed to access RESOLV_FILE : MSG This line is logged when dnsmasq fails to access one of the files defined through resolv-file . This warning is printed only once per file. no servers found in RESOLV_FILE , will retry The read file was empty. dnsmasq will read it again. This warning is printed only once per file. Insecure DS reply received for DOMAIN , check domain configuration and upstream DNS server DNSSEC support A query was marked BOGUS because a DS query could not be validated (returned INSECURE). discarding DNS reply: subnet option mismatch When the EDNS0 option add-subnet is in use, dnsmasq needs to check the reply. If the returned subnet does not match, the reply is treated as invalid. nameserver ADDRESS refused to do a recursive query Upstream at address ADDRESS is missing the RA (recursion available) bit. This warning is printed only once per server. possible DNS-rebind attack detected: NAME A and AAAA answers are checked against possible rebind attacks when stop-dns-rebind is enabled. See rebind-domain-ok=/domain/ for adding exceptions. reducing DNS packet size for nameserver ADDRESS to SAFE_PKTSZ When receiving answers from upstream only with a smaller maximum DNS packet size, dnsmasq warns about this and remembers this decision per server for some time (defaulting to 60 seconds). If you see this message continuously, you are affected by some unusual truncation on the path from your Pi-hole to the configured upstream server. You can get rid of the warning by adding a config file like /etc/dnsmasq.d/99-edns.conf and adding edns-packet-max=1232 After running pihole restartdns your Pi-hole will not even try larger packet sizes (the default is 4096). Check out our unbound guide for a comment about the particular value of 1232 . Ignoring query from non-local network dnsmasq can be configured to only accept queries from at-most-one-hop-away addresses using the option local-service . Other queries are discarded in this case. This is meant to be a safe default to keep otherwise unconfigured installations safe. Note that local-service is ignored if any access-control config is in place ( interface , except-interface , listen-address or auth-server ). Maximum number of concurrent DNS queries reached (max: NUMBER ) The configured maximum number of concurrent DNS queries for a given server is reached. The system is either very busy at the moment or not receiving queries from the configured upstream. Check your connectivity or the upstream DNS server status. The warning can also be printed when being spammed with an excessive amount of duplicates or when the upstream server never replies for specific domains. Check your logs and try to identify similarities between the query directly preceding this warning and earlier queries in /var/log/pihole.log . Try to find out if your upstream does maybe never reply to specific domains and fix this. This warning is printed at most once every five seconds (per upstream server) to help mitigate unlimited log file growth. Maximum number of concurrent DNS queries to DOMAIN reached (max: NUMBER ) Same as above but for a specific domain. ignoring invalid line in lease database: STRING STRING STRING STRING ... An invalid line in the lease file has been skipped. ignoring invalid line in lease database, bad address: ADDRESS Address found in the lease file is neither a valid IPv4 nor a valid IPv6 address. The line is skipped. Ignoring domain CONFIG_DOMAIN for DHCP host name HOSTNAME A DHCP client is not allowed to claim name HOSTNAME in the current DHCP configuration. overflow: NUMBER log entries lost When using asynchronous logging and the disk is too slow, we can loose log lines during busy times. This can be avoided by decreasing the system load or switching to synchronous logging. Note that synchronous logging has the disadvantage of blocking DNS resolution when waiting for the log to be written to disk. failed to create listening socket for ADDRESS : MSG A failure to bind addresses given by listen-address is accepted when dnsmasq is configured with bind-dynamic . failed to create listening socket for port NUMBER : MSG Same as above but for a port rather than an address. LOUD WARNING: listening on ADDRESSS may accept requests via interfaces other than IFNAME When using bind-interfaces , the only access control is the addresses dnsmasq is listening on. There's nothing to avoid a query to the address of an internal interface arriving via an external interface where we don't want to accept queries, except that in the usual case the addresses of internal interfaces are RFC1918. When bind-interfaces in use, and we listen on an address that looks like it's probably globally routeable, this warning is printed. LOUD WARNING: use --bind-dynamic rather than --bind-interfaces to avoid DNS amplification attacks via these interface(s) Advise printed when above's warning is printed. This warning is printed only once. warning: using interface IF_NAME instead When configuring an interface alias (like eth0:0 ), dnsmasq will be listening on the physical (e.g. eth0 ) interface, instead. warning: no addresses found for interface IF_NAME dnsmasq has been configured to listen on an interface that has no address assigned to it. ignoring nameserver ADDRESS - local interface At least one server directive is redundant and point to the dnsmasq instance itself. The server is ignored. ignoring nameserver ADDRESS - cannot make/bind socket: MSG dnsmasq failed to allocate a socket for the mentioned server. The server is ignored. no address range available for DHCP request with subnet selector SUBNET No DHCP context has been configured for this subnet selector. Check your DHCP settings. no address range available for DHCP request via ADDRESS No DHCP context has been configured for this address. Check your DHCP settings. no address range available for DHCP request via IF_NAME No DHCP context has been configured for this interface. Check your DHCP settings. This warning is expected during debug log generation as Pi-hole is trying to request a DHCP lease on all available interfaces. We do this to test that the server replies properly. When an interface does not have a DHCP configuration (such as the loopback interface lo , or other special interfaces such as docker0 ), this warning is printed. You can safely ignore it when it happens only during DHCP testing, e.g., during Pi-hole debug log generation. If it happens often, you can use the option no-dhcp-interface=IF_NAME (insert the interface name here) to specifically disable DHCP on this interface. disabling DHCP static address ADDRESS for HOSTNAME Static DHCP leases are disabled when sending a DHCPDECLINE packet. not using configured address ADDRESS because it is leased to MAC Not handing out configured address because it is already actively used to another device with hardware address MAC . not using configured address ADDRESS because it is in use by the server or relay Handing out addresses used by known critical infrastructure (like the DHCP server or a relay) is prevented to avoid IP address duplication issues. This can happen when you have configured a static address assignment for the IP address of your Pi-hole. As this could result in an IP address conflict, Pi-hole offers a different free address from your configured DHCP pool. As this means Pi-hole behaves differently than you configured it to, it issues a warning. The solution would be to either remove the static reservation for the Pi-hole itself (see ADDRESS in the warning) or simply accept this warning as it should only happen during debug log generation. When this warning appears outside of a running DHCP test, check that your Pi-hole is indeed using a static address. not using configured address ADDRESS because it was previously declined As the warning says. Check your log file for reasons of a prior refusal to hand out this lease. This warning is at most logged once every 10 minutes for a given address. cannot send DHCP/BOOTP option NUMBER : no space left in packet Use less DHCP options as the space for options is limited and cannot be extended (RFC2131). cannot send RFC3925 option: too many options for enterprise number NUMBER A maximum packet length of 250 bytes has to be ensured for dhcp-option = vi-encap:13,17,... configurations. no address range available for DHCPv6 request from relay at ADDRESS No DHCPv6 context has been configured for this address. Check your DHCPv6 settings. no address range available for DHCPv6 request via IF_NAME No DHCPv6 context has been configured for this interface. Check your DHCPv6 settings. If you do not have an upstreams IPv6 connection (use, e.g., test-ipv6.com for testing), Pi-hole does not have any address prefix it could use to build DHCPv6 addresses causing this warning on every DHCPv6 request. The solution will be to disable DHCPv6 in your Pi-hole. disabling DHCP static address ADDRESS for TIME Static DHCPv6 leases are disabled when sending a DHCP(6)DECLINE packet. IPset: error: MSG A non-critical error was encountered when trying to access an IPset device. A human-readable message explains it further. warning: DIOCRADDADDRS: MSG A non-critical error was encountered when trying to add an address to an existing ipset . A human-readable message explains it further. warning: DIOCRDELADDRS: MSG A non-critical error was encountered when trying to remove an address from an existing ipset . A human-readable message explains it further.","title":"Known `dnsmasq` warnings"},{"location":"pi-hole/ftldns/dnsmasq_warn/#known-dnsmasq-warnings","text":"Warnings commonly seen in dnsmasq 's log file ( /var/log/pihole.log ) and the Pi-hole diagnosis system. ignoring zone transfer request from ADDRESS Zone transfer requests (AXFR) are refused unless auth-sec-servers or auth-peers is set. The address requesting the AXFR is logged. DHCP request for unsupported hardware type ( X ) received on Y dnsmasq only supports Ethernet on *BSD. The integer X describes the hardware type (see /usr/include/linux/if_arp.h for definitions). Y is the name of the receiving interface. Unknown protocol version from route socket As the warning says. No action is performed in this case. No IPv4 address found for HOSTNAME Lookup for an A record in the cache returned no result. HOSTNAME is a CNAME, not giving it to the DHCP lease of ADDRESS A hostname claimed by a DHCP client is a known CNAME. dnsmasq does not allow the DHCP clients to take this name. not giving name HOSTNAME to the DHCP lease of ADDRESS because the name exists in SOURCE with address CACHE_ADDR If HOSTNAME is known through a HOSTS file or config (see SOURCE ) and the DHCP address ADDRESS does not match the address in the cache ( CACHE_ADDR ), dnsmasq prevents giving the name to a DHCP client. This prevents possible hostname hijacking by malicious devices. unknown interface IF_NAME in bridge-interface If the interface on which the DHCPv6 request was received is an alias of some other interface (as specified by the bridge-interface option), dnsmasq needs to look for DHCPv6 contexts associated with the aliased interface instead of with the aliasing one. This warning complains that the referenced interface does not exist. DHCP packet received on IF_NAME which has no address No DHCP context has been configured for this interface. Check your DHCP settings. Error sending DHCP packet to ADDRESS : MSG This can fail when, e.g., iptables DROPS destination 255.255.255.255 . Check your firewall settings. DHCP range ADDRESS_FROM -- ADDRESS_TO is not consistent with netmask SUBNET_MASK This warning highlights that one of the two addresses is outside of the configured subnet mask. As a consequence, not all addresses may be reachable from configured hosts leading to unexpected behavior on the clients. Make your DHCP settings consistent. Ignoring duplicate dhcp-option OPTNUM DHCP options specified more than once are ignored. The corresponding option ID is given by OPTNUM HOSTNAME has more than one address in hostsfile, using ADDRESS for DHCP Some people like to keep all static IP addresses in /etc/hosts . dnsmasq goes through /etc/hosts and sets static addresses for any DHCP config records which don't have an address and whose name matches where dnsmasq maintains the invariant that any IP address can appear in at least one DHCP host. duplicate IP address ADDRESS ( HOSTNAME ) in dhcp-config directive As the warning says. cache size greater than 10000 may cause performance issues, and is unlikely to be useful. This causes the cache to consume a lot on memory and slows down cache lookups. As expiring cache entries naturally make room for new records, a large cache does not give any advantages beyond a certain level. This level is typically not very high. Try reducing the cache. Watch out for cache-evictions. If they are zero over a long time, your cache is larger than what you need. warning: failed to change owner of PIDFILE : MSG Changing the ownership of the PID file ( PIDFILE ) to the user dnsmasq will be running as failed. A descriptive error message ( MSG ) is given to explain why the chown failed. setting --bind-interfaces option because of OS limitations Only affects non-Linux builds. bind-dynamic is not supported on non-Linux. dnsmasq falls back to bind-interfaces warning: interface NAME does not currently exist As the warning says. Likely caused by an interface=NAME option where the interface NAME does not exist. Check if your operating system may have changed from simple (like eth0 ) to predictable (like enp2s0 ) interface names. Update your configuration accordingly. warning: ignoring resolv-file flag because no-resolv is set This points to a conflicting configuration that may not behave as expected. Remove either the resolv-file or the --no-resolv option. warning: no upstream servers configured Only local names can be answered as no server=... lines are defined. warning: PATH inaccessible The TFTP prefix (set by tftp-prefix ) is inaccessible or not a directory. warning: TFTP directory PATH inaccessible One of the defined TFTP prefix (comma-separated arguments of tftp-prefix ) is inaccessible or not a directory. restricting maximum simultaneous TFTP transfers to NUMBER If a limited range of ports is in use, this also limits the number of concurrent TFTP transfers. script process killed by signal SIGNUM A script helper was killed by an external signal ( SIGNUM ). script process exited with status EXITCODE A script helper exited with a non-success return code ( EXITCODE ). failed to access RESOLV_FILE : MSG This line is logged when dnsmasq fails to access one of the files defined through resolv-file . This warning is printed only once per file. no servers found in RESOLV_FILE , will retry The read file was empty. dnsmasq will read it again. This warning is printed only once per file. Insecure DS reply received for DOMAIN , check domain configuration and upstream DNS server DNSSEC support A query was marked BOGUS because a DS query could not be validated (returned INSECURE). discarding DNS reply: subnet option mismatch When the EDNS0 option add-subnet is in use, dnsmasq needs to check the reply. If the returned subnet does not match, the reply is treated as invalid. nameserver ADDRESS refused to do a recursive query Upstream at address ADDRESS is missing the RA (recursion available) bit. This warning is printed only once per server. possible DNS-rebind attack detected: NAME A and AAAA answers are checked against possible rebind attacks when stop-dns-rebind is enabled. See rebind-domain-ok=/domain/ for adding exceptions. reducing DNS packet size for nameserver ADDRESS to SAFE_PKTSZ When receiving answers from upstream only with a smaller maximum DNS packet size, dnsmasq warns about this and remembers this decision per server for some time (defaulting to 60 seconds). If you see this message continuously, you are affected by some unusual truncation on the path from your Pi-hole to the configured upstream server. You can get rid of the warning by adding a config file like /etc/dnsmasq.d/99-edns.conf and adding edns-packet-max=1232 After running pihole restartdns your Pi-hole will not even try larger packet sizes (the default is 4096). Check out our unbound guide for a comment about the particular value of 1232 . Ignoring query from non-local network dnsmasq can be configured to only accept queries from at-most-one-hop-away addresses using the option local-service . Other queries are discarded in this case. This is meant to be a safe default to keep otherwise unconfigured installations safe. Note that local-service is ignored if any access-control config is in place ( interface , except-interface , listen-address or auth-server ). Maximum number of concurrent DNS queries reached (max: NUMBER ) The configured maximum number of concurrent DNS queries for a given server is reached. The system is either very busy at the moment or not receiving queries from the configured upstream. Check your connectivity or the upstream DNS server status. The warning can also be printed when being spammed with an excessive amount of duplicates or when the upstream server never replies for specific domains. Check your logs and try to identify similarities between the query directly preceding this warning and earlier queries in /var/log/pihole.log . Try to find out if your upstream does maybe never reply to specific domains and fix this. This warning is printed at most once every five seconds (per upstream server) to help mitigate unlimited log file growth. Maximum number of concurrent DNS queries to DOMAIN reached (max: NUMBER ) Same as above but for a specific domain. ignoring invalid line in lease database: STRING STRING STRING STRING ... An invalid line in the lease file has been skipped. ignoring invalid line in lease database, bad address: ADDRESS Address found in the lease file is neither a valid IPv4 nor a valid IPv6 address. The line is skipped. Ignoring domain CONFIG_DOMAIN for DHCP host name HOSTNAME A DHCP client is not allowed to claim name HOSTNAME in the current DHCP configuration. overflow: NUMBER log entries lost When using asynchronous logging and the disk is too slow, we can loose log lines during busy times. This can be avoided by decreasing the system load or switching to synchronous logging. Note that synchronous logging has the disadvantage of blocking DNS resolution when waiting for the log to be written to disk. failed to create listening socket for ADDRESS : MSG A failure to bind addresses given by listen-address is accepted when dnsmasq is configured with bind-dynamic . failed to create listening socket for port NUMBER : MSG Same as above but for a port rather than an address. LOUD WARNING: listening on ADDRESSS may accept requests via interfaces other than IFNAME When using bind-interfaces , the only access control is the addresses dnsmasq is listening on. There's nothing to avoid a query to the address of an internal interface arriving via an external interface where we don't want to accept queries, except that in the usual case the addresses of internal interfaces are RFC1918. When bind-interfaces in use, and we listen on an address that looks like it's probably globally routeable, this warning is printed. LOUD WARNING: use --bind-dynamic rather than --bind-interfaces to avoid DNS amplification attacks via these interface(s) Advise printed when above's warning is printed. This warning is printed only once. warning: using interface IF_NAME instead When configuring an interface alias (like eth0:0 ), dnsmasq will be listening on the physical (e.g. eth0 ) interface, instead. warning: no addresses found for interface IF_NAME dnsmasq has been configured to listen on an interface that has no address assigned to it. ignoring nameserver ADDRESS - local interface At least one server directive is redundant and point to the dnsmasq instance itself. The server is ignored. ignoring nameserver ADDRESS - cannot make/bind socket: MSG dnsmasq failed to allocate a socket for the mentioned server. The server is ignored. no address range available for DHCP request with subnet selector SUBNET No DHCP context has been configured for this subnet selector. Check your DHCP settings. no address range available for DHCP request via ADDRESS No DHCP context has been configured for this address. Check your DHCP settings. no address range available for DHCP request via IF_NAME No DHCP context has been configured for this interface. Check your DHCP settings. This warning is expected during debug log generation as Pi-hole is trying to request a DHCP lease on all available interfaces. We do this to test that the server replies properly. When an interface does not have a DHCP configuration (such as the loopback interface lo , or other special interfaces such as docker0 ), this warning is printed. You can safely ignore it when it happens only during DHCP testing, e.g., during Pi-hole debug log generation. If it happens often, you can use the option no-dhcp-interface=IF_NAME (insert the interface name here) to specifically disable DHCP on this interface. disabling DHCP static address ADDRESS for HOSTNAME Static DHCP leases are disabled when sending a DHCPDECLINE packet. not using configured address ADDRESS because it is leased to MAC Not handing out configured address because it is already actively used to another device with hardware address MAC . not using configured address ADDRESS because it is in use by the server or relay Handing out addresses used by known critical infrastructure (like the DHCP server or a relay) is prevented to avoid IP address duplication issues. This can happen when you have configured a static address assignment for the IP address of your Pi-hole. As this could result in an IP address conflict, Pi-hole offers a different free address from your configured DHCP pool. As this means Pi-hole behaves differently than you configured it to, it issues a warning. The solution would be to either remove the static reservation for the Pi-hole itself (see ADDRESS in the warning) or simply accept this warning as it should only happen during debug log generation. When this warning appears outside of a running DHCP test, check that your Pi-hole is indeed using a static address. not using configured address ADDRESS because it was previously declined As the warning says. Check your log file for reasons of a prior refusal to hand out this lease. This warning is at most logged once every 10 minutes for a given address. cannot send DHCP/BOOTP option NUMBER : no space left in packet Use less DHCP options as the space for options is limited and cannot be extended (RFC2131). cannot send RFC3925 option: too many options for enterprise number NUMBER A maximum packet length of 250 bytes has to be ensured for dhcp-option = vi-encap:13,17,... configurations. no address range available for DHCPv6 request from relay at ADDRESS No DHCPv6 context has been configured for this address. Check your DHCPv6 settings. no address range available for DHCPv6 request via IF_NAME No DHCPv6 context has been configured for this interface. Check your DHCPv6 settings. If you do not have an upstreams IPv6 connection (use, e.g., test-ipv6.com for testing), Pi-hole does not have any address prefix it could use to build DHCPv6 addresses causing this warning on every DHCPv6 request. The solution will be to disable DHCPv6 in your Pi-hole. disabling DHCP static address ADDRESS for TIME Static DHCPv6 leases are disabled when sending a DHCP(6)DECLINE packet. IPset: error: MSG A non-critical error was encountered when trying to access an IPset device. A human-readable message explains it further. warning: DIOCRADDADDRS: MSG A non-critical error was encountered when trying to add an address to an existing ipset . A human-readable message explains it further. warning: DIOCRDELADDRS: MSG A non-critical error was encountered when trying to remove an address from an existing ipset . A human-readable message explains it further.","title":"Known dnsmasq warnings"},{"location":"pi-hole/ftldns/in-depth/","text":"Available interfaces \u00b6 Pi-hole stats can be accessed via a standard Unix socket ( /run/pihole/FTL.sock ), a telnet-like connection (TCP socket on port 4711 ) as well as indirectly via the Web API ( admin/api.php ), and the command line ( pihole -c -j ). You can out find more details below. Command-line arguments \u00b6 debug - Don't go into daemon mode (stay in foreground) + more verbose logging test - Start FTL and process everything, but shut down immediately afterward version - Don't start FTL , only show the version tag - Don't start FTL , show only git tag branch - Don't start FTL , show only git branch FTL was compiled from no-daemon or -f - Don't go into background (daemon mode) help or -h - Don't start FTL , show help dnsmasq-test - Test resolver config file syntax -- everything behind -- will be passed as options to the internal resolver Command-line arguments can be arbitrarily combined, e.g. pihole-FTL debug test File locations \u00b6 /var/log/pihole-FTL.log log file /run/pihole-FTL.pid PID file /run/pihole-FTL.port file containing port on which FTL is listening /run/pihole/FTL.sock Unix socket Linux capabilities \u00b6 Capabilities (POSIX 1003.1e, capabilities(7) ) provide fine-grained control over superuser permissions, allowing the use of the root user to be avoided. To perform permission checks, traditional UNIX implementations distinguish two categories of processes: privileged processes (superuser or root ), and unprivileged processes . Privileged processes bypass all kernel permission checks, while unprivileged processes are subject to full permission checking based on the process's credentials (user and group permissions and supplementary process capabilities). Capabilities are implemented on Linux using extended attributes ( xattr(7) ) in the security namespace. Extended attributes are supported by all major Linux file systems, including Ext2, Ext3, Ext4, Btrfs, JFS, XFS, and ReiserFS. For your safety and comfort, pihole-FTL is run by the entirely unprivileged user pihole . Whereas dnsmasq is running as root process, we designed pihole-FTL to be run by the entirely unprivileged user pihole . As a consequence, pihole-FTL will not be able to access the files of any other user on this system or mess around with your system's configuration. However, this also implies that FTL DNS cannot bind to ports 53 (DNS) among some other necessary capabilities related to DHCP services. To establish a strong security model, we explicitly grant the pihole-FTL process additional capabilities so that pihole-FTL (but no other processes which may be started by pihole ) can bind to port 53, etc., without giving any additional permissions to the pihole user. We specifically add the following capabilities to pihole-FTL : CAP_NET_BIND_SERVICE : Allows FTL DNS binding to TCP/UDP sockets below 1024 (specifically DNS service on port 53) CAP_NET_RAW : use raw and packet sockets (we need a RAW socket for handling DHCPv6 requests) CAP_NET_ADMIN : modify routing tables and other network-related operations (to allow for handling DHCP requests) Users that cannot use Linux capabilities for various reasons (lacking kernel or file system support) can modify the startup scripts of pihole-FTL to ensure the daemon is started as root . However, be aware that you do so on your own risk (although we don't expect problems to arise).","title":"In depth"},{"location":"pi-hole/ftldns/in-depth/#available-interfaces","text":"Pi-hole stats can be accessed via a standard Unix socket ( /run/pihole/FTL.sock ), a telnet-like connection (TCP socket on port 4711 ) as well as indirectly via the Web API ( admin/api.php ), and the command line ( pihole -c -j ). You can out find more details below.","title":"Available interfaces"},{"location":"pi-hole/ftldns/in-depth/#command-line-arguments","text":"debug - Don't go into daemon mode (stay in foreground) + more verbose logging test - Start FTL and process everything, but shut down immediately afterward version - Don't start FTL , only show the version tag - Don't start FTL , show only git tag branch - Don't start FTL , show only git branch FTL was compiled from no-daemon or -f - Don't go into background (daemon mode) help or -h - Don't start FTL , show help dnsmasq-test - Test resolver config file syntax -- everything behind -- will be passed as options to the internal resolver Command-line arguments can be arbitrarily combined, e.g. pihole-FTL debug test","title":"Command-line arguments"},{"location":"pi-hole/ftldns/in-depth/#file-locations","text":"/var/log/pihole-FTL.log log file /run/pihole-FTL.pid PID file /run/pihole-FTL.port file containing port on which FTL is listening /run/pihole/FTL.sock Unix socket","title":"File locations"},{"location":"pi-hole/ftldns/in-depth/#linux-capabilities","text":"Capabilities (POSIX 1003.1e, capabilities(7) ) provide fine-grained control over superuser permissions, allowing the use of the root user to be avoided. To perform permission checks, traditional UNIX implementations distinguish two categories of processes: privileged processes (superuser or root ), and unprivileged processes . Privileged processes bypass all kernel permission checks, while unprivileged processes are subject to full permission checking based on the process's credentials (user and group permissions and supplementary process capabilities). Capabilities are implemented on Linux using extended attributes ( xattr(7) ) in the security namespace. Extended attributes are supported by all major Linux file systems, including Ext2, Ext3, Ext4, Btrfs, JFS, XFS, and ReiserFS. For your safety and comfort, pihole-FTL is run by the entirely unprivileged user pihole . Whereas dnsmasq is running as root process, we designed pihole-FTL to be run by the entirely unprivileged user pihole . As a consequence, pihole-FTL will not be able to access the files of any other user on this system or mess around with your system's configuration. However, this also implies that FTL DNS cannot bind to ports 53 (DNS) among some other necessary capabilities related to DHCP services. To establish a strong security model, we explicitly grant the pihole-FTL process additional capabilities so that pihole-FTL (but no other processes which may be started by pihole ) can bind to port 53, etc., without giving any additional permissions to the pihole user. We specifically add the following capabilities to pihole-FTL : CAP_NET_BIND_SERVICE : Allows FTL DNS binding to TCP/UDP sockets below 1024 (specifically DNS service on port 53) CAP_NET_RAW : use raw and packet sockets (we need a RAW socket for handling DHCPv6 requests) CAP_NET_ADMIN : modify routing tables and other network-related operations (to allow for handling DHCP requests) Users that cannot use Linux capabilities for various reasons (lacking kernel or file system support) can modify the startup scripts of pihole-FTL to ensure the daemon is started as root . However, be aware that you do so on your own risk (although we don't expect problems to arise).","title":"Linux capabilities"},{"location":"pi-hole/ftldns/interfaces/","text":"Interface binding behavior \u00b6 Pi-hole offers three choices for interface on its dashboard: By default, FTL binds the wildcard address. It does this for all options except Bind only on interface enp2s0 . Your Pi-hole then discards requests that it shouldn't reply to. This has the big advantage of working even when interfaces come and go and change address (this happens way more often than one would think). Recommended setting \u00b6 Allow only local requests \u00b6 This setting accepts DNS queries only from hosts whose address is on a local subnet, i.e., a subnet for which an interface exists on the server. It is intended to be set as a default on installation, to allow unconfigured installations to be useful but also safe from being used for DNS amplification attacks if (accidentally) running public. The dnsmasq option local-service is used. Potentially dangerous options \u00b6 Respond only on interface enp2s0 \u00b6 Respond only to queries arriving on the specified interface. The loopback ( lo ) interface is automatically added to the list of interfaces to use when this option is used. The dnsmasq option interface=enp2s0 is used (the interface may be different). Bind only on interface enp2s0 \u00b6 As said above, the default is to bind to the wildcard address, discarding requests that we shouldn't reply to. If this is not what you want, you can use this option as it forces FTL to really bind only the interfaces it is listening on. Note that this may result in issues when the interface may go down (cable unplugged, etc.). About the only time when this is useful is when running another nameserver on the same port on the same machine. This may also happen if you run a virtualization API such as libvirt . When this option is used, IP alias interface labels (e.g. enp2s0:0 ) are checked rather than interface names. The dnsmasq options interface=enp2s0 bind-interfaces are used (the interface may be different). Permit all origins \u00b6 This truly allows any traffic to be replied to and is a dangerous thing to do as your Pi-hole could become an open resolver . You should always ask yourself if the first option doesn't work for you as well. The dnsmasq option except-interface=nonexisting is used. We add this option to disable any possible local-service settings in other config files.","title":"Interface binding behavior"},{"location":"pi-hole/ftldns/interfaces/#interface-binding-behavior","text":"Pi-hole offers three choices for interface on its dashboard: By default, FTL binds the wildcard address. It does this for all options except Bind only on interface enp2s0 . Your Pi-hole then discards requests that it shouldn't reply to. This has the big advantage of working even when interfaces come and go and change address (this happens way more often than one would think).","title":"Interface binding behavior"},{"location":"pi-hole/ftldns/interfaces/#recommended-setting","text":"","title":"Recommended setting"},{"location":"pi-hole/ftldns/interfaces/#local","text":"This setting accepts DNS queries only from hosts whose address is on a local subnet, i.e., a subnet for which an interface exists on the server. It is intended to be set as a default on installation, to allow unconfigured installations to be useful but also safe from being used for DNS amplification attacks if (accidentally) running public. The dnsmasq option local-service is used.","title":"Allow only local requests"},{"location":"pi-hole/ftldns/interfaces/#potentially-dangerous-options","text":"","title":"Potentially dangerous options"},{"location":"pi-hole/ftldns/interfaces/#single","text":"Respond only to queries arriving on the specified interface. The loopback ( lo ) interface is automatically added to the list of interfaces to use when this option is used. The dnsmasq option interface=enp2s0 is used (the interface may be different).","title":"Respond only on interface enp2s0"},{"location":"pi-hole/ftldns/interfaces/#bind","text":"As said above, the default is to bind to the wildcard address, discarding requests that we shouldn't reply to. If this is not what you want, you can use this option as it forces FTL to really bind only the interfaces it is listening on. Note that this may result in issues when the interface may go down (cable unplugged, etc.). About the only time when this is useful is when running another nameserver on the same port on the same machine. This may also happen if you run a virtualization API such as libvirt . When this option is used, IP alias interface labels (e.g. enp2s0:0 ) are checked rather than interface names. The dnsmasq options interface=enp2s0 bind-interfaces are used (the interface may be different).","title":"Bind only on interface enp2s0"},{"location":"pi-hole/ftldns/interfaces/#all","text":"This truly allows any traffic to be replied to and is a dangerous thing to do as your Pi-hole could become an open resolver . You should always ask yourself if the first option doesn't work for you as well. The dnsmasq option except-interface=nonexisting is used. We add this option to disable any possible local-service settings in other config files.","title":"Permit all origins"},{"location":"pi-hole/ftldns/package_dump/","text":"Pi-hole FTL's internal pcap packet dump \u00b6 Pi-hole has its own embedded package dumping. It can be enabled by adding the following to a file like /etc/dnsmasq.d/99-record.conf : dumpfile=/etc/pihole/dump.pcap (or any other location you prefer), in addition to dumpmask=<mask> where mask specifies which types of packets should be added to the dumpfile defined above. The argument should be the OR of the bitmasks for each type of packet to be dumped: it can be specified in hex by preceding the number with 0x in the normal way. Each time a packet is written to the dumpfile, we log the packet sequence and the mask representing its type. The current types are: 0x0001 - DNS queries from clients 0x0002 - DNS replies to clients 0x0004 - DNS queries to upstream 0x0008 - DNS replies from upstream 0x0010 - queries send upstream for DNSSEC validation 0x0020 - replies to queries for DNSSEC validation 0x0040 - replies to client queries which fail DNSSEC validation 0x0080 - replies to queries for DNSSEC validation which fail validation. If you just want to record everything and later filter this in Wireshark you can just add the two lines dumpfile=/etc/pihole/dump.pcap dumpmask=0x00ff","title":"Package dump"},{"location":"pi-hole/ftldns/package_dump/#pi-hole-ftls-internal-pcap-packet-dump","text":"Pi-hole has its own embedded package dumping. It can be enabled by adding the following to a file like /etc/dnsmasq.d/99-record.conf : dumpfile=/etc/pihole/dump.pcap (or any other location you prefer), in addition to dumpmask=<mask> where mask specifies which types of packets should be added to the dumpfile defined above. The argument should be the OR of the bitmasks for each type of packet to be dumped: it can be specified in hex by preceding the number with 0x in the normal way. Each time a packet is written to the dumpfile, we log the packet sequence and the mask representing its type. The current types are: 0x0001 - DNS queries from clients 0x0002 - DNS replies to clients 0x0004 - DNS queries to upstream 0x0008 - DNS replies from upstream 0x0010 - queries send upstream for DNSSEC validation 0x0020 - replies to queries for DNSSEC validation 0x0040 - replies to client queries which fail DNSSEC validation 0x0080 - replies to queries for DNSSEC validation which fail validation. If you just want to record everything and later filter this in Wireshark you can just add the two lines dumpfile=/etc/pihole/dump.pcap dumpmask=0x00ff","title":"Pi-hole FTL's internal pcap packet dump"},{"location":"pi-hole/ftldns/privacylevels/","text":"Using privacy levels you can specify which level of detail you want to see in your Pi-hole statistics. The privacy level may be changed at any time without having to restart the DNS resolver. Note that queries with (partially) hidden details cannot be disclosed with a subsequent reduction of the privacy level. They can be changed either from the Settings page on the dashboard or in FTL's config file . The available options are Level 0 - show everything \u00b6 Doesn't hide anything, all statistics are available Level 1 - hide domains \u00b6 Show and store all domains as hidden This setting disables Top Domains Top Ads Level 2 - hide domains and clients \u00b6 Show and store all domains as hidden and clients as 0.0.0.0 This setting disables Top Domains Top Ads Top Clients Clients over time Level 3 - anonymous mode (anonymize everything) \u00b6 Disable all details except the most anonymous statistics This setting disables Top Domains Top Ads Top Clients Clients over time Query Log Long-term database logging","title":"Privacylevels"},{"location":"pi-hole/ftldns/privacylevels/#level-0-show-everything","text":"Doesn't hide anything, all statistics are available","title":"Level 0 - show everything"},{"location":"pi-hole/ftldns/privacylevels/#level-1-hide-domains","text":"Show and store all domains as hidden This setting disables Top Domains Top Ads","title":"Level 1 - hide domains"},{"location":"pi-hole/ftldns/privacylevels/#level-2-hide-domains-and-clients","text":"Show and store all domains as hidden and clients as 0.0.0.0 This setting disables Top Domains Top Ads Top Clients Clients over time","title":"Level 2 - hide domains and clients"},{"location":"pi-hole/ftldns/privacylevels/#level-3-anonymous-mode-anonymize-everything","text":"Disable all details except the most anonymous statistics This setting disables Top Domains Top Ads Top Clients Clients over time Query Log Long-term database logging","title":"Level 3 - anonymous mode (anonymize everything)"},{"location":"pi-hole/ftldns/signals/","text":"You can influence FTL by sending signals to the process. There are various signals supported to trigger specific actions, described below. Reload everything using SIGHUP \u00b6 When FTL receives a SIGHUP , it clears the entire DNS cache, and then Re-loads /etc/hosts , /etc/ethers , and any file given by dhcp-hostsfile , dhcp-optsfile , dhcp-hostsdir (files in dhcp-hostsdir are also re-read on change, without the need to send a signal), dhcp-optsdir (files in dhcp-optsdir are also re-read on change, without the need to send a signal), addn-hosts , or hostsdir . The DHCP lease change script is called for all existing DHCP leases. If no-poll is set, FTL also re-reads /etc/resolv.conf . The config file specified by servers-file is re-read. Note: No other dnsmasq config files are re-read. The FTL database connection ( /etc/pihole/pihole-FTL.db ) is re-opened. The privacy level is re-read from pihole-FTL.conf ( PRIVACY_LEVEL ). The blocking status is re-read from setupVars.conf ( BLOCKING_ENABLED ). The debug settings are re-read from pihole-FTL.conf ( DEBUG_* ). The gravity database connection ( /etc/pihole/gravity.db ) is re-opened. The number of blocked domains is updated. All regular expression (RegEx) filters in gravity.db are re-read and pre-compiled for fast execution later on. The blocking cache (storing if a domain has already been analyzed and what the result was) is cleared. If DEBUG_CAPS is enabled, the current set of available capabilities is logged. Real-time (RT) signals \u00b6 While SIGHUP updates/flushes almost everything, such a massive operation is often not necessary. Hence, we added several small real-time signals available for fine-grained control of what FTL does. When you see SIGHUP as a \"big gun\", the real-time signals are rather the \"scalpel\" to serve rather specific needs. Real-time signals are not guaranteed to have the same number on all operating systems. FTL will adapt accordingly. For the signals described below, we will always specify them with the real-time signal ID and the typical signal number in parentheses. Real-time signal can always be executed relative to the first (= minimum) real-time signal just like (for real-time signal 0): sudo pkill -SIGRTMIN+0 pihole-FTL Real-time signal 0 (SIG34) \u00b6 This signal does: The gravity database connection ( /etc/pihole/gravity.db ) is re-opened. The number of blocked domains is updated. All regular expression (RegEx) filters in gravity.db are re-read and pre-compiled for fast execution later on. The blocking cache (storing if a domain has already been analyzed and what the result was) is cleared. The privacy level is re-read from pihole-FTL.conf ( PRIVACY_LEVEL ). The most important difference to SIGHUP is that the DNS cache itself is not flushed. Merely the blocking cache (storing if a domain has already been analyzed and what the result was) is cleared. This is the preferred signal to be used after manipulating the gravity.db database manually as it reloads only what is needed in this case. Real-time signal 1 (SIG35) \u00b6 Reserved - Currently ignored Real-time signal 2 (SIG36) \u00b6 Reserved - Used for internal signaling that a fork or thread crashed and needs to inform the main process to shut down, storing the last (valid) queries still into the long-term database. Real-time signal 3 (SIG37) \u00b6 Reimport alias-clients from the database and recompute affected client statistics. Real-time signal 4 (SIG38) \u00b6 Re-resolve all clients and forward destination hostnames. This forces refreshing hostnames as in that the usual \"resolve only recently active clients\" condition is ignored. The re-resolution adheres to the specified REFRESH_HOSTNAMES config option meaning that this option may not try to resolve all hostnames. Real-time signal 5 (SIG39) \u00b6 Re-parse ARP/neighbour-cache now to update the Network table now","title":"Signals"},{"location":"pi-hole/ftldns/signals/#reload-everything-using-sighup","text":"When FTL receives a SIGHUP , it clears the entire DNS cache, and then Re-loads /etc/hosts , /etc/ethers , and any file given by dhcp-hostsfile , dhcp-optsfile , dhcp-hostsdir (files in dhcp-hostsdir are also re-read on change, without the need to send a signal), dhcp-optsdir (files in dhcp-optsdir are also re-read on change, without the need to send a signal), addn-hosts , or hostsdir . The DHCP lease change script is called for all existing DHCP leases. If no-poll is set, FTL also re-reads /etc/resolv.conf . The config file specified by servers-file is re-read. Note: No other dnsmasq config files are re-read. The FTL database connection ( /etc/pihole/pihole-FTL.db ) is re-opened. The privacy level is re-read from pihole-FTL.conf ( PRIVACY_LEVEL ). The blocking status is re-read from setupVars.conf ( BLOCKING_ENABLED ). The debug settings are re-read from pihole-FTL.conf ( DEBUG_* ). The gravity database connection ( /etc/pihole/gravity.db ) is re-opened. The number of blocked domains is updated. All regular expression (RegEx) filters in gravity.db are re-read and pre-compiled for fast execution later on. The blocking cache (storing if a domain has already been analyzed and what the result was) is cleared. If DEBUG_CAPS is enabled, the current set of available capabilities is logged.","title":"Reload everything using SIGHUP"},{"location":"pi-hole/ftldns/signals/#real-time-rt-signals","text":"While SIGHUP updates/flushes almost everything, such a massive operation is often not necessary. Hence, we added several small real-time signals available for fine-grained control of what FTL does. When you see SIGHUP as a \"big gun\", the real-time signals are rather the \"scalpel\" to serve rather specific needs. Real-time signals are not guaranteed to have the same number on all operating systems. FTL will adapt accordingly. For the signals described below, we will always specify them with the real-time signal ID and the typical signal number in parentheses. Real-time signal can always be executed relative to the first (= minimum) real-time signal just like (for real-time signal 0): sudo pkill -SIGRTMIN+0 pihole-FTL","title":"Real-time (RT) signals"},{"location":"pi-hole/ftldns/signals/#real-time-signal-0-sig34","text":"This signal does: The gravity database connection ( /etc/pihole/gravity.db ) is re-opened. The number of blocked domains is updated. All regular expression (RegEx) filters in gravity.db are re-read and pre-compiled for fast execution later on. The blocking cache (storing if a domain has already been analyzed and what the result was) is cleared. The privacy level is re-read from pihole-FTL.conf ( PRIVACY_LEVEL ). The most important difference to SIGHUP is that the DNS cache itself is not flushed. Merely the blocking cache (storing if a domain has already been analyzed and what the result was) is cleared. This is the preferred signal to be used after manipulating the gravity.db database manually as it reloads only what is needed in this case.","title":"Real-time signal 0 (SIG34)"},{"location":"pi-hole/ftldns/signals/#real-time-signal-1-sig35","text":"Reserved - Currently ignored","title":"Real-time signal 1 (SIG35)"},{"location":"pi-hole/ftldns/signals/#real-time-signal-2-sig36","text":"Reserved - Used for internal signaling that a fork or thread crashed and needs to inform the main process to shut down, storing the last (valid) queries still into the long-term database.","title":"Real-time signal 2 (SIG36)"},{"location":"pi-hole/ftldns/signals/#real-time-signal-3-sig37","text":"Reimport alias-clients from the database and recompute affected client statistics.","title":"Real-time signal 3 (SIG37)"},{"location":"pi-hole/ftldns/signals/#real-time-signal-4-sig38","text":"Re-resolve all clients and forward destination hostnames. This forces refreshing hostnames as in that the usual \"resolve only recently active clients\" condition is ignored. The re-resolution adheres to the specified REFRESH_HOSTNAMES config option meaning that this option may not try to resolve all hostnames.","title":"Real-time signal 4 (SIG38)"},{"location":"pi-hole/ftldns/signals/#real-time-signal-5-sig39","text":"Re-parse ARP/neighbour-cache now to update the Network table now","title":"Real-time signal 5 (SIG39)"},{"location":"pi-hole/ftldns/telnet-api/","text":"Connect via e.g. telnet 127.0.0.1 4711 or use echo \">command\" | nc 127.0.0.1 4711 >quit : Closes the connection to the client >stats : Get current statistics domains_being_blocked 116007 dns_queries_today 30163 ads_blocked_today 5650 ads_percentage_today 18.731558 unique_domains 1056 queries_forwarded 4275 queries_cached 20238 clients_ever_seen 11 unique_clients 9 status enabled >overTime : over time data (10 min intervals) 1525546500 163 0 1525547100 154 1 1525547700 164 0 1525548300 167 0 1525548900 151 0 1525549500 143 0 [...] >top-domains : get top domains 0 8462 x.y.z.de 1 236 safebrowsing-cache.google.com 2 116 pi.hole 3 109 z.y.x.de 4 93 safebrowsing.google.com 5 96 plus.google.com [...] Variant: >top-domains (15) to show (up to) 15 entries >top-ads : get top ad domains 0 8 googleads.g.doubleclick.net 1 6 www.googleadservices.com 2 1 cdn.mxpnl.com 3 1 collector.githubapp.com 4 1 www.googletagmanager.com 5 1 s.zkcdn.net [...] Variant: >top-ads (14) to show (up to) 14 entries top-clients : get recently active top clients (IP addresses + hostnames (if available)) 0 9373 192.168.2.1 router 1 484 192.168.2.2 work-machine 2 8 127.0.0.1 localhost Variant: >top-clients (9) to show (up to) 9 client entries or >top-clients withzero (15) to show (up to) 15 clients even if they have not been active recently (see PR #124 for further details) >forward-dest : get forward destinations (IP addresses + hostnames (if available)) along with the percentage. The first result (ID -2) will always be the percentage of domains answered from blocklists, whereas the second result (ID -1) will be the queries answered from the cache -2 18.70 blocklist blocklist -1 67.10 cache cache 0 14.20 127.0.0.1 localhost Variant: >forward-dest unsorted to show forward destinations in unsorted order (equivalent to using >forward-names ) >querytypes : get collected query types percentage A (IPv4): 53.45 AAAA (IPv6): 45.32 ANY: 0.00 SRV: 0.64 SOA: 0.05 PTR: 0.54 TXT: 0.00 >getallqueries : get all queries that FTL has in memory 1525554586 A fonts.googleapis.com 192.168.2.100 3 0 4 6 1525554586 AAAA fonts.googleapis.com 192.168.2.100 3 0 4 5 1525554586 A www.mkdocs.org 192.168.2.100 3 0 4 7 1525554586 AAAA www.mkdocs.org 192.168.2.100 2 0 3 21 1525554586 A squidfunk.github.io 192.168.2.100 2 0 3 20 1525554586 A pi-hole.net 192.168.2.100 3 0 4 5 1525554586 AAAA squidfunk.github.io 192.168.2.100 3 0 1 6 1525554586 AAAA pi-hole.net 192.168.2.100 2 0 1 18 1525554586 A github.com 192.168.2.100 3 0 4 5 1525554586 AAAA github.com 192.168.2.100 2 0 1 18 Variants: >getallqueries (37) show (up to) 37 latest entries, >getallqueries-time 1483964295 1483964312 gets all queries that FTL has in its database in a limited time interval, >getallqueries-time 1483964295 1483964312 (17) show matches in the (up to) 17 latest entries, >getallqueries-domain www.google.com gets all queries that FTL has in its database for a specific domain name, >getallqueries-client 2.3.4.5 : gets all queries that FTL has in its database for a specific client name or IP >recentBlocked : get most recently pi-holed domain name www.googleadservices.com Variant: >recentBlocked (4) show the four most recent blocked domains >clientID : Get ID of currently connected client 6 >version : Get version information of the currently running FTL instance version v1.6-3-g106498d-dirty tag v1.6 branch master hash 106498d date 2017-03-26 13:10:43 +0200 >dbstats : Get some statistics about FTL 's' long-term storage database (this request may take some time for processing in case of a large database file) queries in database: 2700304 database filesize: 199.20 MB SQLite version: 3.23.1 >domain pi-hole.net : Get detailed information about domain (if available) Domain \"pi-hole.net\", ID: 254 Total: 179 Blocked: 0 Wildcard blocked: false >cacheinfo : Get DNS server cache size and usage information cache-size: 500000 cache-live-freed: 0 cache-inserted: 15529 >dns-port : Get DNS port FTL is listening on 53 >maxlogage : Get timespan of the statistics shown on the dashboard (in seconds) 86400 Note that the port can also be 0 if someone decides to disable the DNS server part of Pi-hole","title":"Telnet api"},{"location":"pi-hole/ftldns/valgrind/","text":"Debugging FTLDNS using valgrind \u00b6 Occasionally, debugging may require us to run pihole-FTL in valgrind . We also use it to measure performance and check that our memory layout is optimal (= minimal footprint). Valgrind is a flexible program for debugging and profiling Linux executables. It consists of a core, which provides a synthetic CPU in software, and a series of debugging and profiling tools. memcheck \u00b6 The arguably most often used tool in valgrind is memcheck . Note: When running FTL in Memcheck, it runs about 10-30x slower than normal. Especially the initial import of queries from the database is largely slowed down as SQLite3 frequently allocates and releases heap memory. Memcheck is a memory error detector. It can detect the following problems that are common in C and C++ programs. Accessing memory you shouldn't, e.g. overrunning and underrunning heap blocks, overrunning the top of the stack, and accessing memory after it has been freed. Using undefined values, i.e. values that have not been initialised, or that have been derived from other undefined values. Incorrect freeing of heap memory, such as double-freeing heap blocks, or mismatched use of malloc / new / new[] versus free / delete / delete[] Overlapping src and dst pointers in memcpy and related functions. Passing a fishy (presumably negative) value to the size parameter of a memory allocation function. Memory leaks. Problems like these can be difficult to find by other means, often remaining undetected for long periods, then causing occasional, difficult-to-diagnose crashes. Make sure to terminate any existing FTL process before starting FTL inside valgrind . Preparations \u00b6 You have to stop the regular pihole-FTL process before starting a valgrind debugging session: sudo service pihole-FTL stop Furthermore, you'll have to strip the networking capabilities from the binary using: sudo setcap -r /usr/bin/pihole-FTL They'll automatically be re-added when using sudo service pihole-FTL start next time. Command \u00b6 We suggest the following one-liner to run pihole-FTL in memcheck : sudo rm /dev/shm/FTL-*; sudo valgrind --trace-children=yes --leak-check=full --track-origins=yes -s /usr/bin/pihole-FTL &> valgrind.log If you compile FTL from source, use sudo rm /dev/shm/FTL-*; ./build.sh && sudo valgrind --trace-children=yes --leak-check=full --track-origins=yes -s ./pihole-FTL &> valgrind.log The used options are: trace-children=yes - Valgrind will trace into sub-processes initiated via the exec system call. This is necessary for multi-process programs. We use this to go down into possibly user scripts on DHCP activity, etc. leak-check=full - When enabled, search for memory leaks when the client program finishes. Each individual leak will be shown in detail and/or counted as an error. track-origins=yes - Memcheck tracks the origin of uninitialised values. By default, it does not, which means that although it can tell you that an uninitialised value is being used in a dangerous way, it cannot tell you where the uninitialised value came from. This often makes it difficult to track down the root problem. When set to yes , Memcheck keeps track of the origins of all uninitialised values. Then, when an uninitialised value error is reported, Memcheck will try to show the origin of the value. False-positive memory issues \u00b6 You may see lines like: main_dnsmasq : Syscall param sendmsg(msg.msg_control) points to uninitialised byte(s) ==2681669== Syscall param sendmsg(msg.msg_control) points to uninitialised byte(s) ==2681669== at 0x49C112D: __libc_sendmsg (sendmsg.c:28) ==2681669== by 0x49C112D: sendmsg (sendmsg.c:25) ==2681669== by 0x188C5B: send_from (forward.c:97) ==2681669== by 0x18C7C1: reply_query (forward.c:1347) ==2681669== by 0x17C45B: check_dns_listeners (dnsmasq.c:1770) ==2681669== by 0x17E759: main_dnsmasq (dnsmasq.c:1209) ==2681669== by 0x146649: main (main.c:96) ==2681669== Address 0x1fff000088 is on thread 1's stack ==2681669== in frame #1, created by send_from (forward.c:34) ==2681669== Uninitialised value was created by a stack allocation ==2681669== at 0x188B7D: send_from (forward.c:34) ==2681669== Syscall param sendmsg(msg.msg_control) points to uninitialised byte(s) ==2681669== at 0x49C112D: __libc_sendmsg (sendmsg.c:28) ==2681669== by 0x49C112D: sendmsg (sendmsg.c:25) ==2681669== by 0x188C5B: send_from (forward.c:97) ==2681669== by 0x18BCFB: receive_query (forward.c:1726) ==2681669== by 0x17C3DA: check_dns_listeners (dnsmasq.c:1797) ==2681669== by 0x17E759: main_dnsmasq (dnsmasq.c:1209) ==2681669== by 0x146649: main (main.c:96) ==2681669== Address 0x1ffeffff88 is on thread 1's stack ==2681669== in frame #1, created by send_from (forward.c:34) ==2681669== Uninitialised value was created by a stack allocation ==2681669== at 0x188B7D: send_from (forward.c:34) main_dnsmasq : Syscall param write(buf) points to uninitialised byte(s) ==2681688== Syscall param write(buf) points to uninitialised byte(s) ==2681688== at 0x49C02CF: __libc_write (write.c:26) ==2681688== by 0x49C02CF: write (write.c:24) ==2681688== by 0x1C10D4: read_write (util.c:698) ==2681688== by 0x17080B: cache_end_insert.part.0 (cache.c:688) ==2681688== by 0x1AA7B1: extract_addresses (rfc1035.c:894) ==2681688== by 0x187CA0: process_reply (forward.c:786) ==2681688== by 0x189C63: tcp_request (forward.c:2321) ==2681688== by 0x17C6B3: check_dns_listeners (dnsmasq.c:1978) ==2681688== by 0x17E759: main_dnsmasq (dnsmasq.c:1209) ==2681688== by 0x146649: main (main.c:96) ==2681688== Address 0x4d013dc is 140 bytes inside a block of size 1,120,000 alloc'd ==2681688== at 0x483DD99: calloc (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so) ==2681688== by 0x1C0324: safe_malloc (util.c:282) ==2681688== by 0x1716F7: cache_init (cache.c:111) ==2681688== by 0x17E089: main_dnsmasq (dnsmasq.c:396) ==2681688== by 0x146649: main (main.c:96) ==2681688== Uninitialised value was created by a stack allocation ==2681688== at 0x1AA4F0: extract_addresses (rfc1035.c:537) These are known false-positives as use of -O2 and above is not recommended with Memcheck ( pihole-FTL is typically compiled with -O3 ). It occasionally reports uninitialised-value errors which don't really exist. Known memory leaks \u00b6 Usually the GNU C library ( libc.so ) doesn't bother to free that memory when the program ends - there would be no point, since the Linux kernel reclaims all process resources when a process exits anyway, so it would just slow things down. The glibc authors realised that this behaviour causes leak checkers, such as Valgrind, to falsely report leaks in glibc, when a leak check is done at exit. In order to avoid this, they provided a routine called __libc_freeres specifically to make glibc release all memory it has allocated. This, however, does not cover the memory allocated by res_init() for gethostbyaddr() . gethostbyaddr : 28 bytes in 1 blocks are definitely lost ==2681688== 28 bytes in 1 blocks are definitely lost in loss record 49 of 200 ==2681688== at 0x483B7F3: malloc (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so) ==2681688== by 0x84B840E: ??? ==2681688== by 0x84B5C43: ??? ==2681688== by 0x84A9904: ??? ==2681688== by 0x84A9C26: ??? ==2681688== by 0x4B022ED: gethostbyaddr_r@@GLIBC_2.2.5 (getXXbyYY_r.c:315) ==2681688== by 0x4B02008: gethostbyaddr (getXXbyYY.c:135) ==2681688== by 0x155BC6: resolveHostname.part.0 (resolve.c:216) ==2681688== by 0x155FF4: resolveHostname (resolve.c:134) ==2681688== by 0x155FF4: resolveAndAddHostname (resolve.c:319) ==2681688== by 0x156F42: resolveUpstreams (resolve.c:553) ==2681688== by 0x156F42: DNSclient_thread (resolve.c:608) ==2681688== by 0x49B5608: start_thread (pthread_create.c:477) ==2681688== by 0x4AF1292: clone (clone.S:95) ==2681688== 96 bytes in 1 blocks are definitely lost in loss record 100 of 200 ==2681688== at 0x483B7F3: malloc (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so) ==2681688== by 0x4A710D4: __libc_alloc_buffer_allocate (alloc_buffer_allocate.c:26) ==2681688== by 0x4B145A8: alloc_buffer_allocate (alloc_buffer.h:143) ==2681688== by 0x4B145A8: __resolv_conf_allocate (resolv_conf.c:411) ==2681688== by 0x4B11EB1: __resolv_conf_load (res_init.c:592) ==2681688== by 0x4B141B2: __resolv_conf_get_current (resolv_conf.c:163) ==2681688== by 0x4B12464: __res_vinit (res_init.c:614) ==2681688== by 0x155DCC: resolveHostname.part.0 (resolve.c:180) ==2681688== by 0x155FF4: resolveHostname (resolve.c:134) ==2681688== by 0x155FF4: resolveAndAddHostname (resolve.c:319) ==2681688== by 0x156BFA: resolveClients (resolve.c:462) ==2681688== by 0x156BFA: DNSclient_thread (resolve.c:605) ==2681688== by 0x49B5608: start_thread (pthread_create.c:477) ==2681688== by 0x4AF1292: clone (clone.S:95) This, and similar, loss record can safely be ignored. For performance reasons, we keep a few prepared SQL statement always ready for execution in the main thread. However, this has the disadvantage that forks will inherit them. As it is not safe to use a database connection across forks, we discard the open connection and open a new one. This will inevitably lead to a memory loss, however, the SQLite3 engine is not able to handle this any better. As forking relies on copy-on-write , this does not actually lead to a memory wasting as the resource will be shared between the fork and the original process. Furthermore, TCP workers are typically rare and short-lived so this leak isn't anything we are too worried about. gravityDB_open : (some) bytes in 1 blocks are definitely lost ==2681688== 40 (32 direct, 8 indirect) bytes in 1 blocks are definitely lost in loss record 75 of 200 ==2681688== at 0x483DD99: calloc (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so) ==2681688== by 0x15AE74: new_sqlite3_stmt_vec (vector.c:22) ==2681688== by 0x16241E: gravityDB_open (gravity-db.c:184) ==2681688== by 0x16241E: gravityDB_open (gravity-db.c:100) ==2681688== by 0x14AE3C: FTL_reload_all_domainlists (datastructure.c:463) ==2681688== by 0x161D84: DB_thread (database-thread.c:86) ==2681688== by 0x49B5608: start_thread (pthread_create.c:477) ==2681688== by 0x4AF1292: clone (clone.S:95) ==2681688== ==2681688== 40 (32 direct, 8 indirect) bytes in 1 blocks are definitely lost in loss record 76 of 200 ==2681688== at 0x483DD99: calloc (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so) ==2681688== by 0x15AE74: new_sqlite3_stmt_vec (vector.c:22) ==2681688== by 0x16245E: gravityDB_open (gravity-db.c:186) ==2681688== by 0x16245E: gravityDB_open (gravity-db.c:100) ==2681688== by 0x14AE3C: FTL_reload_all_domainlists (datastructure.c:463) ==2681688== by 0x161D84: DB_thread (database-thread.c:86) ==2681688== by 0x49B5608: start_thread (pthread_create.c:477) ==2681688== by 0x4AF1292: clone (clone.S:95) ==2681688== ==2681688== 40 (32 direct, 8 indirect) bytes in 1 blocks are definitely lost in loss record 77 of 200 ==2681688== at 0x483DD99: calloc (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so) ==2681688== by 0x15AE74: new_sqlite3_stmt_vec (vector.c:22) ==2681688== by 0x16243E: gravityDB_open (gravity-db.c:188) ==2681688== by 0x16243E: gravityDB_open (gravity-db.c:100) ==2681688== by 0x14AE3C: FTL_reload_all_domainlist (datastructure.c:463) ==2681688== by 0x161D84: DB_thread (database-thread.c:86) ==2681688== by 0x49B5608: start_thread (pthread_create.c:477) ==2681688== by 0x4AF1292: clone (clone.S:95) ==2681688== 188,505 (704 direct, 187,801 indirect) bytes in 1 blocks are definitely lost in loss record 199 of 200 ==2681688== at 0x483B7F3: malloc (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so) ==2681688== by 0x2196BA: sqlite3MemMalloc (sqlite3.c:23771) ==2681688== by 0x28E77A: sqlite3Malloc (sqlite3.c:27686) ==2681688== by 0x28E77A: sqlite3MallocZero (sqlite3.c:27925) ==2681688== by 0x28E77A: openDatabase (sqlite3.c:164957) ==2681688== by 0x162149: gravityDB_open (gravity-db.c:119) ==2681688== by 0x162149: gravityDB_open (gravity-db.c:100) ==2681688== by 0x14AE3C: FTL_reload_all_domainlists (datastructure.c:463) ==2681688== by 0x161D84: DB_thread (database-thread.c:86) ==2681688== by 0x49B5608: start_thread (pthread_create.c:477) ==2681688== by 0x4AF1292: clone (clone.S:95)","title":"Debugging FTLDNS using `valgrind`"},{"location":"pi-hole/ftldns/valgrind/#debugging-ftldns-using-valgrind","text":"Occasionally, debugging may require us to run pihole-FTL in valgrind . We also use it to measure performance and check that our memory layout is optimal (= minimal footprint). Valgrind is a flexible program for debugging and profiling Linux executables. It consists of a core, which provides a synthetic CPU in software, and a series of debugging and profiling tools.","title":"Debugging FTLDNS using valgrind"},{"location":"pi-hole/ftldns/valgrind/#memcheck","text":"The arguably most often used tool in valgrind is memcheck . Note: When running FTL in Memcheck, it runs about 10-30x slower than normal. Especially the initial import of queries from the database is largely slowed down as SQLite3 frequently allocates and releases heap memory. Memcheck is a memory error detector. It can detect the following problems that are common in C and C++ programs. Accessing memory you shouldn't, e.g. overrunning and underrunning heap blocks, overrunning the top of the stack, and accessing memory after it has been freed. Using undefined values, i.e. values that have not been initialised, or that have been derived from other undefined values. Incorrect freeing of heap memory, such as double-freeing heap blocks, or mismatched use of malloc / new / new[] versus free / delete / delete[] Overlapping src and dst pointers in memcpy and related functions. Passing a fishy (presumably negative) value to the size parameter of a memory allocation function. Memory leaks. Problems like these can be difficult to find by other means, often remaining undetected for long periods, then causing occasional, difficult-to-diagnose crashes. Make sure to terminate any existing FTL process before starting FTL inside valgrind .","title":"memcheck"},{"location":"pi-hole/ftldns/valgrind/#preparations","text":"You have to stop the regular pihole-FTL process before starting a valgrind debugging session: sudo service pihole-FTL stop Furthermore, you'll have to strip the networking capabilities from the binary using: sudo setcap -r /usr/bin/pihole-FTL They'll automatically be re-added when using sudo service pihole-FTL start next time.","title":"Preparations"},{"location":"pi-hole/ftldns/valgrind/#command","text":"We suggest the following one-liner to run pihole-FTL in memcheck : sudo rm /dev/shm/FTL-*; sudo valgrind --trace-children=yes --leak-check=full --track-origins=yes -s /usr/bin/pihole-FTL &> valgrind.log If you compile FTL from source, use sudo rm /dev/shm/FTL-*; ./build.sh && sudo valgrind --trace-children=yes --leak-check=full --track-origins=yes -s ./pihole-FTL &> valgrind.log The used options are: trace-children=yes - Valgrind will trace into sub-processes initiated via the exec system call. This is necessary for multi-process programs. We use this to go down into possibly user scripts on DHCP activity, etc. leak-check=full - When enabled, search for memory leaks when the client program finishes. Each individual leak will be shown in detail and/or counted as an error. track-origins=yes - Memcheck tracks the origin of uninitialised values. By default, it does not, which means that although it can tell you that an uninitialised value is being used in a dangerous way, it cannot tell you where the uninitialised value came from. This often makes it difficult to track down the root problem. When set to yes , Memcheck keeps track of the origins of all uninitialised values. Then, when an uninitialised value error is reported, Memcheck will try to show the origin of the value.","title":"Command"},{"location":"pi-hole/ftldns/valgrind/#false-positive-memory-issues","text":"You may see lines like: main_dnsmasq : Syscall param sendmsg(msg.msg_control) points to uninitialised byte(s) ==2681669== Syscall param sendmsg(msg.msg_control) points to uninitialised byte(s) ==2681669== at 0x49C112D: __libc_sendmsg (sendmsg.c:28) ==2681669== by 0x49C112D: sendmsg (sendmsg.c:25) ==2681669== by 0x188C5B: send_from (forward.c:97) ==2681669== by 0x18C7C1: reply_query (forward.c:1347) ==2681669== by 0x17C45B: check_dns_listeners (dnsmasq.c:1770) ==2681669== by 0x17E759: main_dnsmasq (dnsmasq.c:1209) ==2681669== by 0x146649: main (main.c:96) ==2681669== Address 0x1fff000088 is on thread 1's stack ==2681669== in frame #1, created by send_from (forward.c:34) ==2681669== Uninitialised value was created by a stack allocation ==2681669== at 0x188B7D: send_from (forward.c:34) ==2681669== Syscall param sendmsg(msg.msg_control) points to uninitialised byte(s) ==2681669== at 0x49C112D: __libc_sendmsg (sendmsg.c:28) ==2681669== by 0x49C112D: sendmsg (sendmsg.c:25) ==2681669== by 0x188C5B: send_from (forward.c:97) ==2681669== by 0x18BCFB: receive_query (forward.c:1726) ==2681669== by 0x17C3DA: check_dns_listeners (dnsmasq.c:1797) ==2681669== by 0x17E759: main_dnsmasq (dnsmasq.c:1209) ==2681669== by 0x146649: main (main.c:96) ==2681669== Address 0x1ffeffff88 is on thread 1's stack ==2681669== in frame #1, created by send_from (forward.c:34) ==2681669== Uninitialised value was created by a stack allocation ==2681669== at 0x188B7D: send_from (forward.c:34) main_dnsmasq : Syscall param write(buf) points to uninitialised byte(s) ==2681688== Syscall param write(buf) points to uninitialised byte(s) ==2681688== at 0x49C02CF: __libc_write (write.c:26) ==2681688== by 0x49C02CF: write (write.c:24) ==2681688== by 0x1C10D4: read_write (util.c:698) ==2681688== by 0x17080B: cache_end_insert.part.0 (cache.c:688) ==2681688== by 0x1AA7B1: extract_addresses (rfc1035.c:894) ==2681688== by 0x187CA0: process_reply (forward.c:786) ==2681688== by 0x189C63: tcp_request (forward.c:2321) ==2681688== by 0x17C6B3: check_dns_listeners (dnsmasq.c:1978) ==2681688== by 0x17E759: main_dnsmasq (dnsmasq.c:1209) ==2681688== by 0x146649: main (main.c:96) ==2681688== Address 0x4d013dc is 140 bytes inside a block of size 1,120,000 alloc'd ==2681688== at 0x483DD99: calloc (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so) ==2681688== by 0x1C0324: safe_malloc (util.c:282) ==2681688== by 0x1716F7: cache_init (cache.c:111) ==2681688== by 0x17E089: main_dnsmasq (dnsmasq.c:396) ==2681688== by 0x146649: main (main.c:96) ==2681688== Uninitialised value was created by a stack allocation ==2681688== at 0x1AA4F0: extract_addresses (rfc1035.c:537) These are known false-positives as use of -O2 and above is not recommended with Memcheck ( pihole-FTL is typically compiled with -O3 ). It occasionally reports uninitialised-value errors which don't really exist.","title":"False-positive memory issues"},{"location":"pi-hole/ftldns/valgrind/#known-memory-leaks","text":"Usually the GNU C library ( libc.so ) doesn't bother to free that memory when the program ends - there would be no point, since the Linux kernel reclaims all process resources when a process exits anyway, so it would just slow things down. The glibc authors realised that this behaviour causes leak checkers, such as Valgrind, to falsely report leaks in glibc, when a leak check is done at exit. In order to avoid this, they provided a routine called __libc_freeres specifically to make glibc release all memory it has allocated. This, however, does not cover the memory allocated by res_init() for gethostbyaddr() . gethostbyaddr : 28 bytes in 1 blocks are definitely lost ==2681688== 28 bytes in 1 blocks are definitely lost in loss record 49 of 200 ==2681688== at 0x483B7F3: malloc (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so) ==2681688== by 0x84B840E: ??? ==2681688== by 0x84B5C43: ??? ==2681688== by 0x84A9904: ??? ==2681688== by 0x84A9C26: ??? ==2681688== by 0x4B022ED: gethostbyaddr_r@@GLIBC_2.2.5 (getXXbyYY_r.c:315) ==2681688== by 0x4B02008: gethostbyaddr (getXXbyYY.c:135) ==2681688== by 0x155BC6: resolveHostname.part.0 (resolve.c:216) ==2681688== by 0x155FF4: resolveHostname (resolve.c:134) ==2681688== by 0x155FF4: resolveAndAddHostname (resolve.c:319) ==2681688== by 0x156F42: resolveUpstreams (resolve.c:553) ==2681688== by 0x156F42: DNSclient_thread (resolve.c:608) ==2681688== by 0x49B5608: start_thread (pthread_create.c:477) ==2681688== by 0x4AF1292: clone (clone.S:95) ==2681688== 96 bytes in 1 blocks are definitely lost in loss record 100 of 200 ==2681688== at 0x483B7F3: malloc (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so) ==2681688== by 0x4A710D4: __libc_alloc_buffer_allocate (alloc_buffer_allocate.c:26) ==2681688== by 0x4B145A8: alloc_buffer_allocate (alloc_buffer.h:143) ==2681688== by 0x4B145A8: __resolv_conf_allocate (resolv_conf.c:411) ==2681688== by 0x4B11EB1: __resolv_conf_load (res_init.c:592) ==2681688== by 0x4B141B2: __resolv_conf_get_current (resolv_conf.c:163) ==2681688== by 0x4B12464: __res_vinit (res_init.c:614) ==2681688== by 0x155DCC: resolveHostname.part.0 (resolve.c:180) ==2681688== by 0x155FF4: resolveHostname (resolve.c:134) ==2681688== by 0x155FF4: resolveAndAddHostname (resolve.c:319) ==2681688== by 0x156BFA: resolveClients (resolve.c:462) ==2681688== by 0x156BFA: DNSclient_thread (resolve.c:605) ==2681688== by 0x49B5608: start_thread (pthread_create.c:477) ==2681688== by 0x4AF1292: clone (clone.S:95) This, and similar, loss record can safely be ignored. For performance reasons, we keep a few prepared SQL statement always ready for execution in the main thread. However, this has the disadvantage that forks will inherit them. As it is not safe to use a database connection across forks, we discard the open connection and open a new one. This will inevitably lead to a memory loss, however, the SQLite3 engine is not able to handle this any better. As forking relies on copy-on-write , this does not actually lead to a memory wasting as the resource will be shared between the fork and the original process. Furthermore, TCP workers are typically rare and short-lived so this leak isn't anything we are too worried about. gravityDB_open : (some) bytes in 1 blocks are definitely lost ==2681688== 40 (32 direct, 8 indirect) bytes in 1 blocks are definitely lost in loss record 75 of 200 ==2681688== at 0x483DD99: calloc (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so) ==2681688== by 0x15AE74: new_sqlite3_stmt_vec (vector.c:22) ==2681688== by 0x16241E: gravityDB_open (gravity-db.c:184) ==2681688== by 0x16241E: gravityDB_open (gravity-db.c:100) ==2681688== by 0x14AE3C: FTL_reload_all_domainlists (datastructure.c:463) ==2681688== by 0x161D84: DB_thread (database-thread.c:86) ==2681688== by 0x49B5608: start_thread (pthread_create.c:477) ==2681688== by 0x4AF1292: clone (clone.S:95) ==2681688== ==2681688== 40 (32 direct, 8 indirect) bytes in 1 blocks are definitely lost in loss record 76 of 200 ==2681688== at 0x483DD99: calloc (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so) ==2681688== by 0x15AE74: new_sqlite3_stmt_vec (vector.c:22) ==2681688== by 0x16245E: gravityDB_open (gravity-db.c:186) ==2681688== by 0x16245E: gravityDB_open (gravity-db.c:100) ==2681688== by 0x14AE3C: FTL_reload_all_domainlists (datastructure.c:463) ==2681688== by 0x161D84: DB_thread (database-thread.c:86) ==2681688== by 0x49B5608: start_thread (pthread_create.c:477) ==2681688== by 0x4AF1292: clone (clone.S:95) ==2681688== ==2681688== 40 (32 direct, 8 indirect) bytes in 1 blocks are definitely lost in loss record 77 of 200 ==2681688== at 0x483DD99: calloc (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so) ==2681688== by 0x15AE74: new_sqlite3_stmt_vec (vector.c:22) ==2681688== by 0x16243E: gravityDB_open (gravity-db.c:188) ==2681688== by 0x16243E: gravityDB_open (gravity-db.c:100) ==2681688== by 0x14AE3C: FTL_reload_all_domainlist (datastructure.c:463) ==2681688== by 0x161D84: DB_thread (database-thread.c:86) ==2681688== by 0x49B5608: start_thread (pthread_create.c:477) ==2681688== by 0x4AF1292: clone (clone.S:95) ==2681688== 188,505 (704 direct, 187,801 indirect) bytes in 1 blocks are definitely lost in loss record 199 of 200 ==2681688== at 0x483B7F3: malloc (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so) ==2681688== by 0x2196BA: sqlite3MemMalloc (sqlite3.c:23771) ==2681688== by 0x28E77A: sqlite3Malloc (sqlite3.c:27686) ==2681688== by 0x28E77A: sqlite3MallocZero (sqlite3.c:27925) ==2681688== by 0x28E77A: openDatabase (sqlite3.c:164957) ==2681688== by 0x162149: gravityDB_open (gravity-db.c:119) ==2681688== by 0x162149: gravityDB_open (gravity-db.c:100) ==2681688== by 0x14AE3C: FTL_reload_all_domainlists (datastructure.c:463) ==2681688== by 0x161D84: DB_thread (database-thread.c:86) ==2681688== by 0x49B5608: start_thread (pthread_create.c:477) ==2681688== by 0x4AF1292: clone (clone.S:95)","title":"Known memory leaks"},{"location":"pi-hole/main/basic-install/","text":"One-Step Automated Install \u00b6 Those who want to get started quickly and conveniently may install Pi-hole using the following command: curl -sSL https://install.pi-hole.net | bash Info Piping to bash is a controversial topic , as it prevents you from reading code that is about to run on your system. If you would prefer to review the code before installation, we provide these alternative installation methods. Alternative 1: Clone our repository and run \u00b6 git clone --depth 1 https://github.com/pi-hole/pi-hole.git Pi-hole cd \"Pi-hole/automated install/\" sudo bash basic-install.sh Alternative 2: Manually download the installer and run \u00b6 wget -O basic-install.sh https://install.pi-hole.net sudo bash basic-install.sh Alternative 3: Use Docker to deploy Pi-hole \u00b6 Please refer to the Pi-hole docker repo to use the Official Docker Images.","title":"Basic install"},{"location":"pi-hole/main/basic-install/#one-step-automated-install","text":"Those who want to get started quickly and conveniently may install Pi-hole using the following command: curl -sSL https://install.pi-hole.net | bash Info Piping to bash is a controversial topic , as it prevents you from reading code that is about to run on your system. If you would prefer to review the code before installation, we provide these alternative installation methods.","title":"One-Step Automated Install"},{"location":"pi-hole/main/basic-install/#alternative-1-clone-our-repository-and-run","text":"git clone --depth 1 https://github.com/pi-hole/pi-hole.git Pi-hole cd \"Pi-hole/automated install/\" sudo bash basic-install.sh","title":"Alternative 1: Clone our repository and run"},{"location":"pi-hole/main/basic-install/#alternative-2-manually-download-the-installer-and-run","text":"wget -O basic-install.sh https://install.pi-hole.net sudo bash basic-install.sh","title":"Alternative 2: Manually download the installer and run"},{"location":"pi-hole/main/basic-install/#alternative-3-use-docker-to-deploy-pi-hole","text":"Please refer to the Pi-hole docker repo to use the Official Docker Images.","title":"Alternative 3: Use Docker to deploy Pi-hole"},{"location":"pi-hole/main/contact/","text":"While we are primarily reachable on our Discourse User Forum , we can also be found on a variety of social media outlets. Please be sure to check the FAQ's before starting a new discussion, as we do not have the spare time to reply to every request for assistance. Frequently Asked Questions Feature Requests Reddit Twitter YouTube Facebook","title":"Getting in touch"},{"location":"pi-hole/main/coverage/","text":"YouTube/Twit/Video \u00b6 Security Now Netcast: Pi-hole Oct 13, 2015 TekThing: Raspberry Pi-Hole Makes Ads Disappear! Dec 18, 2015 Foolish Tech Show Dec 23, 2015 Digital Trends: 5 Fun, Easy Projects You Can Try With a $35 Raspberry Pi Mar 22, 2016 Adafruit: Raspberry Pi Quick Look at Pi Hole ad blocking server with Tony D Jun 20, 2016 The Defrag Show: Endoscope USB Camera, The Final [HoloLens] Vote, Adblock Pi and more Jan 27, 2016 Know How 355: Killing ads with a Raspberry Pi-Hole! Nov 9, 2017 Linus Tech Tips: Block EVERY Online Ad with THIS Aug 28, 2019 Podcasts \u00b6 MacObserver Podcast 585 Dec 27, 2015 Blogs \u00b6 Lifehacker: Turn A Raspberry Pi Into An Ad Blocker With A Single Command Feb 17, 2015 MakeUseOf: Adblock Everywhere: The Raspberry Pi-Hole Way Mar 25, 2015 Catchpoint: Ad-Blocking on Apple iOS9: Valuing the End User Experience Sept 14, 2015 Adafruit: Pi-hole is a black hole for internet ads Mar 4, 2016 Devacron: OrangePi Zero as an Ad-Block server with Pi-Hole Dec 3, 2016 Linux Pro: The Hole Truth 2017 CryptoAUSTRALIA: How We Tried 5 Privacy Focused Raspberry Pi Projects Oct 5, 2017 CryptoAUSTRALIA: Pi-hole Workshop Nov 2, 2017 Bloomberg: Inside the Brotherhood of the Ad Blockers May 10, 2018 How a Single Raspberry PI made my Home Network Faster March 1, 2019 Coding Horror: An Exercise Program for the Fat Web May 30, 2019","title":"Pi-hole News and Blogs"},{"location":"pi-hole/main/coverage/#youtubetwitvideo","text":"Security Now Netcast: Pi-hole Oct 13, 2015 TekThing: Raspberry Pi-Hole Makes Ads Disappear! Dec 18, 2015 Foolish Tech Show Dec 23, 2015 Digital Trends: 5 Fun, Easy Projects You Can Try With a $35 Raspberry Pi Mar 22, 2016 Adafruit: Raspberry Pi Quick Look at Pi Hole ad blocking server with Tony D Jun 20, 2016 The Defrag Show: Endoscope USB Camera, The Final [HoloLens] Vote, Adblock Pi and more Jan 27, 2016 Know How 355: Killing ads with a Raspberry Pi-Hole! Nov 9, 2017 Linus Tech Tips: Block EVERY Online Ad with THIS Aug 28, 2019","title":"YouTube/Twit/Video"},{"location":"pi-hole/main/coverage/#podcasts","text":"MacObserver Podcast 585 Dec 27, 2015","title":"Podcasts"},{"location":"pi-hole/main/coverage/#blogs","text":"Lifehacker: Turn A Raspberry Pi Into An Ad Blocker With A Single Command Feb 17, 2015 MakeUseOf: Adblock Everywhere: The Raspberry Pi-Hole Way Mar 25, 2015 Catchpoint: Ad-Blocking on Apple iOS9: Valuing the End User Experience Sept 14, 2015 Adafruit: Pi-hole is a black hole for internet ads Mar 4, 2016 Devacron: OrangePi Zero as an Ad-Block server with Pi-Hole Dec 3, 2016 Linux Pro: The Hole Truth 2017 CryptoAUSTRALIA: How We Tried 5 Privacy Focused Raspberry Pi Projects Oct 5, 2017 CryptoAUSTRALIA: Pi-hole Workshop Nov 2, 2017 Bloomberg: Inside the Brotherhood of the Ad Blockers May 10, 2018 How a Single Raspberry PI made my Home Network Faster March 1, 2019 Coding Horror: An Exercise Program for the Fat Web May 30, 2019","title":"Blogs"},{"location":"pi-hole/main/faq/","text":"Frequently Asked Questions \u00b6 This is a collection of questions that were asked repeatedly on discourse or github. Odd random character queries in Pi-hole's query logs \u00b6 You see three queries containing only random strings, sometimes with the local domain suffix, like yfjmdpisrvyrnq attxnwheeeuiad nskywzjbpj Solution: This happens when using Chrome-based browsers. Chrome tries to find out if someone is messing up with the DNS (i.e. wildcard DNS servers to catch all domains). Chrome does this by issuing DNS requests to randomly generated domain names with between 7 and 15 characters In a normal setup this results in a \u201cNo such name\u201d response from your DNS server. If the DNS server you use has a wildcard setup, each of these requests will result in a response (which is normally even the same) so Chrome knows that there is someone messing around with DNS responses. Link to Chromium's source code explaining the function. Pi-hole update fails due to repository changed it's 'Suite' value \u00b6 This happens after a manual OS upgrade to the next major version on deb based systems. A typical message is Repository 'http://archive.raspberrypi.org/debian buster InRelease' changed its 'Suite' value from 'stable' to 'oldstable' Solution: sudo apt-get update --allow-releaseinfo-change Pi-hole's gravity complains about invalid IDN domains \u00b6 During a gravity update, Pi-hole complains about some invalid Internationalized Domain Names (IDN) domains Sample of invalid domains: - test.\u4e2d\u56fd - test.\u0440\u0444 - test.\u092d\u093e\u0930\u0924 - e-ger\u00e4teundhaus.com - r\u00ebdd\u00eft.com Solution: Ask the list maintainer to convert the IDNs to their punycode representation. Internationalizing Domain Names in Applications (IDNA) was conceived to allow client-side use of language-specific characters in domain names without requiring any existing infrastructure (DNS servers, mall servers, etc., including associated protocols) to change. Accordingly, the corresponding original RFC 3490 clearly states that IDNA is employed at application level, not on the server side. Hence, DNS servers never see any IDN domain name, which means DNS records do not store IDN domain names at all, only their Punycode representations. Error while loading data from the long-term database \u00b6 If requesting a lot of data from the long-term database you get this error An unknown error occurred while loading the data. Check the server's log files (/var/log/lighttpd/error.log) for details. You may need to increase PHP memory limit. You can find more info in pi-hole's FAQ: https://docs.pi-hole.net/main/faq/#error-while-loading-data-from-the-long-term-database Solution: You need to increase PHP's memory and restart the server. The amount of memory needed depends on many factors: available system RAM, other processes running on your device, the amount of data you want to process. One approach would be to increase the limit by 128M and check if it was enough to retrieve the data. If not, add another 128M, check again. If not, add another 128M, check again, until you find the best value. Note: Do not assign all available memory as this can freeze your system. Please consider the possibility that your system does not have enough memory at all to load all the needed data. Steps to increase memory_limit : Open or create .user.ini file: sudo nano /var/www/html/.user.ini Add (or change) the memory limit (common abbreviation M=megabyte, G=gigabyte): memory_limit = 256M Restart the web server: sudo service lighttpd restart","title":"Faq"},{"location":"pi-hole/main/faq/#frequently-asked-questions","text":"This is a collection of questions that were asked repeatedly on discourse or github.","title":"Frequently Asked Questions"},{"location":"pi-hole/main/faq/#odd-random-character-queries-in-pi-holes-query-logs","text":"You see three queries containing only random strings, sometimes with the local domain suffix, like yfjmdpisrvyrnq attxnwheeeuiad nskywzjbpj Solution: This happens when using Chrome-based browsers. Chrome tries to find out if someone is messing up with the DNS (i.e. wildcard DNS servers to catch all domains). Chrome does this by issuing DNS requests to randomly generated domain names with between 7 and 15 characters In a normal setup this results in a \u201cNo such name\u201d response from your DNS server. If the DNS server you use has a wildcard setup, each of these requests will result in a response (which is normally even the same) so Chrome knows that there is someone messing around with DNS responses. Link to Chromium's source code explaining the function.","title":"Odd random character queries in Pi-hole's query logs"},{"location":"pi-hole/main/faq/#pi-hole-update-fails-due-to-repository-changed-its-suite-value","text":"This happens after a manual OS upgrade to the next major version on deb based systems. A typical message is Repository 'http://archive.raspberrypi.org/debian buster InRelease' changed its 'Suite' value from 'stable' to 'oldstable' Solution: sudo apt-get update --allow-releaseinfo-change","title":"Pi-hole update fails due to repository changed it's 'Suite' value"},{"location":"pi-hole/main/faq/#pi-holes-gravity-complains-about-invalid-idn-domains","text":"During a gravity update, Pi-hole complains about some invalid Internationalized Domain Names (IDN) domains Sample of invalid domains: - test.\u4e2d\u56fd - test.\u0440\u0444 - test.\u092d\u093e\u0930\u0924 - e-ger\u00e4teundhaus.com - r\u00ebdd\u00eft.com Solution: Ask the list maintainer to convert the IDNs to their punycode representation. Internationalizing Domain Names in Applications (IDNA) was conceived to allow client-side use of language-specific characters in domain names without requiring any existing infrastructure (DNS servers, mall servers, etc., including associated protocols) to change. Accordingly, the corresponding original RFC 3490 clearly states that IDNA is employed at application level, not on the server side. Hence, DNS servers never see any IDN domain name, which means DNS records do not store IDN domain names at all, only their Punycode representations.","title":"Pi-hole's gravity complains about invalid IDN domains"},{"location":"pi-hole/main/faq/#error-while-loading-data-from-the-long-term-database","text":"If requesting a lot of data from the long-term database you get this error An unknown error occurred while loading the data. Check the server's log files (/var/log/lighttpd/error.log) for details. You may need to increase PHP memory limit. You can find more info in pi-hole's FAQ: https://docs.pi-hole.net/main/faq/#error-while-loading-data-from-the-long-term-database Solution: You need to increase PHP's memory and restart the server. The amount of memory needed depends on many factors: available system RAM, other processes running on your device, the amount of data you want to process. One approach would be to increase the limit by 128M and check if it was enough to retrieve the data. If not, add another 128M, check again. If not, add another 128M, check again, until you find the best value. Note: Do not assign all available memory as this can freeze your system. Please consider the possibility that your system does not have enough memory at all to load all the needed data. Steps to increase memory_limit : Open or create .user.ini file: sudo nano /var/www/html/.user.ini Add (or change) the memory limit (common abbreviation M=megabyte, G=gigabyte): memory_limit = 256M Restart the web server: sudo service lighttpd restart","title":"Error while loading data from the long-term database"},{"location":"pi-hole/main/origins/","text":"Pi-hole being a advertising-aware DNS/Web server , makes use of the following technologies: dnsmasq - a lightweight DNS and DHCP server curl - A command-line tool for transferring data with URL syntax lighttpd - web server designed and optimized for high performance php - a popular general-purpose web scripting language AdminLTE Dashboard - premium admin control panel based on Bootstrap 3.x sqlite3 - SQL Database engine While quite outdated at this point, this original blog post about Pi-hole goes into great detail about how Pi-hole was originally set up and how it works. Syntactically, it's no longer accurate, but the same basic principles and logic still apply to Pi-hole's current state.","title":"Pi-hole Origins"},{"location":"pi-hole/main/post-install/","text":"Making your network take advantage of Pi-hole \u00b6 Once the installer has been run, you will need to configure your router to have DHCP clients use Pi-hole as their DNS server which ensures all devices connected to your network will have content blocked without any further intervention. If your router does not support setting the DNS server, you can use Pi-hole's built-in DHCP server ; just be sure to disable DHCP on your router first (if it has that feature available). As a last resort, you can manually set each device to use Pi-hole as its DNS server. Making your Pi-hole host use Pi-hole \u00b6 Pi-hole will not be used by the host automatically after installation. To have the host resolve though Pi-hole and your configured blocking lists, you can make the host use Pi-hole as upstream DNS server: Warning If your Pi-hole host is using Pi-hole as upstream DNS server and Pi-hole fails, your host loses DNS resolution. This can prevent successful repair attempts, e.g. by pihole -r as it needs a working internet connection. If your OS uses dhcpcd for network configuration, you can add to your /etc/dhcpcd.conf static domain_name_servers=127.0.0.1","title":"Post install"},{"location":"pi-hole/main/post-install/#making-your-network-take-advantage-of-pi-hole","text":"Once the installer has been run, you will need to configure your router to have DHCP clients use Pi-hole as their DNS server which ensures all devices connected to your network will have content blocked without any further intervention. If your router does not support setting the DNS server, you can use Pi-hole's built-in DHCP server ; just be sure to disable DHCP on your router first (if it has that feature available). As a last resort, you can manually set each device to use Pi-hole as its DNS server.","title":"Making your network take advantage of Pi-hole"},{"location":"pi-hole/main/post-install/#making-your-pi-hole-host-use-pi-hole","text":"Pi-hole will not be used by the host automatically after installation. To have the host resolve though Pi-hole and your configured blocking lists, you can make the host use Pi-hole as upstream DNS server: Warning If your Pi-hole host is using Pi-hole as upstream DNS server and Pi-hole fails, your host loses DNS resolution. This can prevent successful repair attempts, e.g. by pihole -r as it needs a working internet connection. If your OS uses dhcpcd for network configuration, you can add to your /etc/dhcpcd.conf static domain_name_servers=127.0.0.1","title":"Making your Pi-hole host use Pi-hole"},{"location":"pi-hole/main/prerequisites/","text":"Hardware \u00b6 Pi-hole is very lightweight and does not require much processing power Min. 2GB free space, 4GB recommended 512MB RAM Despite the name, you are not limited to running Pi-hole on a Raspberry Pi. Any hardware that runs one of the supported operating systems will do! Software \u00b6 Pi-hole is supported on distributions utilizing systemd or sysvinit ! Supported Operating Systems \u00b6 The following operating systems are officially supported: Distribution Release Architecture Raspberry Pi OS (formerly Raspbian) Stretch / Buster / Bullseye ARM Ubuntu 16.x / 18.x / 20.x /21.x ARM / x86_64 Debian 9 / 10 /11 ARM / x86_64 / i386 Fedora 33 / 34 ARM / x86_64 CentOS 7 x86_64 CentOS Stream 8 x86_64 Info One of the first tasks the install script has is to determine your Operating System's compatibility with Pi-hole It is possible that Pi-hole will install and run on variants of the above, but we cannot test them all. If you are using an operating system not on this list you may see the following message: [ \u2717 ] Unsupported OS detected: Debian 16 If you are seeing this message and you do have a supported OS, please contact support. https://docs.pi-hole.net/main/prerequisites/#supported-operating-systems If you wish to attempt to continue anyway, you can try one of the following commands to skip this check: e.g: If you are seeing this message on a fresh install, you can run: curl -sSL https://install.pi-hole.net | sudo PIHOLE_SKIP_OS_CHECK = true bash If you are seeing this message after having run pihole -up: sudo PIHOLE_SKIP_OS_CHECK = true pihole -r ( In this case , your previous run of pihole -up will have already updated the local repository ) It is possible that the installation will still fail at this stage due to an unsupported configuration. If that is the case , you can feel free to ask the community on Discourse with the Community Help category: https://discourse.pi-hole.net/c/bugs-problems-issues/community-help/ You can disable this check by setting an environment variable named PIHOLE_SKIP_OS_CHECK to true , however Pi-hole may have issues installing. If you choose to use this environment variable, please use the Community Help topic on Discourse to troubleshoot any installation issues you may (or may not!) have. IP Addressing \u00b6 Pi-hole needs a static IP address to properly function (a DHCP reservation is just fine). Users may run into issues because we currently install dhcpcd5 , which may conflict with other running network managers such as dhclient , dhcpcd , networkmanager , and systemd-networkd . As part of our install process, we append some lines to /etc/dhcpcd.conf in order to statically assign an IP address , so take note of this before installing. Please be aware of this fact because it may cause confusion . This is not the ideal situation for us to be in but, since a significant portion of our users are running Pi-hole on Raspbian - and because Pi-hole's roots began with the Raspberry Pi - it's a problem that is difficult to get away from . Due to the complexity of different ways of setting an IP address across different systems, it's a slow process and we need help . If you're willing to contribute, please let us know. Ports \u00b6 Service Port Protocol Notes pihole-FTL 53 (DNS) TCP/UDP If you happen to have another DNS server running, such as BIND, you will need to turn it off in order for Pi-hole to respond to DNS queries. pihole-FTL 67 (DHCP) IPv4 UDP The DHCP server is an optional feature that requires additional ports. pihole-FTL 547 (DHCPv6) IPv6 UDP The DHCP server is an optional feature that requires additional ports. lighttpd 80 (HTTP) TCP If you have another Web server already running, such as Apache, Pi-hole's Web server will not work. You can either disable the other Web server or change the port on which lighttpd listens, which allows you keep both Web servers running. pihole-FTL 4711 TCP FTL is our API engine and uses port 4711 on the localhost interface. This port should not be accessible from any other interface. Info The use of lighttpd on port 80 is optional if you decide not to install the Web dashboard during installation. The use of pihole-FTL on ports 67 or 547 is optional, but required if you use the DHCP functions of Pi-hole. Firewalls \u00b6 Below are some examples of firewall rules that will need to be set on your Pi-hole server in order to use the functions available. These are only shown as guides, the actual commands used will be found with your distribution's documentation. Because Pi-hole was designed to work inside a local network, the following rules will block the traffic from the Internet for security reasons. 192.168.0.0/16 is the most common local network IP range for home users but it can be different in your case, for example other common local network IPs are 10.0.0.0/8 and 172.16.0.0/12 . Check your local network settings before applying these rules. IPTables \u00b6 IPTables uses two sets of tables. One set is for IPv4 chains, and the second is for IPv6 chains. If only IPv4 blocking is used for the Pi-hole installation, only apply the rules for IP4Tables. Full Stack (IPv4 and IPv6) require both sets of rules to be applied. Note: These examples insert the rules at the front of the chain. Please see your distribution's documentation for the exact proper command to use. IPTables (IPv4) iptables -I INPUT 1 -s 192 .168.0.0/16 -p tcp -m tcp --dport 80 -j ACCEPT iptables -I INPUT 1 -s 127 .0.0.0/8 -p tcp -m tcp --dport 53 -j ACCEPT iptables -I INPUT 1 -s 127 .0.0.0/8 -p udp -m udp --dport 53 -j ACCEPT iptables -I INPUT 1 -s 192 .168.0.0/16 -p tcp -m tcp --dport 53 -j ACCEPT iptables -I INPUT 1 -s 192 .168.0.0/16 -p udp -m udp --dport 53 -j ACCEPT iptables -I INPUT 1 -p udp --dport 67 :68 --sport 67 :68 -j ACCEPT iptables -I INPUT 1 -p tcp -m tcp --dport 4711 -i lo -j ACCEPT iptables -I INPUT -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT IP6Tables (IPv6) ip6tables -I INPUT -p udp -m udp --sport 546 :547 --dport 546 :547 -j ACCEPT ip6tables -I INPUT -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT FirewallD \u00b6 Using the --permanent argument will ensure the firewall rules persist reboots. If only IPv4 blocking is used for the Pi-hole installation, the dhcpv6 service can be removed from the commands below. Create a new zone for the local interface ( lo ) for the pihole-FTL ports to ensure the API is only accessible locally. Finally --reload to have the new firewall configuration take effect immediately. firewall-cmd --permanent --add-service = http --add-service = dns --add-service = dhcp --add-service = dhcpv6 firewall-cmd --permanent --new-zone = ftl firewall-cmd --permanent --zone = ftl --add-interface = lo firewall-cmd --permanent --zone = ftl --add-port = 4711 /tcp firewall-cmd --reload ufw \u00b6 ufw stores all rules persistent, so you just need to execute the commands below. IPv4: ufw allow 80 /tcp ufw allow 53 /tcp ufw allow 53 /udp ufw allow 67 /tcp ufw allow 67 /udp IPv6 (include above IPv4 rules): ufw allow 546 :547/udp","title":"Prerequisites"},{"location":"pi-hole/main/prerequisites/#hardware","text":"Pi-hole is very lightweight and does not require much processing power Min. 2GB free space, 4GB recommended 512MB RAM Despite the name, you are not limited to running Pi-hole on a Raspberry Pi. Any hardware that runs one of the supported operating systems will do!","title":"Hardware"},{"location":"pi-hole/main/prerequisites/#software","text":"Pi-hole is supported on distributions utilizing systemd or sysvinit !","title":"Software"},{"location":"pi-hole/main/prerequisites/#supported-operating-systems","text":"The following operating systems are officially supported: Distribution Release Architecture Raspberry Pi OS (formerly Raspbian) Stretch / Buster / Bullseye ARM Ubuntu 16.x / 18.x / 20.x /21.x ARM / x86_64 Debian 9 / 10 /11 ARM / x86_64 / i386 Fedora 33 / 34 ARM / x86_64 CentOS 7 x86_64 CentOS Stream 8 x86_64 Info One of the first tasks the install script has is to determine your Operating System's compatibility with Pi-hole It is possible that Pi-hole will install and run on variants of the above, but we cannot test them all. If you are using an operating system not on this list you may see the following message: [ \u2717 ] Unsupported OS detected: Debian 16 If you are seeing this message and you do have a supported OS, please contact support. https://docs.pi-hole.net/main/prerequisites/#supported-operating-systems If you wish to attempt to continue anyway, you can try one of the following commands to skip this check: e.g: If you are seeing this message on a fresh install, you can run: curl -sSL https://install.pi-hole.net | sudo PIHOLE_SKIP_OS_CHECK = true bash If you are seeing this message after having run pihole -up: sudo PIHOLE_SKIP_OS_CHECK = true pihole -r ( In this case , your previous run of pihole -up will have already updated the local repository ) It is possible that the installation will still fail at this stage due to an unsupported configuration. If that is the case , you can feel free to ask the community on Discourse with the Community Help category: https://discourse.pi-hole.net/c/bugs-problems-issues/community-help/ You can disable this check by setting an environment variable named PIHOLE_SKIP_OS_CHECK to true , however Pi-hole may have issues installing. If you choose to use this environment variable, please use the Community Help topic on Discourse to troubleshoot any installation issues you may (or may not!) have.","title":"Supported Operating Systems"},{"location":"pi-hole/main/prerequisites/#ip-addressing","text":"Pi-hole needs a static IP address to properly function (a DHCP reservation is just fine). Users may run into issues because we currently install dhcpcd5 , which may conflict with other running network managers such as dhclient , dhcpcd , networkmanager , and systemd-networkd . As part of our install process, we append some lines to /etc/dhcpcd.conf in order to statically assign an IP address , so take note of this before installing. Please be aware of this fact because it may cause confusion . This is not the ideal situation for us to be in but, since a significant portion of our users are running Pi-hole on Raspbian - and because Pi-hole's roots began with the Raspberry Pi - it's a problem that is difficult to get away from . Due to the complexity of different ways of setting an IP address across different systems, it's a slow process and we need help . If you're willing to contribute, please let us know.","title":"IP Addressing"},{"location":"pi-hole/main/prerequisites/#ports","text":"Service Port Protocol Notes pihole-FTL 53 (DNS) TCP/UDP If you happen to have another DNS server running, such as BIND, you will need to turn it off in order for Pi-hole to respond to DNS queries. pihole-FTL 67 (DHCP) IPv4 UDP The DHCP server is an optional feature that requires additional ports. pihole-FTL 547 (DHCPv6) IPv6 UDP The DHCP server is an optional feature that requires additional ports. lighttpd 80 (HTTP) TCP If you have another Web server already running, such as Apache, Pi-hole's Web server will not work. You can either disable the other Web server or change the port on which lighttpd listens, which allows you keep both Web servers running. pihole-FTL 4711 TCP FTL is our API engine and uses port 4711 on the localhost interface. This port should not be accessible from any other interface. Info The use of lighttpd on port 80 is optional if you decide not to install the Web dashboard during installation. The use of pihole-FTL on ports 67 or 547 is optional, but required if you use the DHCP functions of Pi-hole.","title":"Ports"},{"location":"pi-hole/main/prerequisites/#firewalls","text":"Below are some examples of firewall rules that will need to be set on your Pi-hole server in order to use the functions available. These are only shown as guides, the actual commands used will be found with your distribution's documentation. Because Pi-hole was designed to work inside a local network, the following rules will block the traffic from the Internet for security reasons. 192.168.0.0/16 is the most common local network IP range for home users but it can be different in your case, for example other common local network IPs are 10.0.0.0/8 and 172.16.0.0/12 . Check your local network settings before applying these rules.","title":"Firewalls"},{"location":"pi-hole/main/prerequisites/#iptables","text":"IPTables uses two sets of tables. One set is for IPv4 chains, and the second is for IPv6 chains. If only IPv4 blocking is used for the Pi-hole installation, only apply the rules for IP4Tables. Full Stack (IPv4 and IPv6) require both sets of rules to be applied. Note: These examples insert the rules at the front of the chain. Please see your distribution's documentation for the exact proper command to use. IPTables (IPv4) iptables -I INPUT 1 -s 192 .168.0.0/16 -p tcp -m tcp --dport 80 -j ACCEPT iptables -I INPUT 1 -s 127 .0.0.0/8 -p tcp -m tcp --dport 53 -j ACCEPT iptables -I INPUT 1 -s 127 .0.0.0/8 -p udp -m udp --dport 53 -j ACCEPT iptables -I INPUT 1 -s 192 .168.0.0/16 -p tcp -m tcp --dport 53 -j ACCEPT iptables -I INPUT 1 -s 192 .168.0.0/16 -p udp -m udp --dport 53 -j ACCEPT iptables -I INPUT 1 -p udp --dport 67 :68 --sport 67 :68 -j ACCEPT iptables -I INPUT 1 -p tcp -m tcp --dport 4711 -i lo -j ACCEPT iptables -I INPUT -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT IP6Tables (IPv6) ip6tables -I INPUT -p udp -m udp --sport 546 :547 --dport 546 :547 -j ACCEPT ip6tables -I INPUT -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT","title":"IPTables"},{"location":"pi-hole/main/prerequisites/#firewalld","text":"Using the --permanent argument will ensure the firewall rules persist reboots. If only IPv4 blocking is used for the Pi-hole installation, the dhcpv6 service can be removed from the commands below. Create a new zone for the local interface ( lo ) for the pihole-FTL ports to ensure the API is only accessible locally. Finally --reload to have the new firewall configuration take effect immediately. firewall-cmd --permanent --add-service = http --add-service = dns --add-service = dhcp --add-service = dhcpv6 firewall-cmd --permanent --new-zone = ftl firewall-cmd --permanent --zone = ftl --add-interface = lo firewall-cmd --permanent --zone = ftl --add-port = 4711 /tcp firewall-cmd --reload","title":"FirewallD"},{"location":"pi-hole/main/prerequisites/#ufw","text":"ufw stores all rules persistent, so you just need to execute the commands below. IPv4: ufw allow 80 /tcp ufw allow 53 /tcp ufw allow 53 /udp ufw allow 67 /tcp ufw allow 67 /udp IPv6 (include above IPv4 rules): ufw allow 546 :547/udp","title":"ufw"},{"location":"pi-hole/main/projects/","text":"The Big Blocklist Collection Pi-Hole in the cloud Minibian Pi-hole CHiP-hole: Network-wide Ad-blocker Chrome Extension: Pi-Hole List Editor ( Source Code ) Splunk: Pi-hole Visualiser Adblocking with Pi-hole and Ubuntu 14.04 on VirtualBox Pi-hole unRAID Template Copernicus: Windows Tray Application Let your blink1 device blink when Pi-hole filters ads Pi-hole metrics exporter for Prometheus Magic Mirror with DNS Filtering Pi-hole Droid: Android client Windows DNS Swapper , see #1400 Pi-hole Visualizer Enable/Disable Pi-Hole from your iPhone Home Screen Pi-hole Shortcuts: Native macOS client","title":"Community Projects"},{"location":"pi-hole/main/uninstall/","text":"Pi-hole can be uninstalled using: pihole uninstall Warning If you are unsure whether a package should be removed during uninstalling, we'd recommend leaving it installed, as required system packages may be among them!","title":"Uninstall"},{"location":"pi-hole/main/update/","text":"Updating is as simple as running the following command: pihole -up","title":"Update"},{"location":"pi-hole/regex/approximate/","text":"Approximative matching \u00b6 You may or not be know agrep . It is basically a \"forgiving\" grep and is, for instance, used for searching through (offline) dictionaries. It is tolerant against errors (up to degree you specify). It may be beneficial is you want to match against domains where you don't really know the pattern. It is just an idea, we will have to see if it is actually useful. This is a somewhat complicated topic, we'll approach it by examples as it is very complicated to get the head around it by just listening to the specifications. The approximate matching settings for a subpattern can be changed by appending approx-settings to the subpattern. Limits for the number of errors can be set and an expression for specifying and limiting the costs can be given: Accepted insertions ( + ) \u00b6 Use (something){+x} to specify that the regex should still be matching when x characters would need it be inserted into the sub-expression something . Example: doubleclick.net is matched by ^doubleclick\\.(nt){+1}$ The missing e in nt is inserted. Similarly: doubleclick.net is matched by ^(doubleclk\\.nt){+3}$ The missing characters in the domain are substituted. The maximum number of insertions spans the entire domain as is wrapped in the sub-expression (...) . Accepted deletions ( - ) \u00b6 Use (something){-x} to specify that the regex should still be matching when x characters would need it be deleted from the sub-expression something : Example: doubleclick.net is matched by ^doubleclick\\.(neet){-1}$ The surplus e in neet is deleted. Similarly: doubleclick.net is matched by ^(doubleclicky\\.netty){-3}$ doubleclick.net is NOT matched by ^(doubleclicky\\.nettfy){-3}$ Accepted substitutions ( # ) \u00b6 Use (something){#x} to specify that the regex should still be matching when x characters would need to be substituted from the sub-expression something : Example 1: oobargoobaploowap is matched by (foobar){#2~2} Hint: goobap is foobar with two substitutions f->g and r->p Example 2: doubleclick.net is matched by ^doubleclick\\.n(tt){#1}$ The incorrect t in ntt is substituted. Note that substitutions are necessary when a character needs to be replaced as the corresponding realization with one insertion and one deletion is not identical : doubleclick.net is matched by ^doubleclick\\.n(tt){+1-1}$ ( t is removed, e is added), however doubleclick.nt is ALSO matched by ^doubleclick\\.n(tt){+1-1}$ (the t is just removed, nothing had to be added) but doubleclick.nt is NOT matched by ^doubleclick\\.n(tt){#1}$ doesn't match as substitutions always require characters to be swapped by others. Combinations and total error limit ( ~ ) \u00b6 All rules from above can be combined like as {+2-5#6} allowing (up to!) two insertions, five deletions, and six substitutions. You can enforce an upper limit on the number of tried realizations using the tilde. Even when {+2-5#6} can lead to up to 13 operations being tried, this can be limited to (at most) seven tries using {+2-5#6~7} . Example: oobargoobploowap is matched by (foobar){+2#2~3} Hint: goobaap is foobar with - two substitutions f->g and r->p , and - one addition a between bar (to have baap ) Specifying ~2 instead of ~3 will lead to no match as three errors need to be corrected in total for a match in this example. Advanced topic: Cost-equation \u00b6 You can even weight the \"costs\" of insertions, deletions or substitutions. This is really an advanced topic and should only be touched when really needed. A cost-equation can be thought of as a mathematical equation, where i , d , and s stand for the number of insertions, deletions, and substitutions, respectively. The equation can have a multiplier for each of i , d , and s . The multiplier is the cost of the error , and the number after < is the maximum allowed total cost of a match. Spaces and pluses can be inserted to make the equation more readable. When specifying only a cost equation, adding a space after the opening { is required . Example 1: { 2i + 1d + 2s < 5 } This sets the cost of an insertion to two, a deletion to one, a substitution to two, and the maximum cost to five. Example 2: {+2-5#6, 2i + 1d + 2s < 5 } This sets the cost of an insertion to two, a deletion to one, a substitution to two, and the maximum cost to five. Furthermore, it allows only up to 2 insertions (coming at a total cost of 4), five deletions and up to 6 substitutions. As six substitutions would come at a cost of 6*2 = 12 , exceeding the total allowed costs of 5, they cannot all be realized.","title":"Approximative matching"},{"location":"pi-hole/regex/approximate/#approximative-matching","text":"You may or not be know agrep . It is basically a \"forgiving\" grep and is, for instance, used for searching through (offline) dictionaries. It is tolerant against errors (up to degree you specify). It may be beneficial is you want to match against domains where you don't really know the pattern. It is just an idea, we will have to see if it is actually useful. This is a somewhat complicated topic, we'll approach it by examples as it is very complicated to get the head around it by just listening to the specifications. The approximate matching settings for a subpattern can be changed by appending approx-settings to the subpattern. Limits for the number of errors can be set and an expression for specifying and limiting the costs can be given:","title":"Approximative matching"},{"location":"pi-hole/regex/approximate/#accepted-insertions","text":"Use (something){+x} to specify that the regex should still be matching when x characters would need it be inserted into the sub-expression something . Example: doubleclick.net is matched by ^doubleclick\\.(nt){+1}$ The missing e in nt is inserted. Similarly: doubleclick.net is matched by ^(doubleclk\\.nt){+3}$ The missing characters in the domain are substituted. The maximum number of insertions spans the entire domain as is wrapped in the sub-expression (...) .","title":"Accepted insertions (+)"},{"location":"pi-hole/regex/approximate/#accepted-deletions-","text":"Use (something){-x} to specify that the regex should still be matching when x characters would need it be deleted from the sub-expression something : Example: doubleclick.net is matched by ^doubleclick\\.(neet){-1}$ The surplus e in neet is deleted. Similarly: doubleclick.net is matched by ^(doubleclicky\\.netty){-3}$ doubleclick.net is NOT matched by ^(doubleclicky\\.nettfy){-3}$","title":"Accepted deletions (-)"},{"location":"pi-hole/regex/approximate/#accepted-substitutions","text":"Use (something){#x} to specify that the regex should still be matching when x characters would need to be substituted from the sub-expression something : Example 1: oobargoobaploowap is matched by (foobar){#2~2} Hint: goobap is foobar with two substitutions f->g and r->p Example 2: doubleclick.net is matched by ^doubleclick\\.n(tt){#1}$ The incorrect t in ntt is substituted. Note that substitutions are necessary when a character needs to be replaced as the corresponding realization with one insertion and one deletion is not identical : doubleclick.net is matched by ^doubleclick\\.n(tt){+1-1}$ ( t is removed, e is added), however doubleclick.nt is ALSO matched by ^doubleclick\\.n(tt){+1-1}$ (the t is just removed, nothing had to be added) but doubleclick.nt is NOT matched by ^doubleclick\\.n(tt){#1}$ doesn't match as substitutions always require characters to be swapped by others.","title":"Accepted substitutions (#)"},{"location":"pi-hole/regex/approximate/#combinations-and-total-error-limit","text":"All rules from above can be combined like as {+2-5#6} allowing (up to!) two insertions, five deletions, and six substitutions. You can enforce an upper limit on the number of tried realizations using the tilde. Even when {+2-5#6} can lead to up to 13 operations being tried, this can be limited to (at most) seven tries using {+2-5#6~7} . Example: oobargoobploowap is matched by (foobar){+2#2~3} Hint: goobaap is foobar with - two substitutions f->g and r->p , and - one addition a between bar (to have baap ) Specifying ~2 instead of ~3 will lead to no match as three errors need to be corrected in total for a match in this example.","title":"Combinations and total error limit (~)"},{"location":"pi-hole/regex/approximate/#advanced-topic-cost-equation","text":"You can even weight the \"costs\" of insertions, deletions or substitutions. This is really an advanced topic and should only be touched when really needed. A cost-equation can be thought of as a mathematical equation, where i , d , and s stand for the number of insertions, deletions, and substitutions, respectively. The equation can have a multiplier for each of i , d , and s . The multiplier is the cost of the error , and the number after < is the maximum allowed total cost of a match. Spaces and pluses can be inserted to make the equation more readable. When specifying only a cost equation, adding a space after the opening { is required . Example 1: { 2i + 1d + 2s < 5 } This sets the cost of an insertion to two, a deletion to one, a substitution to two, and the maximum cost to five. Example 2: {+2-5#6, 2i + 1d + 2s < 5 } This sets the cost of an insertion to two, a deletion to one, a substitution to two, and the maximum cost to five. Furthermore, it allows only up to 2 insertions (coming at a total cost of 4), five deletions and up to 6 substitutions. As six substitutions would come at a cost of 6*2 = 12 , exceeding the total allowed costs of 5, they cannot all be realized.","title":"Advanced topic: Cost-equation"},{"location":"pi-hole/regex/overview/","text":"A regular expression, or RegEx for short, is a pattern that can be used for building arbitrarily complex filter rules in FTL DNS. We implement the POSIX Extended Regular Expressions similar to the one used by the UNIX egrep (or grep -E ) command. We amend the regex engine by approximate blocking (compare to agrep ) and other special features like matching to specific query types only. Our implementation is light and fast as each domain is only checked once for a match. When you query google.com , it will be checked against your RegEx. Any subsequent query to the same domain will not be checked again until you restart pihole-FTL . Hierarchy of regex filters in FTL DNS \u00b6 FTL DNS uses a specific hierarchy to ensure regex filters work as you expect them to. Whitelisting always has priority over blacklisting. There are two locations where regex filters are important: On loading the blocking domains form the gravity database table, FTL DNS skips not only exactly whitelisted domains but also those that match enabled whitelist regex filters. When a queried domain matches a blacklist regex filter, the query will not be blocked if the domain also matches an exact or a regex whitelist entry. How to use regular expressions for filtering domains \u00b6 FTL DNS reads in regular expression filters from the two regex database views . To tell FTL DNS to reload the list of regex filters, either: Execute pihole restartdns reload-lists or Send SIGHUP to pihole-FTL ( sudo killall -SIGHUP pihole-FTL ) or Restart the service ( sudo service pihole-FTL restart ) The first command is to be preferred as it ensures that the DNS cache itself remains intact. Hence, it is also the fastest of the available options. Pi-hole Regex debugging mode \u00b6 To ease the usage of regular expression filters in FTL DNS, we offer a regex debugging mode. Set DEBUG_REGEX=true in your /etc/pihole/pihole-FTL.conf and restart pihole-FTL to enable or disable this mode. Once the debugging mode is enabled, each match will be logged to /var/log/pihole-FTL.log in the following format: [2018-07-17 17:40:51.304] Regex blacklist (DB ID 15) >> MATCH: \"whatever.twitter.com\" vs. \"((^)|(\\.))twitter\\.\" The given DB ID corresponds to the ID of the corresponding row in the domainlist database table. Note that validation is only done on the first occurrence of a domain to increase the computational efficiency of FTL DNS. The result of this evaluation is stored in an internal DNS cache that is separate from dnsmasq 's own DNS cache. This allows us to only flush this special cache when modifying the black- and whitelists without having to flush the entire DNS cache collected so far.","title":"Overview"},{"location":"pi-hole/regex/overview/#hierarchy-of-regex-filters-in-ftldns","text":"FTL DNS uses a specific hierarchy to ensure regex filters work as you expect them to. Whitelisting always has priority over blacklisting. There are two locations where regex filters are important: On loading the blocking domains form the gravity database table, FTL DNS skips not only exactly whitelisted domains but also those that match enabled whitelist regex filters. When a queried domain matches a blacklist regex filter, the query will not be blocked if the domain also matches an exact or a regex whitelist entry.","title":"Hierarchy of regex filters in FTLDNS"},{"location":"pi-hole/regex/overview/#how-to-use-regular-expressions-for-filtering-domains","text":"FTL DNS reads in regular expression filters from the two regex database views . To tell FTL DNS to reload the list of regex filters, either: Execute pihole restartdns reload-lists or Send SIGHUP to pihole-FTL ( sudo killall -SIGHUP pihole-FTL ) or Restart the service ( sudo service pihole-FTL restart ) The first command is to be preferred as it ensures that the DNS cache itself remains intact. Hence, it is also the fastest of the available options.","title":"How to use regular expressions for filtering domains"},{"location":"pi-hole/regex/overview/#pi-hole-regex-debugging-mode","text":"To ease the usage of regular expression filters in FTL DNS, we offer a regex debugging mode. Set DEBUG_REGEX=true in your /etc/pihole/pihole-FTL.conf and restart pihole-FTL to enable or disable this mode. Once the debugging mode is enabled, each match will be logged to /var/log/pihole-FTL.log in the following format: [2018-07-17 17:40:51.304] Regex blacklist (DB ID 15) >> MATCH: \"whatever.twitter.com\" vs. \"((^)|(\\.))twitter\\.\" The given DB ID corresponds to the ID of the corresponding row in the domainlist database table. Note that validation is only done on the first occurrence of a domain to increase the computational efficiency of FTL DNS. The result of this evaluation is stored in an internal DNS cache that is separate from dnsmasq 's own DNS cache. This allows us to only flush this special cache when modifying the black- and whitelists without having to flush the entire DNS cache collected so far.","title":"Pi-hole Regex debugging mode"},{"location":"pi-hole/regex/pi-hole/","text":"Pi-hole regex extensions \u00b6 Only match specific query types \u00b6 You can amend the regular expressions by special keywords added at the end to fine-tine regular expressions to match only specific query types . Example: abc;querytype=AAAA will block dig AAAA abc but not dig A abc This allows you to do query type based black-/whitelisting. Some user-provided examples are: .*;querytype=!A A regex blacklist entry for blocking AAAA (in fact, everything else than A , call it \"anti- A \") requests for all clients assigned to the same group. This has been mentioned to be benefitial for devices like Chromecast. You may want to fine-tune this further to specific domains. .*;querytype=PTR A regex whitelist entry used to permit PTR lookups with the above \"anti- A \" regex .*;querytype=ANY A regex blacklist entry to block ANY request network wide. Invert matching \u00b6 Sometimes, it may be useful to be able to invert a regular expression altogether. Hence, we added the keyword ;invert to achieve exactly this. For instance, ^abc$;querytype=AAAA;invert will not block abc with type AAAA (but everything else) for the clients assigned to the same groups. This inversion is independent for the query type, e.g. ^abc$;invert will block not block abc but everything else . Specify reply type \u00b6 Pi-hole allows you to configure the reply it serves when a regular expression matches a query. This can be controlled via the ;reply keyword. Valid options are: ;reply=nodata (an empty answer will be provided) ;reply=nxdomain (\"no such domain\" will be provided, can cause unintended side-effects) ;reply=refused (the query will be refused) ;reply=none (the query will be silently dropped) ;reply=ip (the Pi-hole's IP address if not overwritten by REPLY_ADDR4 and/or REPLY_ADDR6 ) ;reply=1.2.3.4 (any valid IPv4 address) ;reply=fe80::1234 (any valid IPv6 address) Only one option should be specified. An exception to this rule are the last two options which may be specified at the same time to configure both an IPv4 and an IPv6 address: IPv4 only: myregex;reply=1.2.3.4 will result in A 1.2.3.4 and AAAA :: - IPv6 only: myregex;reply=fe80::1234 will result in A 0.0.0.0 and AAAA fe80:1234 - IPv4 and IPv6: myregex;reply=1.2.3.4;reply=fe80::1234 will result in A 1.2.3.4 and AAAA fe80:1234 Comments \u00b6 You can specify comments within your regex using the syntax (?#some comment here) The comment can contain any characters except for a closing parenthesis ) (for the sole reason being the terminating element). The text in the comment is completely ignored by the regex parser and it used solely for readability purposes. $ pihole-FTL regex-test \"doubleclick.net\" \"(^|\\.)doubleclick\\.(?#TODO: We need to maybe support more than just .net here)net$\" FTL Regex test: Domain: \"doubleclick.net\" Regex: \"(^|\\.)doubleclick\\.(?#TODO: We need to maybe support more than just .net here)net$\" Step 1: Compiling regex filter... Compiled regex filter in 0.167 msec Step 2: Checking domain... Done in 0.032 msec MATCH Back-references \u00b6 A back reference is a backslash followed by a single non-zero decimal digit d . It matches the same sequence of characters matched by the d th parenthesized subexpression. Example: \"cat.foo.dog---cat%dog!foo\" is matched by \"(cat)\\.(foo)\\.(dog)---\\1%\\3!\\2\" Another (more complex example is): (1234|4321)\\.(foo)\\.(dog)--\\1 MATCH: 1234.foo.dog--1234 MATCH: 4321.foo.dog--4321 NO MATCH: 1234.foo.dog--4321 Mind that the last line gives no match as \\1 matches exactly the same sequence the first character group matched. And 4321 is not the same as 1234 even when both are valid replies for (1234|4321) Back references are not defined for POSIX EREs (for BREs they are, surprisingly enough). We add them to ERE in the BRE style. $ pihole-FTL regex-test \"someverylongandmaybecomplexthing.foo.dog--someverylongandmaybecomplexthing\" \"(someverylongandmaybecomplexthing|somelesscomplexitem)\\.(foo)\\.(dog)--\\1\" FTL Regex test: Domain: \"someverylongandmaybecomplexthing.foo.dog--someverylongandmaybecomplexthing\" Regex: \"(someverylongandmaybecomplexthing|somelesscomplexitem)\\.(foo)\\.(dog)--\\1\" Step 1: Compiling regex filter... Compiled regex filter in 0.563 msec Step 2: Checking domain... Done in 0.031 msec MATCH More character classes for bracket expressions \u00b6 A bracket expression specifies a set of characters by enclosing a nonempty list of items in brackets. Normally anything matching any item in the list is matched. If the list begins with ^ the meaning is negated; any character matching no item in the list is matched. Multiple characters: [abc] matches a , b , and c . Character ranges: [0-9] matches any decimal digit. Character classes: [:alnum:] alphanumeric characters [:alpha:] alphabetic characters [:blank:] blank characters [:cntrl:] control characters [:digit:] decimal digits (0 - 9) [:graph:] all printable characters except space [:lower:] lower-case letters (FTL matches case-insensitive by default) [:print:] printable characters including space [:punct:] printable characters not space or alphanumeric [:space:] white-space characters [:upper:] upper case letters (FTL matches case-insensitive by default) [:xdigit:] hexadecimal digits Furthermore, there are two shortcuts for some character classes: \\d - Digit character (equivalent to [[:digit:]] ) \\D - Non-digit character (equivalent to [^[:digit:]] )","title":"Pi-hole regex extensions"},{"location":"pi-hole/regex/pi-hole/#pi-hole-regex-extensions","text":"","title":"Pi-hole regex extensions"},{"location":"pi-hole/regex/pi-hole/#only-match-specific-query-types","text":"You can amend the regular expressions by special keywords added at the end to fine-tine regular expressions to match only specific query types . Example: abc;querytype=AAAA will block dig AAAA abc but not dig A abc This allows you to do query type based black-/whitelisting. Some user-provided examples are: .*;querytype=!A A regex blacklist entry for blocking AAAA (in fact, everything else than A , call it \"anti- A \") requests for all clients assigned to the same group. This has been mentioned to be benefitial for devices like Chromecast. You may want to fine-tune this further to specific domains. .*;querytype=PTR A regex whitelist entry used to permit PTR lookups with the above \"anti- A \" regex .*;querytype=ANY A regex blacklist entry to block ANY request network wide.","title":"Only match specific query types"},{"location":"pi-hole/regex/pi-hole/#invert-matching","text":"Sometimes, it may be useful to be able to invert a regular expression altogether. Hence, we added the keyword ;invert to achieve exactly this. For instance, ^abc$;querytype=AAAA;invert will not block abc with type AAAA (but everything else) for the clients assigned to the same groups. This inversion is independent for the query type, e.g. ^abc$;invert will block not block abc but everything else .","title":"Invert matching"},{"location":"pi-hole/regex/pi-hole/#specify-reply-type","text":"Pi-hole allows you to configure the reply it serves when a regular expression matches a query. This can be controlled via the ;reply keyword. Valid options are: ;reply=nodata (an empty answer will be provided) ;reply=nxdomain (\"no such domain\" will be provided, can cause unintended side-effects) ;reply=refused (the query will be refused) ;reply=none (the query will be silently dropped) ;reply=ip (the Pi-hole's IP address if not overwritten by REPLY_ADDR4 and/or REPLY_ADDR6 ) ;reply=1.2.3.4 (any valid IPv4 address) ;reply=fe80::1234 (any valid IPv6 address) Only one option should be specified. An exception to this rule are the last two options which may be specified at the same time to configure both an IPv4 and an IPv6 address: IPv4 only: myregex;reply=1.2.3.4 will result in A 1.2.3.4 and AAAA :: - IPv6 only: myregex;reply=fe80::1234 will result in A 0.0.0.0 and AAAA fe80:1234 - IPv4 and IPv6: myregex;reply=1.2.3.4;reply=fe80::1234 will result in A 1.2.3.4 and AAAA fe80:1234","title":"Specify reply type"},{"location":"pi-hole/regex/pi-hole/#comments","text":"You can specify comments within your regex using the syntax (?#some comment here) The comment can contain any characters except for a closing parenthesis ) (for the sole reason being the terminating element). The text in the comment is completely ignored by the regex parser and it used solely for readability purposes. $ pihole-FTL regex-test \"doubleclick.net\" \"(^|\\.)doubleclick\\.(?#TODO: We need to maybe support more than just .net here)net$\" FTL Regex test: Domain: \"doubleclick.net\" Regex: \"(^|\\.)doubleclick\\.(?#TODO: We need to maybe support more than just .net here)net$\" Step 1: Compiling regex filter... Compiled regex filter in 0.167 msec Step 2: Checking domain... Done in 0.032 msec MATCH","title":"Comments"},{"location":"pi-hole/regex/pi-hole/#back-references","text":"A back reference is a backslash followed by a single non-zero decimal digit d . It matches the same sequence of characters matched by the d th parenthesized subexpression. Example: \"cat.foo.dog---cat%dog!foo\" is matched by \"(cat)\\.(foo)\\.(dog)---\\1%\\3!\\2\" Another (more complex example is): (1234|4321)\\.(foo)\\.(dog)--\\1 MATCH: 1234.foo.dog--1234 MATCH: 4321.foo.dog--4321 NO MATCH: 1234.foo.dog--4321 Mind that the last line gives no match as \\1 matches exactly the same sequence the first character group matched. And 4321 is not the same as 1234 even when both are valid replies for (1234|4321) Back references are not defined for POSIX EREs (for BREs they are, surprisingly enough). We add them to ERE in the BRE style. $ pihole-FTL regex-test \"someverylongandmaybecomplexthing.foo.dog--someverylongandmaybecomplexthing\" \"(someverylongandmaybecomplexthing|somelesscomplexitem)\\.(foo)\\.(dog)--\\1\" FTL Regex test: Domain: \"someverylongandmaybecomplexthing.foo.dog--someverylongandmaybecomplexthing\" Regex: \"(someverylongandmaybecomplexthing|somelesscomplexitem)\\.(foo)\\.(dog)--\\1\" Step 1: Compiling regex filter... Compiled regex filter in 0.563 msec Step 2: Checking domain... Done in 0.031 msec MATCH","title":"Back-references"},{"location":"pi-hole/regex/pi-hole/#more-character-classes-for-bracket-expressions","text":"A bracket expression specifies a set of characters by enclosing a nonempty list of items in brackets. Normally anything matching any item in the list is matched. If the list begins with ^ the meaning is negated; any character matching no item in the list is matched. Multiple characters: [abc] matches a , b , and c . Character ranges: [0-9] matches any decimal digit. Character classes: [:alnum:] alphanumeric characters [:alpha:] alphabetic characters [:blank:] blank characters [:cntrl:] control characters [:digit:] decimal digits (0 - 9) [:graph:] all printable characters except space [:lower:] lower-case letters (FTL matches case-insensitive by default) [:print:] printable characters including space [:punct:] printable characters not space or alphanumeric [:space:] white-space characters [:upper:] upper case letters (FTL matches case-insensitive by default) [:xdigit:] hexadecimal digits Furthermore, there are two shortcuts for some character classes: \\d - Digit character (equivalent to [[:digit:]] ) \\D - Non-digit character (equivalent to [^[:digit:]] )","title":"More character classes for bracket expressions"},{"location":"pi-hole/regex/testmode/","text":"Regex Test mode \u00b6 In order to ease regex development, we added a regex test mode to pihole-FTL which can be invoked like pihole-FTL regex-test doubleclick.net (test doubleclick.net against all regexs in the gravity database), or pihole-FTL regex-test doubleclick.net \"(^|\\.)double\" (test doubleclick.net against the CLI-provided regex (^|\\.)double . You do NOT need to be sudo for this, any arbitrary user should be able to run this command. The test returns 0 on match and 1 on no match and errors, hence, it may be used for scripting.","title":"Regex Test mode"},{"location":"pi-hole/regex/testmode/#regex-test-mode","text":"In order to ease regex development, we added a regex test mode to pihole-FTL which can be invoked like pihole-FTL regex-test doubleclick.net (test doubleclick.net against all regexs in the gravity database), or pihole-FTL regex-test doubleclick.net \"(^|\\.)double\" (test doubleclick.net against the CLI-provided regex (^|\\.)double . You do NOT need to be sudo for this, any arbitrary user should be able to run this command. The test returns 0 on match and 1 on no match and errors, hence, it may be used for scripting.","title":"Regex Test mode"},{"location":"pi-hole/regex/tutorial/","text":"Pi-hole regular expressions tutorial \u00b6 We provide a short but thorough introduction to our regular expressions implementation. This may come in handy if you are designing blocking or whitelisting rules (see also our cheat sheet below!). In our implementation, all characters match themselves except for the following special characters: .[{}()\\*+?|^$ . If you want to match those, you need to escape them like \\. for a literal period, but no rule without exception (see character groups below for further details). Anchors ( ^ and $ ) \u00b6 First of all, we look at anchors that can be used to indicate the start or the end of a domain, respectively. If you don't specify anchors, the match may be partial (see examples below). Example Interpretation domain partial match . Without anchors, a text may appear anywhere in the domain. This matches some.domain.com , domain.com and verylongdomain.com and more ^localhost$ exact match matching only localhost but neither a.localhost nor localhost.com ^abc matches any domain starting ( ^ ) in \"abc\" like abcdomain.com , abc.domain.com but not def.abc.com com$ matches any domain ending ( $ ) in \"com\" such as domain.com but not domain.com.co.uk Wildcard ( . ) \u00b6 An unescaped period stands for any single character. Example Interpretation ^domain.$ matches domaina , domainb , domainc , but not domain Bounds and multipliers ( {} , * , + , and ? ) \u00b6 With bounds, one can denote the number of times something has to occur: Bound Meaning ab{4} matches a domain that contains a single a followed by four b (matching only abbbb ) ab{4,} matches a domain that contains a single a followed by at least four b (matching also abbbbbbbb ) ab{3,5} matches a domain that contains a single a followed by three to five b (matching only abbb , abbbb , and abbbbb ) Multipliers are shortcuts for some of the bounds that are needed most often: Multipliers Bounds equivalent Meaning ? {0,1} never or once (optional) * {0,} never or more (optional) + {1,} once or more (mandatory) To illustrate the usefulness of multipliers (and bounds), we provide a few examples: Example Interpretation ^r-*movie matches a domain like r------movie.com where the number of dashes can be arbitrary (also none) ^r-?movie matches only the domains rmovie.com and r-movie.com but not those with more than one dash ^r-+movie matches only the domains with at least one dash, i.e., not rmovie.com ^a?b+ matches domains like abbbb.com (zero or one a at the beginning followed by one or more b ) Character groups ( [] ) \u00b6 With character groups, a set of characters can be matched: Character group Interpretation [abc] matches a , b , or c (using explicitly specified characters) [a-c] matches a , b , or c (using a range ) [a-c]+ matches any non-zero number of a , b , c [a-z] matches any single lowercase letter [a-zA-Z] matches any single letter [a-z0-9] matches any single lowercase letter or any single digit [^a-z] Negation matching any single character except lowercase letters abc[0-9]+ matches the string abc followed by a number of arbitrary length Bracket expressions are an exception to the character escape rule. Inside them, all special characters, including the backslash ( \\ ), lose their special powers, i.e. they match themselves exactly. Furthermore, to include a literal ] in the list, make it the first character (like []] or [^]] if negated). To include a literal - , make it the first or last character, or the second endpoint of a range (e.g. [a-z-] to match a to z and - ). Groups ( () ) \u00b6 Using groups, we can enclose regular expressions, they are most powerful when combined with bounds or multipliers (see also alternations below). Example Interpretation (abc) matches abc (trivial example) (abc)* matches zero or more copies of abc like abcabc but not abcdefabc (abc){1,3} matches one, two or three copies of abc : abc , abcabc , abcabcabc but nothing else Alternations ( | ) \u00b6 Alternations can be used as an \"or\" operator in regular expressions. Example Interpretation (abc)|(def) matches abc and def domain(a|b)\\.com matches domaina.com and domainb.com but not domain.com or domainx.com domain(a|b)*\\.com matches domain.com , domainaaaa.com domainbbb.com but not domainab.com (any number of a or b in between domain and .com ) Character classes ( [:class:] ) \u00b6 In addition to character groups, there are also some special character classes available, such as Character class Group equivalent Pi-hole specific Interpretation [:digit:] [0-9] No matches digits [:lower:] [a-z] No matched lowercase letters(FTL matches case-insensitive by default) [:upper:] [A-Z] No matched uppercase letters(FTL matches case-insensitive by default) [:alpha:] [A-Za-z] No matches alphabetic characters [:alnum:] [A-Za-z0-9] No matches alphabetic characters and digits [:blank:] [ \\t] Yes blank characters [:cntrl:] N/A Yes control characters [:graph:] N/A Yes all printable characters except space [:print:] N/A Yes printable characters including space [:punct:] N/A Yes printable characters not space or alphanumeric [:space:] [ \\f\\n\\r\\t\\v] Yes white-space characters [:xdigit:] [0-9a-fA-F] Yes hexadecimal digits Advanced examples \u00b6 After going through our quick tutorial, we provide some more advanced examples so you can test your knowledge. Block domain with only numbers \u00b6 ^[0-9][^a-z]+\\.((com)|(edu))$ Blocks domains containing only numbers (no letters) and ending in .com or .edu . This blocks 555661.com , and 456.edu , but not 555g555.com Block domains without subdomains \u00b6 ^[a-z0-9]+([\\-]{1}[a-z0-9]+)*\\.[a-z]{2,7}$ A domain name shall not start or end with a dash but can contain any number of them. It must be followed by a TLD (we assume a valid TLD length of two to seven characters) Cheatsheet \u00b6 Expression Meaning Example ^ Beginning of string ^client matches strings that begin with client , such as client.server.com but not more.client.server.com (exception: within a character range ( [] ) ^ means negation) $ End of string ing$ matches exciting but not ingenious * Match zero or more of the previous ah* matches ahhhhh or a ? Match zero or one of the previous ah? matches a or ah + Match one or more of the previous ah+ matches ah or ahhh but not a . Wildcard character, matches any character do.* matches do , dog , door , dot , etc.; do.+ matches dog , door , dot , etc. but not do (wildcard with + requires at least one extra character for matching) ( ) Group Enclose regular expressions, see the example for | | Alternation (mon|tues)day matches monday or tuesday but not friday or mondiag [ ] Matches a range of characters [cbf]ar matches car , bar , or far ; [^] Negation [^0-9] matches any character except 0 to 9 { } Matches a specified number of occurrences of the previous [0-9]{3} matches any three-digit number like 315 but not 31 ; [0-9]{2,4} matches two- to four-digit numbers like 12 , 123 , and 1234 but not 1 or 12345 ; [0-9]{2,} matches any number with two or more digits like 1234567 , 123456789 , but not 1 \\ Used to escape a special character not inside [] google\\.com matches google.com","title":"Pi-hole regular expressions tutorial"},{"location":"pi-hole/regex/tutorial/#pi-hole-regular-expressions-tutorial","text":"We provide a short but thorough introduction to our regular expressions implementation. This may come in handy if you are designing blocking or whitelisting rules (see also our cheat sheet below!). In our implementation, all characters match themselves except for the following special characters: .[{}()\\*+?|^$ . If you want to match those, you need to escape them like \\. for a literal period, but no rule without exception (see character groups below for further details).","title":"Pi-hole regular expressions tutorial"},{"location":"pi-hole/regex/tutorial/#anchors-and","text":"First of all, we look at anchors that can be used to indicate the start or the end of a domain, respectively. If you don't specify anchors, the match may be partial (see examples below). Example Interpretation domain partial match . Without anchors, a text may appear anywhere in the domain. This matches some.domain.com , domain.com and verylongdomain.com and more ^localhost$ exact match matching only localhost but neither a.localhost nor localhost.com ^abc matches any domain starting ( ^ ) in \"abc\" like abcdomain.com , abc.domain.com but not def.abc.com com$ matches any domain ending ( $ ) in \"com\" such as domain.com but not domain.com.co.uk","title":"Anchors (^ and $)"},{"location":"pi-hole/regex/tutorial/#wildcard","text":"An unescaped period stands for any single character. Example Interpretation ^domain.$ matches domaina , domainb , domainc , but not domain","title":"Wildcard (.)"},{"location":"pi-hole/regex/tutorial/#bounds-and-multipliers-and","text":"With bounds, one can denote the number of times something has to occur: Bound Meaning ab{4} matches a domain that contains a single a followed by four b (matching only abbbb ) ab{4,} matches a domain that contains a single a followed by at least four b (matching also abbbbbbbb ) ab{3,5} matches a domain that contains a single a followed by three to five b (matching only abbb , abbbb , and abbbbb ) Multipliers are shortcuts for some of the bounds that are needed most often: Multipliers Bounds equivalent Meaning ? {0,1} never or once (optional) * {0,} never or more (optional) + {1,} once or more (mandatory) To illustrate the usefulness of multipliers (and bounds), we provide a few examples: Example Interpretation ^r-*movie matches a domain like r------movie.com where the number of dashes can be arbitrary (also none) ^r-?movie matches only the domains rmovie.com and r-movie.com but not those with more than one dash ^r-+movie matches only the domains with at least one dash, i.e., not rmovie.com ^a?b+ matches domains like abbbb.com (zero or one a at the beginning followed by one or more b )","title":"Bounds and multipliers ({}, *, +, and ?)"},{"location":"pi-hole/regex/tutorial/#character-groups","text":"With character groups, a set of characters can be matched: Character group Interpretation [abc] matches a , b , or c (using explicitly specified characters) [a-c] matches a , b , or c (using a range ) [a-c]+ matches any non-zero number of a , b , c [a-z] matches any single lowercase letter [a-zA-Z] matches any single letter [a-z0-9] matches any single lowercase letter or any single digit [^a-z] Negation matching any single character except lowercase letters abc[0-9]+ matches the string abc followed by a number of arbitrary length Bracket expressions are an exception to the character escape rule. Inside them, all special characters, including the backslash ( \\ ), lose their special powers, i.e. they match themselves exactly. Furthermore, to include a literal ] in the list, make it the first character (like []] or [^]] if negated). To include a literal - , make it the first or last character, or the second endpoint of a range (e.g. [a-z-] to match a to z and - ).","title":"Character groups ([])"},{"location":"pi-hole/regex/tutorial/#groups","text":"Using groups, we can enclose regular expressions, they are most powerful when combined with bounds or multipliers (see also alternations below). Example Interpretation (abc) matches abc (trivial example) (abc)* matches zero or more copies of abc like abcabc but not abcdefabc (abc){1,3} matches one, two or three copies of abc : abc , abcabc , abcabcabc but nothing else","title":"Groups (())"},{"location":"pi-hole/regex/tutorial/#alternations","text":"Alternations can be used as an \"or\" operator in regular expressions. Example Interpretation (abc)|(def) matches abc and def domain(a|b)\\.com matches domaina.com and domainb.com but not domain.com or domainx.com domain(a|b)*\\.com matches domain.com , domainaaaa.com domainbbb.com but not domainab.com (any number of a or b in between domain and .com )","title":"Alternations (|)"},{"location":"pi-hole/regex/tutorial/#character-classes-class","text":"In addition to character groups, there are also some special character classes available, such as Character class Group equivalent Pi-hole specific Interpretation [:digit:] [0-9] No matches digits [:lower:] [a-z] No matched lowercase letters(FTL matches case-insensitive by default) [:upper:] [A-Z] No matched uppercase letters(FTL matches case-insensitive by default) [:alpha:] [A-Za-z] No matches alphabetic characters [:alnum:] [A-Za-z0-9] No matches alphabetic characters and digits [:blank:] [ \\t] Yes blank characters [:cntrl:] N/A Yes control characters [:graph:] N/A Yes all printable characters except space [:print:] N/A Yes printable characters including space [:punct:] N/A Yes printable characters not space or alphanumeric [:space:] [ \\f\\n\\r\\t\\v] Yes white-space characters [:xdigit:] [0-9a-fA-F] Yes hexadecimal digits","title":"Character classes ([:class:])"},{"location":"pi-hole/regex/tutorial/#advanced-examples","text":"After going through our quick tutorial, we provide some more advanced examples so you can test your knowledge.","title":"Advanced examples"},{"location":"pi-hole/regex/tutorial/#block-domain-with-only-numbers","text":"^[0-9][^a-z]+\\.((com)|(edu))$ Blocks domains containing only numbers (no letters) and ending in .com or .edu . This blocks 555661.com , and 456.edu , but not 555g555.com","title":"Block domain with only numbers"},{"location":"pi-hole/regex/tutorial/#block-domains-without-subdomains","text":"^[a-z0-9]+([\\-]{1}[a-z0-9]+)*\\.[a-z]{2,7}$ A domain name shall not start or end with a dash but can contain any number of them. It must be followed by a TLD (we assume a valid TLD length of two to seven characters)","title":"Block domains without subdomains"},{"location":"pi-hole/regex/tutorial/#cheatsheet","text":"Expression Meaning Example ^ Beginning of string ^client matches strings that begin with client , such as client.server.com but not more.client.server.com (exception: within a character range ( [] ) ^ means negation) $ End of string ing$ matches exciting but not ingenious * Match zero or more of the previous ah* matches ahhhhh or a ? Match zero or one of the previous ah? matches a or ah + Match one or more of the previous ah+ matches ah or ahhh but not a . Wildcard character, matches any character do.* matches do , dog , door , dot , etc.; do.+ matches dog , door , dot , etc. but not do (wildcard with + requires at least one extra character for matching) ( ) Group Enclose regular expressions, see the example for | | Alternation (mon|tues)day matches monday or tuesday but not friday or mondiag [ ] Matches a range of characters [cbf]ar matches car , bar , or far ; [^] Negation [^0-9] matches any character except 0 to 9 { } Matches a specified number of occurrences of the previous [0-9]{3} matches any three-digit number like 315 but not 31 ; [0-9]{2,4} matches two- to four-digit numbers like 12 , 123 , and 1234 but not 1 or 12345 ; [0-9]{2,} matches any number with two or more digits like 1234567 , 123456789 , but not 1 \\ Used to escape a special character not inside [] google\\.com matches google.com","title":"Cheatsheet"},{"location":"pi-hole/routers/asus/","text":"ASUS was so kind to set up a FAQ how to configure their routers together with Pi-hole. They offer two kinds of setup depending on your router's firmware version. On newer firmware they recommend setting Pi-hole as DNS server for the WAN connection and on older versions for LAN connections. However, we recommend to setup Pi-hole always as DNS server for your LAN ! If you do so, Pi-hole's IP is distributed as DNS server via DHCP to your network clients. Each client will directly send their queries to Pi-hole and will be shown individually in Pi-hole's web interface. Additionally, you can use the group management features. You can find the FAQ here: https://www.asus.com/support/FAQ/1046062/","title":"Asus"},{"location":"pi-hole/routers/fritzbox-de/","text":"Diese Anleitung wurde f\u00fcr FRITZ!OS 07.21 geschrieben, sollte jedoch auch mit anderen Firmware-Versionen funktionieren. Ziel ist es, grundlegende Prinzipien f\u00fcr ein reibungsloses Zusammenspiel zwischen Fritz!Box und Pi-hole zu verdeutlichen. Hinweis: Es gibt nicht nur die eine Art , ein funktionierendes DNS-System aufzusetzen. Konfiguriert euer Netzwerk nach euren Bed\u00fcrfnissen. Diese Anleitung wurde f\u00fcr IPv4 geschrieben und muss f\u00fcr IPv6 Netwerke entsprechend angepasst werden. Erweiterte Ansicht aktivieren \u00b6 Einige dieser Einstellungen sind nur sichtbar, wenn voher die Ansicht auf \"Erweitert\" gesetzt wurde. Diese wird durch Umschalten (Klick) auf \"Standard\" am unteren linken Bildrand aktiviert. Pi-hole als DNS Server via DHCP an Clients verteilen (LAN Seite) \u00b6 Mit dieser Konfiguration wird allen Clients die IP des Pi-hole als DNS Server angeboten, wenn sie einen DHCP Lease von der Fritz!Box anfordern. DNS Anfragen nehmen folgenden Weg Client -> Pi-hole -> Upstream DNS Server Hinweis: Die Fritz!Box selbst wird den unter Internet/Zugangsdaten/DNS-Server eingestellten DNS Server nutzen (siehe unten). Die Fritz!Box kann der Upstream Server von Pi-hole sein, solange Pi-hole nicht der Upstream Server der Fritz!Box ist. Dies w\u00fcrde zu einem DNS Loop f\u00fchren. Um diese Konfiguration zu nutzen, muss die IP des Pi-hole als \"Lokaler DNS-Server\" in Heimnetz/Netzwerk/Netzwerkeinstellungen/IP-Adressen/IPv4-Konfiguration/Heimnetz eingetragen werden. Warning Clients bemerken \u00c4nderungen an den DHCP Einstellungen erst, wenn der DHCP Lease erneuert wird. Der einfachste Weg dies zu erzwingen ist ein Unterbrechen und Wiederherstellen der Netzwerkverbindung. Nun sollten einzelne Clients in Pi-hole Dashboard auftrauchen. Pi-hole als Upstream DNS Server der Fritz!Box (WAN Seite) \u00b6 Mit dieser Konfiguration wird Pi-hole auch von der Fritz!Box selbst als Upstream DNS Server genutzt. DNS Anfragen nehmen folgenden Weg ( Clients ) -> Fritz!Box -> Pi-hole -> Upstream DNS Server Zum Einstellen muss die IP des Pi-hole als \"Bevorzugter DNSv4-Server\" und \"Alternativer DNSv4-Server\" in Internet/Zugangsdaten/DNS-Server eingetragen werden. Warning Die Fritz!Box darf mit dieser Konfiguration nicht als Upstream DNS Server im Pi-hole eingestellt werden. Dies w\u00fcrde zu einem DNS Loop f\u00fchren, da Pi-hole dann die Anfragen an die Fritz!Box senden w\u00fcrde, welche sie wiederum an Pi-hole senden w\u00fcrde. Wird ausschlie\u00dflich diese Konfiguration genutz, sind im Pi-hole Dashboard keine individuellen Clients sichtbar. F\u00fcr Pi-hole scheinen alle Anfragen von der Fritz!Box zu kommen. Dadurch k\u00f6nnen nicht alle Funktionen von Pi-hole genutzt werden, z.B. die M\u00f6glichkeit, Clients individuell zu filtern (Group Management). Wenn dies gew\u00fcnscht ist, muss Pi-hole (zus\u00e4tzlich) als DNS Server via DHCP an die Clients verteilt werden (siehe oben). Pi-hole im Gastnetzwerk nutzen \u00b6 Es gibt in der Fritz!Box keine M\u00f6glichkeit unter Heimnetz/Netzwerk/Netzwerkeinstellungen/IP-Adressen/IPv4-Konfiguration/Gastnetz den DNS Server des Gastnetzwerks einzustellen. Die Fritz!Box wird immer ihre eigene IP als DNS Server des Gastnetzes einstellen. Um die DNS Anfragen dennoch \u00fcber den Pi-hole zu senden, muss dieser als Upstream DNS Server f\u00fcr die Fritz!Box eingetragen werden. Da es keine andere Option gibt, werden alle Anfragen aus dem Gastnetz f\u00fcr Pi-hole so erscheinen, als ob sie direkt von der Fritz!Box kommen. Eine individuelle Filterung je nach Client innerhalb des Gastnetzwerks ist deshalb nicht m\u00f6glich. Hostnamen in Pi-hole statt IP-Addressen - Conditional forwarding \u00b6 Wenn die Fritz!Box im Netzwerk als DHCP Server fungiert, werden die Hostnamen der Clients nur dort registriert. Pi-hole versucht standardm\u00e4\u00dfig, die IP-Adressen der Clients wieder in Hostnamen aufzul\u00f6sen. Daher m\u00fcssen die Anfragen zur Fritz!Box gelangen. Daf\u00fcr gibt es zwei Wege: Die Fritz!Box ist der Upstream DNS Server des Pi-holes. Damit landen alle Anfragen sowieso bei der Fritz!Box, welche die Hostnamen an Pi-hole zur\u00fccksenden kann. Warning Die Fritz!Box darf nur der Upstream DNS Server des Pi-hole sein, wenn dieser nicht gleichzeitig der Upstream DNS Server der Fritz!Box ist. Dies w\u00fcrde zu einem DNS Loop f\u00fchren. Es werden nur die Anfragen an die Fritz!Box gesendet, welche versuchen im lokalen Netzwerk IP-Adressen wieder Hostnamen zuzuordnene. Alle anderen Anfragen werden an den Upstream DNS Server des Pi-Hole gesendet. Daf\u00fcr ist die Option Conditional forwarding zust\u00e4ndig. Folgende Einstellungen m\u00fcssen daf\u00fcr vorgenommen werden: Local network in CIDR notation: IP-Bereich des Netzwerks in CIDR Notation, Standard f\u00fcr die Fritz!Box ist 192.168.178.0/24 IP address of your DHCP server (router): IP-Adresse der Fritz!Box selbst, Standard ist 192.168.178.1 Local domain name (optional): Name der lokalen Dom\u00e4n, f\u00fcr die Fritz!Box fritz.box","title":"Fritzbox de"},{"location":"pi-hole/routers/fritzbox-de/#erweiterte-ansicht-aktivieren","text":"Einige dieser Einstellungen sind nur sichtbar, wenn voher die Ansicht auf \"Erweitert\" gesetzt wurde. Diese wird durch Umschalten (Klick) auf \"Standard\" am unteren linken Bildrand aktiviert.","title":"Erweiterte Ansicht aktivieren"},{"location":"pi-hole/routers/fritzbox-de/#pi-hole-als-dns-server-via-dhcp-an-clients-verteilen-lan-seite","text":"Mit dieser Konfiguration wird allen Clients die IP des Pi-hole als DNS Server angeboten, wenn sie einen DHCP Lease von der Fritz!Box anfordern. DNS Anfragen nehmen folgenden Weg Client -> Pi-hole -> Upstream DNS Server Hinweis: Die Fritz!Box selbst wird den unter Internet/Zugangsdaten/DNS-Server eingestellten DNS Server nutzen (siehe unten). Die Fritz!Box kann der Upstream Server von Pi-hole sein, solange Pi-hole nicht der Upstream Server der Fritz!Box ist. Dies w\u00fcrde zu einem DNS Loop f\u00fchren. Um diese Konfiguration zu nutzen, muss die IP des Pi-hole als \"Lokaler DNS-Server\" in Heimnetz/Netzwerk/Netzwerkeinstellungen/IP-Adressen/IPv4-Konfiguration/Heimnetz eingetragen werden. Warning Clients bemerken \u00c4nderungen an den DHCP Einstellungen erst, wenn der DHCP Lease erneuert wird. Der einfachste Weg dies zu erzwingen ist ein Unterbrechen und Wiederherstellen der Netzwerkverbindung. Nun sollten einzelne Clients in Pi-hole Dashboard auftrauchen.","title":"Pi-hole als DNS Server via DHCP an Clients verteilen (LAN Seite)"},{"location":"pi-hole/routers/fritzbox-de/#pi-hole-als-upstream-dns-server-der-fritzbox-wan-seite","text":"Mit dieser Konfiguration wird Pi-hole auch von der Fritz!Box selbst als Upstream DNS Server genutzt. DNS Anfragen nehmen folgenden Weg ( Clients ) -> Fritz!Box -> Pi-hole -> Upstream DNS Server Zum Einstellen muss die IP des Pi-hole als \"Bevorzugter DNSv4-Server\" und \"Alternativer DNSv4-Server\" in Internet/Zugangsdaten/DNS-Server eingetragen werden. Warning Die Fritz!Box darf mit dieser Konfiguration nicht als Upstream DNS Server im Pi-hole eingestellt werden. Dies w\u00fcrde zu einem DNS Loop f\u00fchren, da Pi-hole dann die Anfragen an die Fritz!Box senden w\u00fcrde, welche sie wiederum an Pi-hole senden w\u00fcrde. Wird ausschlie\u00dflich diese Konfiguration genutz, sind im Pi-hole Dashboard keine individuellen Clients sichtbar. F\u00fcr Pi-hole scheinen alle Anfragen von der Fritz!Box zu kommen. Dadurch k\u00f6nnen nicht alle Funktionen von Pi-hole genutzt werden, z.B. die M\u00f6glichkeit, Clients individuell zu filtern (Group Management). Wenn dies gew\u00fcnscht ist, muss Pi-hole (zus\u00e4tzlich) als DNS Server via DHCP an die Clients verteilt werden (siehe oben).","title":"Pi-hole als Upstream DNS Server der Fritz!Box (WAN  Seite)"},{"location":"pi-hole/routers/fritzbox-de/#pi-hole-im-gastnetzwerk-nutzen","text":"Es gibt in der Fritz!Box keine M\u00f6glichkeit unter Heimnetz/Netzwerk/Netzwerkeinstellungen/IP-Adressen/IPv4-Konfiguration/Gastnetz den DNS Server des Gastnetzwerks einzustellen. Die Fritz!Box wird immer ihre eigene IP als DNS Server des Gastnetzes einstellen. Um die DNS Anfragen dennoch \u00fcber den Pi-hole zu senden, muss dieser als Upstream DNS Server f\u00fcr die Fritz!Box eingetragen werden. Da es keine andere Option gibt, werden alle Anfragen aus dem Gastnetz f\u00fcr Pi-hole so erscheinen, als ob sie direkt von der Fritz!Box kommen. Eine individuelle Filterung je nach Client innerhalb des Gastnetzwerks ist deshalb nicht m\u00f6glich.","title":"Pi-hole im Gastnetzwerk nutzen"},{"location":"pi-hole/routers/fritzbox-de/#hostnamen-in-pi-hole-statt-ip-addressen-conditional-forwarding","text":"Wenn die Fritz!Box im Netzwerk als DHCP Server fungiert, werden die Hostnamen der Clients nur dort registriert. Pi-hole versucht standardm\u00e4\u00dfig, die IP-Adressen der Clients wieder in Hostnamen aufzul\u00f6sen. Daher m\u00fcssen die Anfragen zur Fritz!Box gelangen. Daf\u00fcr gibt es zwei Wege: Die Fritz!Box ist der Upstream DNS Server des Pi-holes. Damit landen alle Anfragen sowieso bei der Fritz!Box, welche die Hostnamen an Pi-hole zur\u00fccksenden kann. Warning Die Fritz!Box darf nur der Upstream DNS Server des Pi-hole sein, wenn dieser nicht gleichzeitig der Upstream DNS Server der Fritz!Box ist. Dies w\u00fcrde zu einem DNS Loop f\u00fchren. Es werden nur die Anfragen an die Fritz!Box gesendet, welche versuchen im lokalen Netzwerk IP-Adressen wieder Hostnamen zuzuordnene. Alle anderen Anfragen werden an den Upstream DNS Server des Pi-Hole gesendet. Daf\u00fcr ist die Option Conditional forwarding zust\u00e4ndig. Folgende Einstellungen m\u00fcssen daf\u00fcr vorgenommen werden: Local network in CIDR notation: IP-Bereich des Netzwerks in CIDR Notation, Standard f\u00fcr die Fritz!Box ist 192.168.178.0/24 IP address of your DHCP server (router): IP-Adresse der Fritz!Box selbst, Standard ist 192.168.178.1 Local domain name (optional): Name der lokalen Dom\u00e4n, f\u00fcr die Fritz!Box fritz.box","title":"Hostnamen in Pi-hole statt IP-Addressen - Conditional forwarding"},{"location":"pi-hole/routers/fritzbox/","text":"This guide was developed using FRITZ!OS 07.21 but should work for others too. It aims to line out a few basic principles to have a seamless DNS experience with Pi-hole and Fritz!Boxes. Note: There is no single way to do it right. Choose the one best fitting your needs. This guide is IPv4 only. You need to adjust for IPv6 accordingly. Enable advanced settings \u00b6 Some of the following settings might be visible only if advanced settings are enabled. Therefore, \"View\" has to be changed to advanced by clicking on \"Standard\" in the lower left corner. Distribute Pi-hole as DNS server via DHCP \u00b6 Using this configuration, all clients will get Pi-hole's IP offered as DNS server when they request a DHCP lease from your Fritz!Box. DNS queries take the following path Client -> Pi-hole -> Upstream DNS Server Note: The Fritz!Box itself will use whatever is configured in Internet/Account Information/DNS server (see below). The Fritz!Box can be Pi-hole's upstream DNS server, as long Pi-hole itself is not the upstream server of the Fritz!Box. This would cause a DNS loop. To set it up, enter Pi-hole's IP as \"Local DNS server\" in Home Network/Network/Network Settings/IP Addresses/IPv4 Configuration/Home Network Warning Clients will notice changes in DHCP settings only after they acquired a new DHCP lease. The easiest way to force a renewal is to dis/reconnect the client from the network. Now you should see individual clients in Pi-hole's web dashboard. Pi-hole as upstream DNS server for your Fritz!Box \u00b6 With this configuration, Pi-hole is also used by the Fritz!Box itself as an upstream DNS server. DNS queries take the following path ( Clients ) -> Fritz!Box -> Pi-hole -> Upstream DNS Server To set it up, enter Pi-hole's IP as \"Preferred DNSv4 server\" and \"Alternative DNSv4 server\" in Internet/Account Information/DNS server Warning Don't set the Fritz!Box as upstream DNS server for Pi-hole if using this configuration! This will lead to a DNS loop as the Pi-hole will send the queries to the Fritz!Box which in turn will send them to Pi-hole. If only this configuration is used, you won't see individual clients in Pi-hole's dashboard. For Pi-hole, all queries will appear as if they are coming from your Fritz!Box. You will therefore miss out on some features, e.g. Group Management. If you want to use them, Pi-hole must (additionally) be distributed to the clients as DNS server via DHCP (see above). Using Pi-hole within the Guest Network \u00b6 There is no option to set the DNS server for the guest network in Home Network/Network/Network Settings/IP Addresses/IPv4 Configuration/Guest Network The Fritz!Box always sets its own IP as DNS server for the guest network. To filter its traffic, you have to setup Pi-hole as upstream DNS server for your Fritz!Box. As there is no other option, all DNS requests from your guest network will appear as coming from your Fritz!Box. Individual filtering per client within the guest network is therefore not possible. Hostnames instead of IP addresses in Pi-hole's web interface - Conditional forwarding \u00b6 In case the Fritz!Box is used as DHCP server, client's hostnames are registered only there. By default, Pi-hole tries to resolve the IP addresses of the clients back into host names. Therefore, the requests must reach the Fritz!Box. There are two ways to do this: The Fritz!Box is the upstream DNS server of the Pi-hole. This means that all queries end up with the Fritz!Box anyway, which can send the host names back to Pi-hole. Warning The Fritz!Box may only be the upstream DNS server of the Pi-hole if Pi-hole is not the upstream DNS server of the Fritz!Box. This would lead to a DNS loop. Only those queries are sent to the Fritz!Box that attempt to determine hostnames for IP addresses (clients) of the local network. All other requests are sent to the upstream DNS server of the Pi-Hole. The Conditional forwarding option is responsible for this. The following settings must be made: Local network in CIDR notation: Standard IP range of the Fritz!Box is 192.168.178.0/24 IP address of your DHCP server (router): IP of the Fritz!Box, standard is 192.168.178.1 Local domain name (optional): Fritz!Box uses fritz.box","title":"Fritzbox"},{"location":"pi-hole/routers/fritzbox/#enable-advanced-settings","text":"Some of the following settings might be visible only if advanced settings are enabled. Therefore, \"View\" has to be changed to advanced by clicking on \"Standard\" in the lower left corner.","title":"Enable advanced settings"},{"location":"pi-hole/routers/fritzbox/#distribute-pi-hole-as-dns-server-via-dhcp","text":"Using this configuration, all clients will get Pi-hole's IP offered as DNS server when they request a DHCP lease from your Fritz!Box. DNS queries take the following path Client -> Pi-hole -> Upstream DNS Server Note: The Fritz!Box itself will use whatever is configured in Internet/Account Information/DNS server (see below). The Fritz!Box can be Pi-hole's upstream DNS server, as long Pi-hole itself is not the upstream server of the Fritz!Box. This would cause a DNS loop. To set it up, enter Pi-hole's IP as \"Local DNS server\" in Home Network/Network/Network Settings/IP Addresses/IPv4 Configuration/Home Network Warning Clients will notice changes in DHCP settings only after they acquired a new DHCP lease. The easiest way to force a renewal is to dis/reconnect the client from the network. Now you should see individual clients in Pi-hole's web dashboard.","title":"Distribute Pi-hole as DNS server via DHCP"},{"location":"pi-hole/routers/fritzbox/#pi-hole-as-upstream-dns-server-for-your-fritzbox","text":"With this configuration, Pi-hole is also used by the Fritz!Box itself as an upstream DNS server. DNS queries take the following path ( Clients ) -> Fritz!Box -> Pi-hole -> Upstream DNS Server To set it up, enter Pi-hole's IP as \"Preferred DNSv4 server\" and \"Alternative DNSv4 server\" in Internet/Account Information/DNS server Warning Don't set the Fritz!Box as upstream DNS server for Pi-hole if using this configuration! This will lead to a DNS loop as the Pi-hole will send the queries to the Fritz!Box which in turn will send them to Pi-hole. If only this configuration is used, you won't see individual clients in Pi-hole's dashboard. For Pi-hole, all queries will appear as if they are coming from your Fritz!Box. You will therefore miss out on some features, e.g. Group Management. If you want to use them, Pi-hole must (additionally) be distributed to the clients as DNS server via DHCP (see above).","title":"Pi-hole as upstream DNS server for your Fritz!Box"},{"location":"pi-hole/routers/fritzbox/#using-pi-hole-within-the-guest-network","text":"There is no option to set the DNS server for the guest network in Home Network/Network/Network Settings/IP Addresses/IPv4 Configuration/Guest Network The Fritz!Box always sets its own IP as DNS server for the guest network. To filter its traffic, you have to setup Pi-hole as upstream DNS server for your Fritz!Box. As there is no other option, all DNS requests from your guest network will appear as coming from your Fritz!Box. Individual filtering per client within the guest network is therefore not possible.","title":"Using Pi-hole within the Guest Network"},{"location":"pi-hole/routers/fritzbox/#hostnames-instead-of-ip-addresses-in-pi-holes-web-interface-conditional-forwarding","text":"In case the Fritz!Box is used as DHCP server, client's hostnames are registered only there. By default, Pi-hole tries to resolve the IP addresses of the clients back into host names. Therefore, the requests must reach the Fritz!Box. There are two ways to do this: The Fritz!Box is the upstream DNS server of the Pi-hole. This means that all queries end up with the Fritz!Box anyway, which can send the host names back to Pi-hole. Warning The Fritz!Box may only be the upstream DNS server of the Pi-hole if Pi-hole is not the upstream DNS server of the Fritz!Box. This would lead to a DNS loop. Only those queries are sent to the Fritz!Box that attempt to determine hostnames for IP addresses (clients) of the local network. All other requests are sent to the upstream DNS server of the Pi-Hole. The Conditional forwarding option is responsible for this. The following settings must be made: Local network in CIDR notation: Standard IP range of the Fritz!Box is 192.168.178.0/24 IP address of your DHCP server (router): IP of the Fritz!Box, standard is 192.168.178.1 Local domain name (optional): Fritz!Box uses fritz.box","title":"Hostnames instead of IP addresses in Pi-hole's web interface - Conditional forwarding"},{"location":"tutorials/general/","text":"General Tutorials \u00b6 Keeping a certain tutorial up to date has proven infeasible. Two main problems are: Different teachers/tutors have different styles, and thus have difficulties upgrading someone else's tutorial. Different tutorials cover different parts of the material, and so the upgrade of \"the\" standard tutorial always was inconsistent between its different pieces. We are now aiming for the following: The standard intro reference is \" The Book \". TU Berlin teaches a MATSim class during every summer term. We plan to move the tutorial material of that class to the site here at the end of each term (i.e. around July/August of every year). The most current version is the 2020 course . Additional material is available under matsim.org/javadoc --> main distribution --> tutorials. That material may be a bit more difficult to find or read, but it has the advantage that it is inside the code repository and thus always compiling and in many cases even secured by a regression test. 2020: MATSim class at TU Berlin (MATSim version 12.x) . 2019: MATSim class at TU Berlin (MATSim version 11.x) . 2018: MATSim class at TU Berlin (MATSim version 0.10.x) . 2017: MATSim class at TU Berlin (MATSim version 0.9.x) . 2016: MATSim class at TU Berlin (MATSim version 0.8.x) .","title":"Quick start"},{"location":"tutorials/general/#general-tutorials","text":"Keeping a certain tutorial up to date has proven infeasible. Two main problems are: Different teachers/tutors have different styles, and thus have difficulties upgrading someone else's tutorial. Different tutorials cover different parts of the material, and so the upgrade of \"the\" standard tutorial always was inconsistent between its different pieces. We are now aiming for the following: The standard intro reference is \" The Book \". TU Berlin teaches a MATSim class during every summer term. We plan to move the tutorial material of that class to the site here at the end of each term (i.e. around July/August of every year). The most current version is the 2020 course . Additional material is available under matsim.org/javadoc --> main distribution --> tutorials. That material may be a bit more difficult to find or read, but it has the advantage that it is inside the code repository and thus always compiling and in many cases even secured by a regression test. 2020: MATSim class at TU Berlin (MATSim version 12.x) . 2019: MATSim class at TU Berlin (MATSim version 11.x) . 2018: MATSim class at TU Berlin (MATSim version 0.10.x) . 2017: MATSim class at TU Berlin (MATSim version 0.9.x) . 2016: MATSim class at TU Berlin (MATSim version 0.8.x) .","title":"General Tutorials"},{"location":"userguide/","text":"The MATSim user guide \u00b6 The MATSim user guide (pdf) is an extract and update of the MATSim book . These chapters contain the most relevant topics for new users. If the above link does not work, try to right-click the link and select \"Save Link As\u2026\" or \"Download Linked File As\u2026\" or similar, depending on your browser. The user guide is typically updated along with the MATSim class that we teach at TU Berlin every year between April and July.","title":"User Guide"},{"location":"userguide/#the-matsim-user-guide","text":"The MATSim user guide (pdf) is an extract and update of the MATSim book . These chapters contain the most relevant topics for new users. If the above link does not work, try to right-click the link and select \"Save Link As\u2026\" or \"Download Linked File As\u2026\" or similar, depending on your browser. The user guide is typically updated along with the MATSim class that we teach at TU Berlin every year between April and July.","title":"The MATSim user guide"},{"location":"userguide/terminology/","text":"In many cases, MATSim uses a terminology that is different from the mainstream terminology. In most cases, the reason is that the concepts are only similar, but not identical, and we wanted to avoid the confusion of using the same term for aspects that are similar but not identical. The following attempts some commented approximate \u201dtranslations\u201d from more standard teminology to MATSim terminology. Choice set \u2192 \u201cplan set\u201d of an agent During MATSim iterations, agent accumulate plans. This can be interpreted as building a choice set over time. A problem is that the process that generates the choice set at this point is not systematic. Possible future developments: Once it has been made explicit that \u201dplans generation\u201d means \u201dchoice set generation\u201d, the terminology may be made standard. Choice set generation \u2192 Time mutation/re-route/... ; \u201dinnovation\u201d As said above, the set of MATSim plans can be seen as this agent\u2019s choice set. MATSim generates new plans \u201don-the-fly\u201d, i.e. while the simulation is running. We sometimes call this \u201dinnovation\u201d, since agents create new plans (= add entries to the choice set), rather than choosing between existing plans. Choice set generation, choice \u2192 replanning In MATSim, there is no strict separation between \u201dchoice set generation\u201d and \u201dchoice\u201d: at the replanning step, for each agent, a replanning strategy is randomly choosen. This strategy may consist in selecting a random plan to use to generate a new plan by mutation (\u201dchoice set generation\u201d part), or just to select a past plan based on the experienced score (\u201dchoice\u201d part). Convergence \u2192 learning rate Scores in matsim are computed as score new = (1 \u2212 \u03b1 ) \u00b7 score old + \u03b1 \u00b7 score sim , where score sim is the score that is obtained from the execution of the plans (= network loading). \u03bc (logit model scaling factor) \u2192 beta brain MATSim scoring function: BrainExpBeta \u22c5 \u2211 i \u03b2 i x i Typical logit model formulation: \u03bc \u22c5 \u2211 i \u03b2 i x i As is well known, \u03bc or \u03b2 i are not independently identifiable from estimation. For simulation, they are hence somewhat arbitrary. The default value for \u201d BrainExpBeta \u201d is 2 for historical reasons, but it should be set to 1 if the parameters of the scoring function are estimated rather than hand-calibrated. Possible future development: Default value of BrainExpBeta should be set to 1 instead of 2. Multinomial logit \u2192 ExpBetaPlanSelector Comments: The main problem is that one needs to keep in mind how the choice set is constructed (see above). In most simulations, we use ExpBetaPlanChanger instead, which is a Metropolis Monte Carlo variant of making multinomial logit draws Possible future developments: None of this is ideal, since, after the introduction of a policy, it is not clear which behavioral switches are due to the policy, and which are due to sampling. In theory, one should have unbiased samples before and after the introduction of the policy, but at this point this is not implemented and it is also computationally considerably more expensive than what is done now. Network loading \u2192 mobsim, mobility simulation, physical simulation The standard terminology has the \u201dnetwork loading\u201d on the \u201dsupply side\u201d. In my (KN\u2019s) view, the \u201dsimulation of the physical system\u201d is not the supply side, but what in economics is called \u201dtechnology\u201d. This can for example be seen in the fact that \u201dlane changing\u201d is part of the mobsim, but this is, in my view, not a \u201dsupply side\u201d aspect. Possible future developments: May switch to \u201dnetwork loading\u201d if there is agreement that this is a better name. Stationary \u2192 relaxed \u201cstationary\u201d means that the probability distribution does not shift any more. However, as long as \u201dinnovation\u201d is still switched in on MATSim (new routes, new times, ...), the result is not truly stationary. Thus we avoid the word. If innovation is switched off, the result is indeed a statinary process, but limited to the set of plans that every agent has at that point in time. Possible future developments: not clear. Minimally, publications should be precise. <module name=\"strategy\" > <!-- iteration after which module will be disabled. ... --> <param name=\"ModuleDisableAfterIteration_1\" value=\"null\" /> <param name=\"ModuleDisableAfterIteration_2\" value=\"950\" /> <!-- probability that a strategy is applied to a given person. ... --> <param name=\"ModuleProbability_1\" value=\"0.9\" /> <param name=\"ModuleProbability_2\" value=\"0.1\" /> <!-- name of strategy ... --> <param name=\"Module_1\" value=\"ChangeExpBeta\" /> <param name=\"Module_2\" value=\"ReRoute\" /> <!-- maximum number of plans per agent ... --> <param name=\"maxAgentPlanMemorySize\" value=\"4\" /> </module> The above means: StrategyModule \u201dReRoute\u201d (= innovative Module, produces plans with new routes) is switched off after iteration 950. StrategyModule \u201dChangeExpBeta\u201d (= non-innovative Module, switches between existing plans) is never switched off. If an agent ever ends up with more than 4 plans, plans are deleted until she is back to 4 plans. (Deletion goes via a \u201dPlanSelectorForRemoval\u201d, which affects the choice set, and thus more thought needs to go into this. Currently, the plan with the worst score is removed.) Utility \u2194 score Configuration: At least when using random utility models (such as multinomial logit aka ExpBeta...), the score has the same function as the deterministic utility.","title":"Terminology"}]}